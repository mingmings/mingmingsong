<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[coding pages 去掉欢迎页之 Hosted by Coding Pages]]></title>
    <url>%2Fnote%2Fgit_coding-pages-%E5%8E%BB%E6%8E%89%E6%AC%A2%E8%BF%8E%E9%A1%B5%E4%B9%8B-Hosted-by-Coding-Pages.html</url>
    <content type="text"><![CDATA[我期望躺在向日葵上，即使沮丧，也能朝着阳光。 &emsp;&emsp;个人静态页托管在 coding 上，但是发觉 coding 上收费政策变更了，普通会员和银牌会员使用 pages 服务，会默认加载 Pages 跳转页，引来一大片吐槽。。。 不过 pages 跳转页是可以消除的，有如下两种办法： 1、升级金牌会员，199￥/年，这点捆绑式被人吐槽的不轻，光用一个 pages 服务这个价格太高，当然土豪请随意2、在网站首页的任何位置放置「Hosted by Coding Pages」的文字版或图片版，然后后台提交审核申请，申请通过即可消除。 下面介绍具体操作 1、首先必须把Coding Pages升级为银牌会员（免费），其实就是补全个人资料罢了，貌似是手机号绑定后就好。2、然后在Page服务中才会出现Hosted by Coding Pages设置项，如下图。 有两种方式来去掉欢迎页，一种是文字，一种是图片，图片尺寸是300*300，感觉有点大，并且是方形的，我用的是 next 主题，不知道放那里，只好选择了文字，就是下边这一行代码。&lt;p&gt;Hosted by &lt;a href="https://pages.coding.me" style="font-weight: bold"&gt;Coding Pages&lt;/a&gt;&lt;/p&gt; 前端的我不是很熟悉，就从网上找找修改 next 主题的页脚部分，需要修改如下内容themes/next/layout/_partials/footer.swig 脚本原来内容为&lt;div class="copyright" &gt; &#123;% set current = date(Date.now(), "YYYY") %&#125; &amp;copy; &#123;% if theme.since and theme.since != current %&#125; &#123;&#123; theme.since &#125;&#125; - &#123;% endif %&#125; &lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love"&gt; &lt;i class="fa fa-&#123;&#123; theme.authoricon &#125;&#125;"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class="author" itemprop="copyrightHolder"&gt;&#123;&#123; config.author &#125;&#125;&lt;/span&gt;&lt;/div&gt;&#123;% if theme.copyright %&#125;&lt;div class="powered-by"&gt; &#123;&#123; __('footer.powered', '&lt;a class="theme-link" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125;&lt;/div&gt;&lt;div class="theme-info"&gt; &#123;&#123; __('footer.theme') &#125;&#125; - &lt;a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt;&#123;% endif %&#125; 增加 coding pages host 设置&lt;div class="copyright" &gt; &#123;% set current = date(Date.now(), "YYYY") %&#125; &amp;copy; &#123;% if theme.since and theme.since != current %&#125; &#123;&#123; theme.since &#125;&#125; - &#123;% endif %&#125; &lt;span itemprop="copyrightYear"&gt;&#123;&#123; current &#125;&#125;&lt;/span&gt; &lt;span class="with-love"&gt; &lt;i class="fa fa-&#123;&#123; theme.authoricon &#125;&#125;"&gt;&lt;/i&gt; &lt;/span&gt; &lt;span class="author" itemprop="copyrightHolder"&gt;&#123;&#123; config.author &#125;&#125;&lt;/span&gt; &lt;!--以下3行为一条竖线和Coding Page--&gt; &lt;div class="powered-by"&gt; &lt;/div&gt; &lt;span&gt;Hosted by &lt;a href="https://pages.coding.me" style="font-weight: bold"&gt;Coding Pages&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;&#123;% if theme.copyright %&#125;&lt;div class="powered-by"&gt; &#123;&#123; __('footer.powered', '&lt;a class="theme-link" href="https://hexo.io"&gt;Hexo&lt;/a&gt;') &#125;&#125;&lt;/div&gt;&lt;div class="theme-info"&gt; &#123;&#123; __('footer.theme') &#125;&#125; - &lt;a class="theme-link" href="https://github.com/iissnan/hexo-theme-next"&gt; NexT.&#123;&#123; theme.scheme &#125;&#125; &lt;/a&gt;&lt;/div&gt;&#123;% endif %&#125; 重新部署 hexo 后，在后台提交点击已放置 [Hosted by Coding Pages] 按钮，等待审核，审核通过，pages 跳转页即可取消 &emsp;&emsp; 参考阅读 Android_大船]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>coding pages</tag>
        <tag>Hosted by Coding Pages</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django QuerySet]]></title>
    <url>%2Fnote%2Fdjango_django-QuerySet.html</url>
    <content type="text"><![CDATA[掉了的东西就不要捡了，路过的风景也不要打听了，失去的人也别再纠缠了。 查询集&emsp;&emsp;一旦你建立好数据模型，Django 会自动为你生成一套数据库抽象的API，可以让你创建、检索、更新和删除对象。&emsp;&emsp;Django 使用一种直观的方式把数据库表中的数据表示成Python 对象：一个模型类代表数据库中的一个表，一个模型类的实例代表这个数据库表中的一条特定的记录。 &emsp;&emsp;所以如果要获取数据库里的一条对象，那么 django 通过模型中的管理器构造一个查询集，来从你的数据库中获取对象。查询集表示从数据库中取出来的对象的集合。它可以含有零个、一个或者多个过滤器。过滤器基于所给的参数限制查询的结果。 从SQL 的角度，查询集和SELECT 语句等价，过滤器是像WHERE 和LIMIT 一样的限制子句。 In [2]: Group.objects.all()Out[2]: &lt;QuerySet [&lt;Group: devops&gt;, &lt;Group: hr&gt;, &lt;Group: op&gt;, &lt;Group: ops&gt;]&gt; 注意 all()方法返回包含数据库中所有对象的一个查询集。但在通常情况下，你往往想要获取的是完整数据集的一个子集。要创建这样一个子集，你需要在原始的的查询集上增加一些过滤条件。 两个最普遍的途径是： filter(**kwargs)返回一个新的查询集，它包含满足查询参数的对象。 exclude(**kwargs)返回一个新的查询集，它包含不满足查询参数的对象。 In [4]: Group.objects.filter(id=1)Out[4]: &lt;QuerySet [&lt;Group: devops&gt;]&gt;In [5]: Group.objects.exclude(id=1)Out[5]: &lt;QuerySet [&lt;Group: hr&gt;, &lt;Group: op&gt;, &lt;Group: ops&gt;]&gt; 1、查询集是惰性执行的创建查询集不会带来任何数据库的访问。你可以将过滤器保持一整天，直到查询集 需要求值时，Django 才会真正运行这个查询。看下这个例子：In [8]: u1 = User.objects.all()In [9]: u2 = u1.exclude(id__exact=1)In [10]: u3 = u1.filter(id__exact=1)In [11]: print(u3) 虽然它看上去有三次数据库访问，但事实上只有在最后一行（print()）时才访问一次数据库。一般来说，只有在“请求”查询集 的结果时才会到数据库中去获取它们。 2、缓存和查询集每个查询集都包含一个缓存来最小化对数据库的访问。在一个新创建的查询集中，缓存为空。首次对查询集进行求值 —— 同时发生数据库查询 —— Django 将保存查询的结果到查询集的缓存中并返回明确请求的结果（例如，如果正在迭代查询集，则返回下一个结果）。接下来对该查询集 的求值将重用缓存的结果。 # 下面两行相同的数据库查询将执行两次，显然增加了数据库负载。同时，还有可能两个结果列表并不包含相同的数据库记录In [13]: print([u.username for u in User.objects.all()])In [14]: print([u.email for u in User.objects.all()]) 因为在两次请求期间有可能有不同的条目被添加进来或删除掉。为了避免这个问题，只需保存查询集并重用 # 下面两次 print 都重用了 qs 查询集缓存，实际上只执行了一次数据库查询In [16]: qs = User.objects.all()In [17]: print([u.username for u in qs]) # 查询数据库In [18]: print([u.email for u in qs]) # 使用缓存 查询集不会永远缓存它们的结果。当只对查询集的部分进行求值时会检查缓存， 但是如果这个部分不在缓存中，那么接下来查询返回的记录都将不会被缓存。特别地，这意味着使用切片或索引来限制查询集将不会填充缓存。 例如，重复获取查询集对象中一个特定的索引将每次都查询数据库：（这部分直接摘抄官方的例子） &gt;&gt;&gt; queryset = Entry.objects.all()&gt;&gt;&gt; print queryset[5] # 查询数据库&gt;&gt;&gt; print queryset[5] # 仍旧查询数据库 然而，如果已经对全部查询集求值过，则将检查缓存： &gt;&gt;&gt; queryset = Entry.objects.all()&gt;&gt;&gt; [entry for entry in queryset] # 查询数据库&gt;&gt;&gt; print queryset[5] # 使用缓存&gt;&gt;&gt; print queryset[5] # 使用缓存 下面是一些其它例子，它们会使得全部的查询集被求值并填充到缓存中： &gt;&gt;&gt; [entry for entry in queryset] # 查询库&gt;&gt;&gt; bool(queryset)&gt;&gt;&gt; entry in queryset&gt;&gt;&gt; list(queryset) 另外，简单地打印查询集不会填充缓存。因为__repr__()调用只返回全部查询集的一个切片。 3、其他查询集方法Django 提供了一系列 的QuerySet筛选方法，用于改变 QuerySet 返回的结果类型或者SQL查询执行的方式。 大多数情况下，需要从数据库中查找对象时，你会使用all()、 get()、filter() 和exclude()。查询集方法的完整列表，请参见查询集API 参考。 这里说一下 values() 和 values_list() values()：返回一个ValuesQuerySet —— QuerySet 的一个子类，迭代时返回字典而不是模型实例对象。需要注意的是，返回的不是list，不要直接当list来用了。对ValuesQuerySet遍历，每一个元素是“字典”dict。 当不传入参数时，返回这个model的所有字段 In [20]: Group.objects.values()Out[20]: &lt;QuerySet [&#123;'id': 1, 'name': 'devops'&#125;, &#123;'id': 11, 'name': 'hr'&#125;, &#123;'id': 2, 'name': 'op'&#125;, &#123;'id': 10, 'name': 'ops'&#125;]&gt; 当传入参数时，只会列出你指定的参数 In [22]: Group.objects.values('name')Out[22]: &lt;QuerySet [&#123;'name': 'devops'&#125;, &#123;'name': 'hr'&#125;, &#123;'name': 'op'&#125;, &#123;'name': 'ops'&#125;]&gt; 也可以加上filter，filter在前或者后面都是一样的 In [24]: Group.objects.filter(pk=1).values('name')Out[24]: &lt;QuerySet [&#123;'name': 'devops'&#125;]&gt; 下面两种写法是相同的 Blog.objects.values().order_by('id')Blog.objects.order_by('id').values() 当values() 与distinct() 一起使用时，注意排序可能影响最终的结果。详细信息参见distinct() 中的备注。 如果values() 子句位于extra() 调用之后，extra() 中的select 参数定义的字段必须显式包含在values() 调用中。values() 调用后面的extra() 调用将忽略选择的额外的字段。 在values() 之后调用only() 和defer() 不太合理，所以将引发一个NotImplementedError。 values_list()：和values一样，只是返回的不是字典而是元组。 官方给了一个例子比较好理解。如果只传递一个字段，你还可以传递flat 参数。如果为True，它表示返回的结果为单个值而不是元组。一个例子会让它们的区别更加清晰： &gt;&gt;&gt; Entry.objects.values_list('id').order_by('id')[(1,), (2,), (3,), ...]&gt;&gt;&gt; Entry.objects.values_list('id', flat=True).order_by('id')[1, 2, 3, ...] 如果有多个字段，传递flat 将发生错误。 如果你不传递任何值给values_list()，它将返回模型中的所有字段，以它们在模型中定义的顺序。 注意，这个方法返回ValuesListQuerySet。这个类的行为类似列表。大部分时候它足够用了，但是如果你需要一个真实的Python 列表对象，可以对它调用list()，这将会对查询集求值。 最后还有几点注意，摘自涂伟忠大大自强学堂内容 (1). 如果只是检查 Entry 中是否有对象，应该用 Entry.objects.all().exists() (2). QuerySet 支持切片 Entry.objects.all()[:10] 取出10条，可以节省内存 (3). 用 len(es) 可以得到Entry的数量，但是推荐用 Entry.objects.count()来查询数量，后者用的是SQL：SELECT COUNT(*) (4). list(es) 可以强行将 QuerySet 变成 列表 &emsp;&emsp; 参考阅读 执行查询 QuerySet API参考 查找 API 参考 Django QuerySet API]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>model</tag>
        <tag>filter</tag>
        <tag>get</tag>
        <tag>数据模型查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[离开也许是另一种精彩]]></title>
    <url>%2Fnote%2Ftravel-%E7%A6%BB%E5%BC%80%E4%B9%9F%E8%AE%B8%E6%98%AF%E5%8F%A6%E4%B8%80%E7%A7%8D%E7%B2%BE%E5%BD%A9.html</url>
    <content type="text"><![CDATA[人的行为会改变，但内心的温度通常不会改变。 &emsp;&emsp;2017年6月3号这一天，注定对我来讲是个特殊的日子。这一天是我离开生活了5年的北京，重新踏入另一个城市的日子，也意味着全新生活即将从此拉开序幕。 &emsp;&emsp;是的，我也离开了万众瞩目的首都，成为”逃离北上广“的一员了，不同于多数人回到自己熟悉的家乡发展，我选择了离家更远的成都。至于理由，我想每个人都不同。 &emsp;&emsp;一个人拖着行李走出偌大的机场，回想五年前一个人出了北京的火车站，面临一段即将开始的新生活，不同的是另一个城市，可同样的还是我一人，虽有点触景生情般，无奈也只能整理脚步去迎接…… &emsp;&emsp;离开，是一种无奈。 &emsp;&emsp;我是万千北漂群体中的一员，在这里寻求更多的资源和更广阔的天空，希望在这片天空下开拓自己的眼界和寻求更好的发展，这座城市的魅力之一，只要自己想要什么，她就能最大限度提供。从刚开始到现在结束，无论何时，有人问我：你后悔来北京么？我的回答从来没有变过：不后悔！我很幸运在人生最需要奋斗的年纪来了这里，从刚踏入这片土地的朦胧无知的青涩少年犹如海绵一样吸收着所有，逐渐成长为一个有着自己见解，有独立担当的一个成人，对于自己当初来的目的，我可以拍着胸脯回答：我及格了！当然成长肯定不止是这些，伴随成长带来的喜悦同事而来的还有更多的社会责任和义务，早已不能再有当初的冲动和鲁莽，也许这就是世人眼里所谓的“成熟”吧，想要反抗些什么，发觉会被某些”线”操纵的更多，在这里，是得明白自己到底想要什么，想成为个什么样的人，我觉得这个在我们这个年纪比挣钱更加重要，人生毕竟才刚开始不久，总有些能让人用某种走完人生全程的信念值得去竖立和追求吧 &emsp;&emsp;伴随这成熟而来的还有一些显而易见的社会属性变化，当开始逐渐步入中年，考虑的问题不单单是自己，还有家人，另一半（当然前提得有）以及这个年纪都会有的问题等等。房价，就成了首个必须考虑的问题。从08年开始，帝都的房价就乘坐上了高速快轨，只升不降的一路飙升，当想在这个城市有个自己的小家的时候发觉力不从心，有心期待稍微调控可以勉强买上的时候发觉哀莫大于心死，各种房价的数字触目惊心，在这个城市有个属于自己的小窝已遥不可及。 &emsp;&emsp;当然我们中的还是有能力出众的，在这安了自己的家，但多数都在离主城相对远一点的聚集地，房子买的远自然上班通勤成了又一个无法回避的问题，动辄1-2小时的单趟通勤成本已是常态，如果不想面对，那离上班近的主城的房价又是跨不过去的坎。而对于我，我曾尝试在之前的一个多小时的通勤时间上看书，来争取在这个时间做一点事情，可是长久的这个状态无疑是牺牲掉了全部属于生活上的时间，起床上班，下班回家睡觉已成了这个群体的生活状态。而我，这样的生活我不要，所以宁可住的贵，也要离得近，留给自己一部分时间好好经营生活，我始终固执的认为没有愉悦的生活，那么工作也没法全力以赴，所以对于我这样的普通大众对于这个社会常态要么接受，要么离开….. &emsp;&emsp;离开，也许是另一种精彩 &emsp;&emsp;北上深高昂的房价已让想留下来的人不堪重负，面对这样的压力，何不及时调转船头去追寻另一种自己想要的生活。而我，只是在还能有选择的时候迈出了这一步。 &emsp;&emsp;成都，一座世界美食之都 &emsp;&emsp;成都，一座历史名城 &emsp;&emsp;成都，一座旅游城市 &emsp;&emsp;成都，一座适宜居住的城市 &emsp;&emsp;成都，一首《成都》下的城市 &emsp;&emsp;关于这座城市的故事从来不绝于耳，此时轻装上阵的我带着莫名的兴奋和探索的心情感受她的一切，一切的精彩生活也正在悄然上演……]]></content>
      <categories>
        <category>在路上</category>
      </categories>
      <tags>
        <tag>离京，脱离北漂</tag>
        <tag>成都</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vagrant 做测试环境的一点总结(下)]]></title>
    <url>%2Fnote%2Fdjango_vagrant-%E5%81%9A%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%BB%E7%BB%93(%E4%B8%8B).html</url>
    <content type="text"><![CDATA[生活不会因为某个节点而变得与众不同，未来的幸运，都是过往努力的积攒。 vagrant 是我在本地 osx 系统下做测试环境时候开始研究的，以前只是单一的用 vbox 装个本地虚机时并没有发觉用或者不用有什么差别，但随着本地开始有一些特殊需求的时候，才发觉 vagrant 提供的功能还是很值得称赞的。 provisioning 类似于开机启动，可以开机执行某个命令，可以执行某个脚本都可以 比如我想在开机后自动安装某个包，同步下时间，那么如果是 vbox 的虚机可能你得连到虚机里，然后在/etc/rc.local下写上命令等等，但在 Vagrantfile 里，可以直接以配置的形式体现，下面这段是配置里自带的一段，开机自动更新包，安装 Apacheconfig.vm.provision "shell", inline: &lt;&lt;-SHELL apt-get update apt-get install -y apache2SHELL 所以只要把中间那部分换成自己的命令就好，但是如果命令太长，还有逻辑判断，最好是开机执行个脚本，那在配置文件里应该这样写 config.vm.provision :shell, path: "&lt;scriptname.sh&gt;" 注意这里的路径是以Vagrantfile所在的目录为根目录的，上述的写法，脚本就必须存放在和 Vagrantfile同级就可以 vagrant 创建集群如果是 vbox 或者是 VMware 的话，模拟一个集群方法就是多建几个虚机环境，然后打通内网，无论是 clone 还是新建都还挺麻烦的，但是 vagrant 靠一个配置文件就可以完成，这里直接引用 go-best-practice 里的这段话 Vagrant支持单机模拟多台机器，而且支持一个配置文件Vagrntfile就可以跑分布式系统。这种多机器模式特别适合以下几种人： 快速建立产品网络的多机器环境，例如web服务器、db服务器 建立一个分布式系统，学习他们是如何交互的 测试API和其他组件的通信 容灾模拟，网络断网、机器死机、连接超时等情况 现在我们来建立多台VM跑起來，並且让他们之间能够相通信，假设一台是应用服务器、一台是DB服务器，那么这个结构在Vagrant中非常简单，其实和单台的配置差不多，你只需要通过config.vm.define来定义不同的角色就可以了，现在我们打开配置文件进行如下设置： Vagrant.configure("2") do |config| config.vm.define :web do |web| web.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "web", "--memory", "512"] end web.vm.box = "base" web.vm.hostname = "web" web.vm.network :private_network, ip: "11.11.1.1" end config.vm.define :db do |db| db.vm.provider "virtualbox" do |v| v.customize ["modifyvm", :id, "--name", "db", "--memory", "512"] end db.vm.box = "base" db.vm.hostname = "db" db.vm.network :private_network, ip: "11.11.1.2" endend 这里的设置和前面我们单机设置配置类似，只是我们使用了:web以及:db分別做了两个VM的设置，并且给每个VM设置了不同的hostname和IP，设置好之后再使用vagrant up将虚拟机跑起来： 再次启动并连接，连接并需要指定角色即可$ vagrant up$ vagrant ssh webvagrant@web:~$$ vagrant ssh dbvagrant@db:~$ 批量生成机器 上面的情况适合于想建立个小集群，用于特定的环境，而现在有个需求想一次性生成10台机器，用上面的方法就略显复杂了，得写一大串配置文件，显得臃肿，不过 vagrant 也提供了特定的方式 以下这个配置来源于 https://jacobustczhi.gitbooks.io/-vagrant/content/chapter.htmlVagrant.configure("2") do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://atlas.hashicorp.com/search. (0..10).each do |i| config.vm.define "node#&#123;i&#125;" do |node| # 设置虚拟机的Box node.vm.box = "ubuntu/trusty64" # 设置虚拟机的主机名 node.vm.hostname="node#&#123;i&#125;" # 设置虚拟机的IP node.vm.network "public_network", bridge: "eno1", ip: "192.168.17.20#&#123;i&#125;" # VirtaulBox相关配置 node.vm.provider "virtualbox" do |v| v.name = "node#&#123;i&#125;" v.memory = 1024 v.cpus = 1 end end if ARGV[0] == "up" &amp;&amp; ! File.exist?("./disk1.vdi"） # 运行脚本增加swap空间 config.vm.provision "shell", path: "increase_swap.sh" end endend 可以看到，与创建单个虚拟机相比，这里多了层循环,而变量 i 可以用于设置节点的名称与IP，使用#{i}取值： (0..10).each do |i| end plugin 根据网友KiwenLau的文章里提到了一个错误 VirtualBox 设置共享目录时需要在虚拟机中安装VirtualBox Guest Additions，这个 Vagrant会自动安装。但是，VirtualBox Guest Additions是内核模块，当虚拟机的内核升级之后，VirtualBox Guest Additions会失效，导致共享目录挂载失败，出错信息如下: Failed to mount folders in Linux guest. This is usually becausethe “vboxsf” file system is not available. Please verify thatthe guest additions are properly installed in the guest andcan work properly. The command attempted was:mount -t vboxsf -o uid=id -u vagrant,gid=getent group vagrant | cut -d: -f3 vagrant /vagrantmount -t vboxsf -o uid=id -u vagrant,gid=id -g vagrant vagrant /vagrantThe error output from the last command was:stdin: is not a tty/sbin/mount.vboxsf: mounting failed with the error: No such device 安装 Vagrant 插件vagrant-vbguest可以解决这个问题，因为该插件会在虚拟机内核升级之后重新安装VirtualBox Guest Additions。$ vagrant plugin install vagrant-vbguest &emsp;&emsp; 参考阅读 KiwenLau]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>vagrant 实用技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vagrant 做测试环境的一点总结(上)]]></title>
    <url>%2Fnote%2Fdjango_vagrant-%E5%81%9A%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%BB%E7%BB%93(%E4%B8%8A).html</url>
    <content type="text"><![CDATA[既然还在幸运的活着，当然要全力以赴的快乐。 “Vagrant uses Oracle’s VirtualBox to build configurable, lightweight, and portable virtual machines dynamically.” Vagrant 是 Mitchell Hashimoto 用 ruby 写的，去年11月份，Mitchell 专门成立了一个公司 HashiCorp 来更好的开发 Vagrant, 并且申明，Vagrant会一直开源。Announcing HashiCorp感兴趣的还可以看下作者在就HashiCorp成立在Hacker News上发的一个 topic vagrant 是什么Vagrant 提供了基于企业级标准技术的易配置、可重复、可移植的工作环境，从而最大化团队的生产力和灵活性。 Vagrant 可构建在由 VirtualBox，VMware，AWS 以及其他提供商提供的机器上，并且可以使用 shell 脚本，Chef，Puppet 等配置管理工具。 vagrant 的特点: 将配置和依赖隔离在一次性和一致性的环境中 使用简单，只需 Vagrantfile 和 vagrant up，适用人群广(开发者，运维人员，设计师) vagrant 其实就是封装了的 Virtualbox 的 API 的 ruby DSL，抽象和简化了某些操作，用一个命令以及配置文件，而不是一堆命令去管理和使用 vm。 更多关于 vagrant 的介绍，网上比较多，这里就不在阐述，有兴趣的可以读一下 Go实战开发 这本书里关于 vagrant 的介绍，已经很详细了，我就简单的介绍点常用的即可 基础1、基本命令# 查看帮助$ vagrant list-commands -v, --version -h, --help # 把镜像加入到 vagrant 中$ vagrant box add "centos-6.6-x86_64 py27" vagrantbox/centos-6.6-x86_64.box# 查看 vagrant 环境$ vagrant box listcentos-6.6-x86_64 py27 (virtualbox, 0)# 初始化一个新的仓库$ cd test_env$ vagrant init "centos-6.6-x86_64 py27"A `Vagrantfile` has been placed in this directory. You are nowready to `vagrant up` your first virtual environment! Please readthe comments in the Vagrantfile as well as documentation on`vagrantup.com` for more information on using Vagrant.会在当前目录下生成一个 Vagrantfile 这个配置文件 2、下面贴个常见配置,修改 Vagrantfile 文件config.vm.box = "centos-6.6-x86_64 py27"config.vm.network "forwarded_port", guest: 8000, host: 8000config.vm.network "forwarded_port", guest: 3306, host: 9999config.vm.synced_folder ".", "/vagrant" # 将当前目录映射到虚拟机上的/vagrant 目录config.vm.hostname = "devops-node1"config.vm.provider "virtualbox" do |vb| # Display the VirtualBox GUI when booting the machine # vb.gui = true # Customize the amount of memory on the VM: vb.memory = "1024" vb.cpus = 1end 3、服务管理# 启动，重载，关机$ vagrant up$ vagrant reload重新读取配置$ vagrant halt将虚拟机关闭，虚拟机内存释放，下次启动要慢一点。$ vagrant suspend将虚拟机挂起，虚拟机内存都保存到硬盘上，下次可以快速恢复$ vagrant destroy将虚拟机删除，所有变更都丢失，下次启动要重新克隆一个 Vagrant box。$ vagrant status查看虚拟机的状态 更多命令行：https://www.vagrantup.com/docs/cli/index.html 制作模板 当做好基础的环境后，方便打包发送给其他人和方便以此为模板衍生其他环境，所以需要对这个环境进行打包，形成模板 $ VBoxManage list vms"win10" &#123;f0fa02e2-48ca-439f-bfca-0e4ddb138485&#125;"centos6.5-node1" &#123;57e5500f-e91b-469e-86c9-f0b90b2a01a8&#125;"env_default_1488966927566_38686" &#123;16817773-c844-4412-af8d-df89bae489ca&#125; 1、打包基础环境$ vagrant package --base env_default_1488966927566_38686 --output centos66-base.box/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777==&gt; env_default_1488966927566_38686: Attempting graceful shutdown of VM... env_default_1488966927566_38686: Guest communication could not be established! This is usually because env_default_1488966927566_38686: SSH is not running, the authentication information was changed, env_default_1488966927566_38686: or some other networking issue. Vagrant will force halt, if env_default_1488966927566_38686: capable.==&gt; env_default_1488966927566_38686: Forcing shutdown of VM...==&gt; env_default_1488966927566_38686: Clearing any previously set forwarded ports...==&gt; env_default_1488966927566_38686: Exporting VM...==&gt; env_default_1488966927566_38686: Compressing package to: /Users/song/Downloads/vagrant/env/centos66-base.box 2、还原基础环境 到此打包到封装好的环境就在当前目录下生成了，下次用这个模板重新开始初始化新环境就非常容易了 # 拷贝打包好的镜像到其他小伙伴的机器，或者共享目录# 在本地导入并重新启动一个环境$ vagrant box add "template_centos66" centos66-base.box/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777==&gt; box: Box file was not detected as metadata. Adding it directly...==&gt; box: Adding box 'template_centos66' (v0) for provider: box: Unpacking necessary files from: file:///Users/song/Downloads/vagrant/centos66-base.box==&gt; box: Successfully added box 'template_centos66' (v0) for 'virtualbox'!$ vagrant box listcentos-6.6-x86_64 py27 (virtualbox, 0)template_centos66 (virtualbox, 0)$ mkdir test_env$ cd test_env$ rm -rf Vagrantfile$ vagrant init template_centos66A `Vagrantfile` has been placed in this directory. You are nowready to `vagrant up` your first virtual environment! Please readthe comments in the Vagrantfile as well as documentation on`vagrantup.com` for more information on using Vagrant.$ vagrant up/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777Bringing machine 'default' up with 'virtualbox' provider...==&gt; default: Importing base box 'template_centos66'...==&gt; default: Matching MAC address for NAT networking...==&gt; default: Setting the name of the VM: test_env_default_1489043027159_6542==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2222 (host) (adapter 1)==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... 3、测试完毕，销毁测试环境$ vagrant destroy/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777 default: Are you sure you want to destroy the 'default' VM? [y/N] y==&gt; default: Destroying VM and associated drives... 出现的错误 这里出现的错误主要在迁移的过程中，如果只是安装部署中出现错误，多数应该是配置文件Vagrantfile的语法错误，我这里先描述下错误出现的背景 – default: Warning: Authentication failure. Retrying…1、当我打包一个系统镜像为模板的时候，想根据这个模板生成新的 vagrant 系统，所以有如下操作$ vagrant package --base env_default_1488966927566_38686 --output centos66-base.box$ vagrant box add "template_centos66" centos66-base.box$ mkdir test_env$ cd test_env$ vagrant init template_centos66适当修改 Vagrantfile，然后启动$ vagrant up 如果一切正常，则会产生一个新的 vagrant 虚拟环境，但这里会报错$ vagrant up/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777Bringing machine 'default' up with 'virtualbox' provider...==&gt; default: Clearing any previously set forwarded ports...==&gt; default: Fixed port collision for 22 =&gt; 2222. Now on port 2200.==&gt; default: Clearing any previously set network interfaces...==&gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat==&gt; default: Forwarding ports... default: 22 (guest) =&gt; 2200 (host) (adapter 1)==&gt; default: Running 'pre-boot' VM customizations...==&gt; default: Booting VM...==&gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2200 default: SSH username: vagrant default: SSH auth method: private key default: Warning: Authentication failure. Retrying... default: Warning: Connection refused. Retrying... default: Warning: Authentication failure. Retrying... ... 一直卡在这里无法过去，然后根据错误 google 找了下，在 vagrant 的 github 的 issue 里找到了有人提出了这个问题，根据里面的回答，我做了如下尝试 1、升级 vagrant 和 vbox ，确保都是最新版，怕有人提到的因为版本不匹配导致的原因，报错依旧 2、根据 @kikitux 这个哥们在 5 Mar 2015 的回答 Adding here my impressions for people that find this issue from google/internet: This is my point of view here. The source box use the insecure keyby default the actual version of vagrant will remove it, to make it securethe new box, use a generated pair key.. that is not being used anymorevagrant can’t connect to the new box. You have 3 options here. A. Tell vagrant in the middle box to NOT create a new safe/secure pair.B. Run an Script before packaging to delete 70-persistent-net.rulesand put back the insecure pair keyC. Copy the new now secure pair to /vagrant and include it in thepackage box plus Vagrantifle conf to use it I will say, if this is for prototyping, just use A, just rememberdelete 70-persistent-net.rules On the first box, add:config.ssh.insert_key = false 我在 Vagrantfile 里新增了config.ssh.insert_key = false这个配置，发觉无果，报错依旧 3、issue 上 @mtchavez 的回答得到了多数人的支持，很多人用了他的方法解决了问题 I had found a solution to this and haven’t had time to update this issue. I did something similar to what @dylanschoenmakers described. The main thing which fixed it for me was adding the vagrant.pub to the authorized_keys with wget https://raw.githubusercontent.com/mitchellh/vagrant/master/keys/vagrant.pub -O .ssh/authorized_keyschmod 700 .sshchmod 600 .ssh/authorized_keyschown -R vagrant:vagrant .ssh Then when building the base box I think you need to add the config.ssh.insert_key = false to your Vagrantfile. If you built a new version of the box you can simply do a vagrant box update otherwise you can do what @dylanschoenmakers already mentioned to remove and re-add the box to get the newest box. This all makes sense, but I am not clear on if this is something that needs to be documented or if there was indeed a change in Vagrant that used to do this transparently for previous versions which is broken now. 他其实做的方法和 @dylanschoenmakers 类似a、首先在 Vagrantfile 中增加了这段config.ssh.insert_key = falseb、其次在连接 vagrant 的 ssh-config 配置$ vagrant ssh-config/opt/vagrant/embedded/gems/gems/vagrant-1.9.2/lib/vagrant/util/platform.rb:24: warning: Insecure world writable dir /usr/local in PATH, mode 040777Host default HostName 127.0.0.1 User vagrant Port 2200 UserKnownHostsFile /dev/null StrictHostKeyChecking no PasswordAuthentication no IdentityFile /Users/song/.vagrant.d/insecure_private_key IdentitiesOnly yes LogLevel FATAL这里的 IdentityFile 在基于模板创建新的 vagrant 虚机环境的时候 ssh 连接使用的 key，所以 @dylanschoenmakers 用了一个新的内容替换原有的内容ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA6NF8iallvQVp22WDkTkyrtvp9eWW6A8YVr+kz4TjGYe7gHzIw+niNltGEFHzD8+v1I2YJ6oXevct1YeS0o9HZyN1Q9qgCgzUFtdOKLv6IedplqoPkcmF0aYet2PkEDo3MlTBckFXPITAMzF8dJSIFo9D8HfdOV0IAdx4O7PtixWKn5y2hMNG0zQPyUecp4pzC6kivAIhyfHilFR61RGL+GPXQ2MWZWFYbAGjyiYJnAmCP3NOTd0jMZEnDkbUvxhMmBYSdETk1rRgm+R4LOzFUGaHqHDLKLX+FIPKcF96hrucXzcWyLbIbEgE98OHlnVYCzRdK8jlqm8tehUc9c9WhQ== vagrant insecure public keyc、再次重新打包环境 而我的解决方案并不和上述一样，我查看了下 ssh-config 配置# 第一个正常连接的 vagrant 环境的配置$ vagrant ssh-configHost default ...... IdentityFile /Users/song/Downloads/vagrant/env_django/.vagrant/machines/default/virtualbox/private_key ......# 登录异常的基于模板产生的 vagrant 环境$ vagrant ssh-configHost default ...... IdentityFile /Users/song/.vagrant.d/insecure_private_key ...... 这里只贴出了不同的部分，所以我的想法就是把这个连接秘钥用正常环境的那个秘钥是否可以解决，所以在问题环境的 Vagrantfile 里增加如下配置 config.ssh.private_key_path = “/Users/song/Downloads/vagrant/env_django/.vagrant/machines/default/virtualbox/private_key” 再次启动虚拟环境，发觉再无报错，至此问题解决 另外好像还有个解决办法， 就是不指定用 key 连接，而是直接使用密码连接，虽然暴力，但是的确提供了一种思路config.ssh.username = "vagrant"config.ssh.password = "vagrant" –warning: Insecure world writable dir /usr/local in PATH, mode 040777 曾经为了方便，改过 osx 下这个目录权限，现在操作 vagrant 都会报这个警告，修改权限如下即可 $ sudo chmod go-w /usr/local/ &emsp;&emsp; 参考阅读 官网 “Warning: Authentication failure. Retrying… “ after packaging box #5186 部署 学习 Vagrant]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>vagrant</tag>
        <tag>vagrant 多虚拟机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django reverse vs reverse_lazy]]></title>
    <url>%2Fnote%2Fdjango-reverse-vs-reverse-lazy.html</url>
    <content type="text"><![CDATA[这个世界上有很多好人。如果你找不到，就让自己成为一个。 &emsp;&emsp;上一篇里分析了django url 里 name、namespace、app_name 的用途，但是上一篇里也提到了反向解析用在了 template 里，而在 python 代码里没有过多的体现，今天看到 CHENG’S BLOG 博客，容易理解，遂转载之。 现在定义了一个 urlurlpatterns = [ url(r'^$', views.IndexView.as_view(), name='index'),] 当然了，如果我想在 template 里使用的话可以如下&lt;h1&gt; &#123;% url 'index' %&#125; &lt;/h1&gt; 现在后端有下面这段代码from django.core.urlresolvers import reverseclass UserProfileView(FormView): template_name = 'profile.html' form_class = UserProfileForm success_url = reverse('index') 如果运行，会报如下错django.core.exceptions.ImproperlyConfigured: The included urlconf 'config.urls' does not appear to have any patterns in it. If you see valid patterns in the file then the issue is probably caused by a circular import. 根据 CHENG’S BLOG 里的介绍，有两种方式解决这个问题。方法一： from django.core.urlresolvers import reverse_lazy class UserProfileView(FormView): template_name = 'profile.html' form_class = UserProfileForm success_url = reverse_lazy('index') # use reverse_lazy instead of reverse 方法二：from django.core.urlresolvers import reverseclass UserProfileView(FormView): template_name = 'profile.html' form_class = UserProfileForm def get_success_url(self): # override this function if you want to use reverse return reverse('index') 单单从代码上看，reverse_lasy要方便很多。根据 Django’s document 上的描述，reverse_lazy当项目里的URLConf未加载时用来取代 reverse。reverse_lasy可以用在以下几个场景 在 class-based view 中用 reversed url. (上述方法一) 装饰器中使用 reversed url (例如装饰器 django.contrib.auth.decorators.permission_required() 中 login_url 参数). 函数参数的默认值中的 reversed url 最后看了下两者的源码，看的一知半解，但是如下源码中 # reversedef reverse(viewname, urlconf=None, args=None, kwargs=None, prefix=None, current_app=None): ......# reverse_lazyreverse_lazy = lazy(reverse, six.text_type) 可以看到reverse_lasy是reverse的一层封装，这样我就可以用reverse_lazy可以用在任何reverse的场景里，而且不用担心出错，所以 have a try~ &emsp;&emsp; 参考阅读 CHENG’S BLOG]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django reverse</tag>
        <tag>reverse_lazy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 的行话术语大全]]></title>
    <url>%2Fnote%2Fpython-%E7%9A%84%E8%A1%8C%E8%AF%9D%E6%9C%AF%E8%AF%AD%E5%A4%A7%E5%85%A8.html</url>
    <content type="text"><![CDATA[读一些无用的书，做一些无用的事，花一些无用的时间，都是为了在一切已知之外，保留一个超越自己的机会，人生中一些很了不起的变化，就是来自这种时刻。 python 中有些术语还是知道的比较好，像沉浸其中的老鸟可能张嘴就是术语，像我这类新人刚入总会被术语弄的云里雾里，网上看到这篇文章，转载过来，加深学习 ABC(计算机语言) 是由 Leo Geurts, Lambert Meertens 和 Steven Pemberton 创建的一种编程语言。开发了 Python 的 Guido van Rossum，在 20 世纪 80 年代曾以程序员的身份实现了 ABC 的环境。块由缩进来组织，内置元组和字典，元组拆分，for 循环语义，以及对所有序列化类型的一致处理等这些 Python 的鲜明特性都借鉴自 ABC。 Abstract base class(ABC) 一个不能被实例化，只能被子类化的类。Python 中的接口由 ABC 形式化表示。除了可以继承一个 ABC 外，类也可以通过注册成一个 ABC 的虚拟子类来声明实现了某个接口。 accessor 一个实现了可用于访问单个数据属性的方法。一些开发者将 accessor 作为一个通用术语使用，即包含 getter 和 setter 方法，而另一些开发者使用时只表述 getter，setter 表述为 mutator。 aliasing 为相同的对象分配两个或多个名字。例如，在 a = []; b = a 这个例子中，变量 a 和 b 都是同一个列表对象的别名。在任何一种变量用于存储对象引用的语言中，别名会很自然地发生。为避免混淆，只需忘掉变量是保存对象的盒子这样的想法（一个对象不能同时保存在两个盒子中）。最好将它们理解成是贴在对象上的标签（一个对象可以有多个标签）。 argument 指调用一个函数时，所传递的一个表达式。在 Python 中，argument 和 parameter 几乎就是同义词。关于这两个术语的区别和使用方法的更多信息，见术语 parameter。 attribute 方法和数据属性(如 Java 术语中的 “fields” 等）在 Python 中都被称作属性。方法也是一个属性，只不过这个属性恰好是一个可调用对象（通常是一个函数，但不是必需的）。 BDFL Benevolent Dictator For Life，是 Python 语言的创造者 Guido van Rossum 的别称。 binary sequence 一个用于表述含有字节元素的序列化类型的通用术语。内置的二进制序列类型有 byte，bytearray 和 memoryview。 BOM Byte Order Mark（字节序标识符），该字节串可能会出现在以 UTF-16 编码的文件的开头处。一个 BOM 就是字符 U+FEFF(ZERO WIDTH NO-BREAK SPACE)，它编码后在大数端的 CPU 上生成 b’\xfe\xff’，在小数端的 CPU 上生成 b’\xff\xfe’。因为 Unicode 中没有 U+FFFE 这个字符，因此一旦出现该字节串就能明确判断出该编码使用的字节序。可能有点多余，但在 UTF-8 文件中可能会找到编码成 b’\xef\xbb\xbf’ 的 BOM。 bound method 一个需要通过实例访问的方法，因为它被绑定到了那个实例。任何一个方法实际上都是一个描述子 descriptor(实现了 get)，当被访问时，它将自身封装到一个对象中，该对象将方法绑定到实例。该对象就是一个绑定方法。调用它可以不用传递 self 值。例如，通过以下赋值 my_method = my_obj.method，该绑定函数以后可以通过 my_method() 调用。 build-in function(BIF) 一个与 Python 解析器捆绑的函数，它使用低层实现语言编写（例如，CPython 用的 C; Jython 用的 Java 等等）。该术语通常只表述那些无需导入就能使用的函数。但是内置模块如 sys, math, re 等也含有内置函数。 byte string 很不幸 Python 3 中仍然还用这个名字表示 bytes 和 bytearray。在 Python 2 中， str 类型实际上是一个字节字符串，因此使用该术语将 str 字符串和 unicode字符串进行区分是说得通的。而在 Python 3 中还坚持使用这个术语就没有意义了，Python 3 中最好用 byte sequence 表述。 bytes-like object 一个通用的字节序列。最常见的 bytes-like 类型是 bytes, bytearray 和 memoryview。但是其它支持低层 CPython buffer 协议的对象，如果它们的元素都是单字节的话，也有符合条件的。 callable object 一个可以通过调用操作符 () 进行调用的对象，它能返回一个结果或者执行某些操作。在 Python 中有七种可调用对象: 用户定义的函数，内置函数，内置方法，实例方法，生成器函数，类，实现了 call 特殊方法的类实例。 CamelCase 标识的一种写法约定：相连的每个词首字母都大写（如 ConnectionRefusedError）。PEP-8 建议类名应该以 CamelCase 约定命名，但是 Python 的标准库并没有遵循这个建议。见 snake_case 术语。 CheeseShop Python Package Index(PyPi) 的原名，以 Monty Python 剧中的奶酪店命名。目前 https://cheeseshop.python.org 仍然可访问。 见 PyPI 术语。 class 一种用于定义新类型的程序结构，它具有数据属性和可在其上进行某些操作的方法。见 type 术语。 code point 0 到 0x10FFFF 区间内的一个整数，用于标识 Unicode 字符数据库中的一个记录。在 Unicode 7.0 中，只有不到 3% 的代码点被分配了字符。在 Python 文档中，该术语可能有两种表述。例如， chr 函数说需要一个整数 “code point”，而其相应的 ord 函数，描述为返回一个 “Unicode code point”。 code smell 表明该程序设计可能会有问题的一种代码编写模式。例如，过度使用 isinstance 来检查具体类就是一种 code smell，因为它使程序在将来难以扩展以应对新的类型。 codec (encoder/decoder)，一个具有编码和解析函数的模块，通常用于进行 str 和 bytes 间的相互转换，虽然 Python 也有几个 codecs 可以用于执行 bytes 到 bytes，以及 str 到 str 的转换。 collection 一种通用术语，用于表述这类数据结构：它由多个项组成，并且项能被单独存取。 一些 collection (集合) 可以包含任意类型的对象（见 container 术语），而另一些只能包含一种简单原子类型的对象（见 flat sequence 术语）。list 和 bytes 都是集合， 但是 list 是一个 container，而 bytes 是一个 flat sequence。 considered harmful Edsger Dijkstra 的一封名叫 “Go To Statement Considered Harmful” 的信为那些批评某种计算机科学技术的论文标题建立了一种范式。Wikipedia 上的 “Considered harmful” 文章 举了一些例子，包括由 Eric A. Meyer 写的 “Considered Harmful Essays Considered Harmful”。 constructor 非正式地，类中的 init 实例方法被称为构造器，因为它的语义和 Java 的构造器非常相似。但是，init 更恰当的名字应该叫初始化器，因为它实际上并没有构造该实例，它只是接收这个实例为自己的 self 参数。constructor 这个术语用于描述类中的 new 方法会更好，Python 在调用 init 前调用该方法，它实际上负责创建并返回实例对象。见 initializer 术语。 container 一个能保存其它对象的引用的对象。Python 中的大多数 collection 类型都是容器，但有些不是。例如 flat sequence，它是 collection，但不是 container。 context manager 一个实现了 enter 和 exit 这两个特殊方法的对象，用于 with 块中。 coroutine 一个用于并行程序开发的 generator(生成器)，该生成器通过 coro.send(value) 从一个 schedulere (调度器) 或 event loop (事件循环器) 中获取数值。该术语可用于描述 generator function (生成器函数)，也可以描述通过调用生成器函数所获得的 generator object (生成器对象)。见 generator 术语。 CPython 标准 Python 解析器，用 C 实现。该术语只在以下情况下使用：讨论特定于某种实现的特性时，或讨论 PyPy 等有多种可用 Python 解析器时。 CURD 即 Create, Read, Update 和 Delete 的字母缩写，它们是任何数据存储型应用系统的四个基本功能。 decorator 一个可调用对象 A，调用能返回另一个可调用对象 B，对 A 的调用要在一个可调用对象 C 的定义体前使用语法 @A 进行。当碰到这种代码时，Python 解析器调用 A(C) 并将结果 B 绑定到之前分配给 C 的变量，从而事实上将 C 的定义替换成了 B。如果该目标可调用对象 C 是一个函数，那么 A 就是一个函数装饰器;如果 C 是一个类，那么 A 就是一个类装饰器。 deep copy 拷贝一个对象时，对象中的所有属性自身也被拷贝。对比 shallow copy。 descriptor 一个实现了 get, set, delete 这三个特殊方法中的一个或多个方法的类，当它的一个实例成为了另一个类（即 managed class， 受管理类) 的类属性时，即成为一个 descriptor (描述子)。描述子对受管理类中的受管理属性的存取和删除操作进行管理，并通常将数据保存到 managed instance (受管理实例）中。 docstring 即 documentation string 的简写。当一个模块、类或函数中的首行语句是一个字符串时，Python 会将该字符串作为该对象的 docstring，并保存到该对象的 doc 属性上。见 doctest 术语。 doctest 是一个模块，它包含一些函数用于解析和运行嵌在 Python 模块的 docstring 中或纯文本文件中的示例代码。也可以在命令行中这样使用: python -m doctest module_with_tests.py DRY Don’t Repeat Yourself–一种软件工程原则，它表述为 “Every piece of knowledge must have a single, unambiguous, authoritative representation within a system”。它最先出现在 Andy Hunt 和 Dava Thomas 写的 《The Pragmatic Programmer》(Addison-Wesley, 1999) 中。 duck typing 多态的一种形式: 函数可作用于任何实现了特定方法的对象上，而不需要考虑它们的类或者显式接口声明。 dunder double underscores 的简写，用于简化那些前后带有双下划线的特殊方法和属性名的发音（如 len 读作 “dunder len”)。 dunder method 见术语 dunder 和 special methods 。 EAFP 是 “It’s easier to ask forgiveness than permission” 的缩写，它源于计算机先驱 Grace Hopper，Python 开发人员引用它来阐述这样的动态编程实践: 对属性的存取都可假定属性是存在的，因而不必进行事先测试，如果不存在的话，只需捕获相关异常即可。hasattr 函数的 docstring 实际上这样描述它的工作原理: “通过调用 getattr(object, name) 并捕猎 AttributeError。” eager 一个 iterable object (可迭代对象），它会立马构建出其所有的元素。在 Python 中，一个 list comprehension (列表推导器) 是一个 eager。相较于 lazy。 fail-fast 一种系统设计原则，它建议错误应该尽早汇报。相比于大部分动态语言，Python 更加遵循该原则。例如，它没有 “undefined” 值: 变量没有初始化前一旦P被引用就会产生错误，并且 my_dict[k] 时当 k 不存在时会抛出异常 (相较于 JavaScript)。另一个例子，Python 中通过元组拆分进行的并行赋值只有当元组中的每个元素都匹配时才能进行，而 Ruby 却是不声不响地处理了元素个数不匹配的情况: 忽略 = 右边没有使用的元素，或者将 nil 值赋给左边多余的变量。 falsy 表示任何一个值 x, 该值 x 当调用 bool(x) 时会返回 False; 在布尔上下文中，例如控制 if 或 while 循环的表达式中，Python 默认使用 bool 来计算对象值。它的相反的值是 truthy。 file-like object 在官方文档中非正式地用于表述实现了文件协议的对象，这些对象都有像 read, write, close 等方法。常见的变体有: 包含已编码字符串以便于面向行读写的文本文件，StringIO 实例–内存中的文本文件和包含未编码字节数据的二进制文件。后者可能有缓冲，也可能没有。标准文件类型自 Python 2.6 开始都定义在 io 模块中。 first-class function 编程语言中能作为 first-class object (一类对象) 的任何函数 (即可以在运行时创建，能赋值给变量，能作为参数传递，能作为另一个函数的返回值返回)。Python 函数都是一类函数。 flat sequence 一种序列类型: 它实际存储其元素的值，而不是存储到其它对象的引用。内置的类型如 str, bytes, bytearray, memoryview 和 array.array 等都是 flat sequence (简单序列)。而 list, tuple 和 collections.deque 都是 container sequence (容器序列)。见术语 container。 function 严格来说，是一个从 def 块或 lambda 表达式运行而来的对象。非正式地，function 这个词用于描述任何可调用对象，如方法、甚至有时也可以是类。官方的 内置函数 列表中也含有一些内置类，像 dict, range 和 str 等。见 callable object。 genexp generator expression 的缩写。 generator 一个由 generator function (生成器函数) 或 generator expression (生成器表达式) 构建的迭代器，它在产生值时无需遍历整个集合; 典型的例子是一个产生 Fibonacci 序列的生成器，由于该序列是无限的，因而不适合在存于一个集合中。该术语除了表述从生成器函数调用中返回的对象外，有时也用于表述该生成器函数本身。 generator function 一个在函数体中使用了 yeild 关键字的函数。当被调用时，generator function (生成器函数) 会返回一个 generator (生成器)。 generator expression 一种由括号包围的表达式，它使用和 list comprehension (列表推导式) 相同的语法，只不过它返回的不是列表，而是一个生成器。一个 generator expression (生成器表达式) 可以被理解成列表推导式的 lazy 版本。见术语 lazy。 generic function 指一组函数：它们意在以可定制的方式为不同的对象类型实现相同的操作。在 Python 3.4 中，functools.singledispatch 装饰器是创建 generic function (通用函数) 的标准方法。在其它语言中也叫做 multimethods。 GoF book 《Design Patterns: Elements of Resuable Object-Oriented Software》(Addison Wesley, 1995) 的别称。它的作者即所谓的四人帮: Erich Gamma, Richard Helm, Ralph Johnson 和 John Vlissides。 hashable 一个对象为 hashable 即指它同时含有 hash 和 eq 方法，并且有以下限制: 它的哈希值永远不会变且当 a == b 成立时 hash(a) == hash(b) 也必须为 True。大多数内置的不可修改类型都是 hashable 的，但是元组只有当其每个元素都 hashable 时才是 hashable 的。 higher-order function 指一个能接受另一个函数作为参数的函数，如 sorted, map 和 filter 等，或者指一个将函数作为返回值的函数，如 Python 装饰器。 idion “A manner of speaking that it natural to native speakers of a language”，摘自 Princeton WordNet。 import time 指一个模块初始化运行的时刻，此时模块代码被 Python 解析器加载，并从上到下进行运算，然后被编译成字节码。这是类和函数执行定义并变成活跃对象的时刻，也是执行装假器的时刻。 initializer 更适合 init 方法的名字(相较于 constructor 构造器)。init 的任务是初始化作为 self 参数接收来的实例。而实际的实例构建过程是由 new 函数完成的。见术语 constructor。 iteralbe 任何一个只要通过 iter 这个内置函数能获取一个 iterator (迭代器) 的对象。iterable object (可迭代对象) 可作为 for 循环、推导式和元组拆分时的元素源。那些实现了 iter 方法并返回一个迭代器的对象都是 iterable 的; 而其它实现了 getitem 方法的对象可能也是 iterable 的。 iterable unpacking tuple unpacking 的一个现代的，更加准确的同义词。见 parallel assignment。 iterator 任何一个实现了 next 方法的的对象，next 不接收参数，调用它时会返回序列中的下一个元素，或者当序列中已无元素时会抛出 StopIteration 异常。Python 的 iterator (迭代器) 也会实现 iter 方法，因而它们也是 iterable 的。经典的迭代器，根据原来的设计模式，是从集合中返回元素。generator (生成器) 也是一个迭代器，但是它更加灵活。见术语 generator。 KISS principle 即 “Keep It Simple, Stupid”。提倡寻求尽可能简单，稳定的解决方案。这句话是由 Kelly Johnson 提出的，Johnson 是一个天才的航空航天工程师，他在真正的 51 区工作，20 世纪的很多高级飞行器都是由他设计出来的。 lazy 一个按需产生元素的可迭代对象。在 Python 中，相较于 eager，生成器是 lazy 的。 listcomp list comprehension 的简写。 list comprehension 一种由方括号包围的表达式: 它使用 for 和 in 关键字，并对来自一个或多个可迭代对象中的元素进行处理和过滤，从而创建出一个列表。list comprehension (列表推导式) 是即时计算的，见术语 eager。 liveness 一个异步的、多线程的或者分布式的系统，当 “某些好事终会发生” (即虽然一些期望的计算现在还没有发生，但它最终会完成的) 时，即展现了它的 liveness (活性)。如果系统死锁了，那它就失去了它的活性。 magic method 同 special method。 managed attribute 一个由描述子对象管理的公共属性。虽然 managed attribute (受管理属性) 是在 managed class (受管理类) 中定义的，但是它操作起来像一个实例属性 (即它通常在每个实例中都有一个值，并保存在 storage attribute 中)。见术语 descriptor。 managed class 一个使用描述子对象来管理其至少一个属性的类。见术语 descriptor。 managed instance managed class 的一个实例。见 managed attribute 和 descriptor。 metaclass 一种其实例也是类的类。默认地，Python 的类是 type 的实例，例如，type(int) 返回类 type，因此 type 是一个 metaclass。用户自定义的 metaclass 可以通过继承 type 来创建。 metaprogramming 一种使用有关其自身的运行时信息来修改其行为的程序编写实践。例如，ORM 可能会检查数据模型类的声明来确定如何去验证数据库记录中的数据域，以及如何将数据库类型转换成 Python 中的类型。 monkey patching 在运行时动态地修改一个模块、类，或者函数，通常是为了添加功能和修正 Bug。因为它是在内存中实现的，并没有修改源代码，因此一个 monkey patch 只在当前运行的进程中有效。Monkey patch 破坏了封装性并且趋于和修复部分的实现细节紧密藕合，因此它们只被认为是临时的解决方法，不是代码集成的一种推荐技术。 mixin class 一种意在与一个或更多个类一起使用在多重类继承树的类。一个 mixin 类不能被初始化，mixin class 的具体子类也应该继承其它的非 mixin class。 mixin method 一个具体的方法实现: 该方法由一个 ABC 或 mixin class 提供。 mutator 见术语 accessor。 name mangling 自动将私有属性从 x 重命名为 _MyClassx 的过程，它由 Python 解析器在运行时执行。 nonoverriding descriptor 一种未实现 set 的描述子，因而不会干涉受管理实例上的受管理属性的设置过程。其结果是，如果受管理实例上设置了一个同名属性，将隐藏该实例上的描述子。也称作 nondata descriptor 或者 shadowable descriptor。相较于 overriding descriptor。 ORM Object-Relation Mapper–一种 API: 它以 Python 类和对象的形式提供访问数据库和记录的方式，提供方法调用来执行数据库操作。SQLAlchemy 是一个流行地独立 Python ORM; Django 和 Web2py 框架都有它们自己捆绑的 ORM。 overriding descriptor 一种实现了 set 的描述子，因而它会干预并覆盖在受管理实例上设置受管理属性的企图。也称为 data descriptor 或者 enforced descriptor。相较于 nonoverriding descriptor。 parallel assignment 用来将一个可迭代对象中的多个元素赋值给多个变量，使用像 a, b = [c, d] 这样的语法–也称为 destructing assignment (解构赋值)。这是 tuple unpacking (元组拆分) 的常见用法。 parameter 函数会声明成具有 0 到多个 “形式参数”，它们都是未绑定的本地变量。当函数被调用时，传递的参数或 “实参” 会绑定到这些变量。通常，arguemnt 指实参，而 parameter 指形参，但是 Python 文档和 API 中这两者都是混用的。见术语 argument。 prime (动词) prime 动词的含义是 “填充、事先准备好”，它在一个协程上调用 next(coro)，使其运行到首个 yeild 表达式处，从而使其能准备好接收由接下来的 coro.send(value) 调用发送的数值。 PyPI 即 Python Package Index，上面有超过 60,000 个包，也称作 Cheese shop (见术语 Cheese shop)。PyPI 发音为 “pie-P-eye”，以避免与 PyPy 混淆。 PyPy Python 编程语言的另一种实现，它所使用的工具链将 Python 的一个子集编译成了机器码，因此解析器的源代码实际上是用 Python 编写的。PyPy 还包含一个 JIT，用于将用户程序实时转换成机器码–像 Java VM 做的一样。截止 2014 年 12 月，根据 公布的评测数据，PyPy 平均比 CPython 快 6.8 倍。PyPy 发音为 “pie-pie”，以避免与 PyPI 混淆。 Pythonic 用于称赞符合语言习惯的 Python 代码，这些代码很好地利用了语言特性，从而显得简洁、易读，通常也更快。也用于表述 API，这些 API 使得熟练的 Python 程序员使用它们进行编程时显得很自然。 refcount 每个 CPython 对象在内部保存的引用计算器，以便决定它自身何时能被垃圾回收器回收。 REPL Read-Eval-Print Loop，一个交互式的控制台，例如标准的 python 或者其它的像 ipython, bpython 和 Python Anywhere 等。 sequence 某些可迭代数据结构的通用名字: 这些数据结构有已知的大小 (如 len(s)) 并且允许使用基于 0 的整数索引进行访问 (如 s[0])。sequence 一开始就是一个 Python 术语，但是直到 Python 2.6 它才正式地作为一个抽象类在 collections.abc.Sequence 中定义。 serialization 将一个对象从其内存结构转换成一个二进制或面向文本的结构，以便于存储或传输，它能使用的方式能便于以后在相同或不同的系统上重建该对象的一个克隆版本。pickle 模块支持将任意的 Python 对象序列化成一个二进制格式。 shallow copy 对象的拷贝版本与原对象共享属性对象的引用。相较于 deep copy。也见 aliasing。 singleton 一个对象是某个类的唯一存在的实例–通常不是偶尔引起的，而是有意设计该类以避免其能创建多个实例。有一个设计模式也叫 Singleton，是编写这种类的指南。Python 中的 None 对象就是一个 singleton (独子)。 slicing 通过使用切片表示法来生产某个序列的子集，比如 my_sequence[2:6]。Slicing (切片) 通常是通过复制数据来创建一个新的对象; 特别如 my_sequence[:] 会创建整个序列的一个 shallow copy (浅复制版本)。而一个 memoryview 对象通过切片生成的新 memoryview 对象能与源对象共享数据。 snake_case 标识的一种写法约定：用下划线 (_) 连接单词，例如 run_until_complete。PEP-8 称这种风格为 “单词都小写，并以下划线分隔” 并且推荐以它来命名函数，方法，参数和变量。而对于包，PEP-8 建议名字中的各名词直接相连接，不使用分隔符。Python 标准库中有很多 snake_case 型的标识例子，但是也有很多标识中的单词没有用分隔符 (例如 getattr, classmethod, isinstance, str.endswith 等)。见术语 CamelCase。 special method 具有特殊名字的方法，如 getitem，它的开头和结尾都有双下划线。 storage attribute managed instance (受管理实例) 中的一个属性，用于保存某个受描述子管理的属性值。 strong reference 该引用使被引用的对象在 Python 中一直保持活跃。相较于 weak reference。 tuple unpacking 将来自一个可迭代对象中的元素赋值给一组变量 (例如: first, second, third = my_list)。Python 开发人员一般都使用该术语，但是 iterable unpacking 也越来越受到青睐。 truthy 表示任何一个值 x, 该值 x 当调用 bool(x) 时会返回 True; 在布尔上下文中，例如控制 if 或 while 循环的表达式中，Python 默认使用 bool 来计算对象值。它的相反的值是 falsy。 type 它表述有关程序数据的每个特定类别，它通过一组可能值及可运用于其上的操作来定义。有些 Python type (类型) 与机器数据类型很接近 (如 float 和 bytes)，而其它的会有相应的扩展 (如 int 不受限于 CPU 的字大小，str 能保存多字节的 Unicode 数据点)，同时还有很高级的抽象类型 (如 dict, deque 等)。类型可以是用户自定义的，也可以是内置于解析器中的 ( 一个 “内置” 类型)。在 Python 2.2 之前，type/class 还没有统一起来，那时 type 和 class 是不同的实体，用户自定义的类无法对内置的类型进行扩展。而自 Python 2.2 后，内置类型和新型的类开始变得相互兼容，class (类) 成为了 type (类型) 的一个实例。而在 Python 3 中，所有类都是新型类。见 class 和 metaclass。 unbound method 一个实例方法如果直接通过类来访问就没有绑定到该实例上; 从而被称为是一个 “unbound method (未绑定的方法)”。要想顺利进行，对一个未绑定方法的调用必须显式地传递一个类的实例作为首个参数。那个实例将赋给该方法的 self 参数。见术语 bound method。 uniform access principle Bertrand Meyer, Eiffel 语言的创建者，写道: “All services offered by a module should be available through a uniform notation, which does not betray whether they are implemented through storage or through computation.” 属性和描述子使得在 Python 中能实现 uniform access principle (统一访问原则)。由于没有 new 操作符，调用函数和初始化对象看起来是一样的，这也是该原则的另一种形式: 调用者无需知道被调用对象是一个类、一个函数、或者是任何其它的可调用对象。 user-defined 在 Python 文档中 user 这个单词几乎总是指你和我–使用 Python 语言的程序员–相较于那些实现 Python 解析器的开发人员。因此术语 “user-defined class” 意指一个用 Python 编写的类，相较于内置的用 C 编写的类，比如说 str。 view Python 3 中的 view (视图) 指的是通过 dict 的 .keys(), .values() 和 .items() 方法返回的特殊数据结构，它无需进行数据复制，就能为我们提供一个关于 dict 键和值的一个动态视图，而在 Python 2 中，由于这些方法返回列表，因而有数据复制的过程。所有 dict 视图都是可迭代的，并且都支持 in 操作符。另外，如果被视图引用的元素都是 hashable 的，那么该视图也会实现 collections.abc.Set 接口。所有由 .keys() 方法返回的视图都属于这种情况，而当 dict 的值是 hashable 时，由 .items() 方法返回的视图也是 hashable 的。 vitual subclass 一个没有继承 superclass，但又使用 TheSuperClass.register(TheSubClass) 注册过的类。参见 abc.ABCMeta.register 的文档。 wart 该语言的不好的特性。Andrew Kuchling 的那篇很有名的文章 “Python warts” 已经被 BDFL 认可了，并在他设计 Python 3 时做出打破向后兼容性这样的决定中起来了很大作用，因为如果不这样，提到的大部分缺陷都将无法修复。Kuchling 提到的很多问题都已在 Python 3 中修复了。 weak reference 一种特殊种类的对象引用，它不增加 referent 对象引用计数值。弱引用由 weakref 模块中的某个函数和数据结构创建。 YAGNI “You Ain’t Gonna Need It”, 该标语用来避免实现那些现在不需要，而基于未来假定会需要的那些功能。 Zen of Python 在 Python 2.2 版本之后的任何 Python 终端中输入 import this 即可显示。 &emsp;&emsp; 参考阅读 atjiang 《Fluent Python》中 Python Jargon 章。]]></content>
      <tags>
        <tag>python 行话</tag>
        <tag>python 术语</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 项目整合套件 pipenv]]></title>
    <url>%2Fnote%2Fpython-%E9%A1%B9%E7%9B%AE%E6%95%B4%E5%90%88%E5%A5%97%E4%BB%B6-pipenv.html</url>
    <content type="text"><![CDATA[也许过程有些煎熬，但真的，熬过去就好了。 &emsp;&emsp;今天翻看了强哥的博客，发觉他 mark 了一个工具，pipenv，是requests作者 kennethreitz 的又一新作，直观这即将成为又一装逼利器，于是乎虎躯一震，赶紧翻翻介绍，官网，本地测试。 &emsp;&emsp;python 部落的这篇文章比较能说明痛点，目前在Python语言中，没有类似于Bundler或Gemfiles的东西，所以通常情况下Python开发人员使用Virtualenv创建一个虚拟环境，再创建一个依赖包列表requirements.txt，然后使用 Pip 安装依赖项。这种方法一般都会正常工作，但有时它也会表现出一些怪异的行为，因此你必须手动安装或删除某些特定版本的包，并记得定期更新requirements.txt文件，以保持项目环境的一致。特别是当你想要在你的虚拟环境中安装Python包，但它不一定与项目本身相关联。 此外，一些项目有时会保留requirements.txt文件的两个版本——一个用于开发环境，一个用于生产环境，这可能会导致更多的复杂性。Kenneth Reitz的最新工具Pipenv可以用于简化Python项目中依赖项的管理。 它汇集了Pip，Pipfile和Virtualenv的功能，是一个强大的命令行工具。 根据作者自己的说法 Pipenv 是一个实验性项目，旨在将所有最好的 packaging 世界带到 Python 世界。它将 Pipfile，pip 和 virtualenv 整合到一个单一的工具。 功能特性： 自动生成和检查文件的哈希值锁定的依赖 自动更新 PIP 自动在包卸载时移除包 在安装包时自动为 Pipfile 添加包 自动在标准位置创建一个 virtualenv 如果 aPipfile.lock 不尊在自动生成一个 如果 aPipfile 不存在自动生成一个 通过寻找 aPipfile 自动查找工程主页，递归 开始1、官网已经给了例子，简单说下安装$ pip install pipenv 2、初始化项目目录$ mkdir your_dir$ pipenv installCreating a Pipfile for this project...Creating a virtualenv for this project...⠋New python executable in /Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa/bin/pythonInstalling setuptools, pip, wheel...done.Virtualenv location: /Users/song/.local/share/virtualenvs/testpro-jrC8EhsaNo package provided, installing all dependencies.Pipfile found at /Users/song/tmp/testpro/Pipfile. Considering this to be the project home.Pipfile.lock not found, creating...Locking [dev-packages] dependencies...⠸Locking [packages] dependencies...⠴Updated Pipfile.lock!Installing dependencies from Pipfile.lock...⠋⠴To activate this project's virtualenv, run the following: $ pipenv shell$ lltotal 16-rw-r--r-- 1 song staff 68B Apr 10 16:01 Pipfile-rw-r--r-- 1 song staff 355B Apr 10 16:01 Pipfile.lock 从提示上可以看到在这个目录下新建两个文件，并且还在家目录下用 virtualenv 新建了一个虚拟环境/Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa，这里终端是有色彩显示的，但是我这里显示的原因 2、进入虚拟环境$ pipenv shellSpawning environment shell (/bin/zsh).source /Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa/bin/activate song@mingming  ~/tmp/testpro  source /Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa/bin/activate(testpro-jrC8Ehsa) song@mingming  ~/tmp/testpro 这里碰到一个问题，我这条命令执行，终端缺没有变化，找寻了一遍发觉没能找到原因，直接在 github 上问了下作者，发觉已经有人碰到过类似的问题了，这里贴下 Display ($VIRTUALENV) in PS1 #77 terminal prompt doesn’t show you’re in the venv #269 除了用pew可以解决外，直接使用pipenv shell -c 进入虚拟环境 使用1、首先看下项目下的这两个文件，这是纯净状态下的配置# 查看当前项目目录$ pipenv --wherePipfile found at /Users/song/tmp/testpro/Pipfile. Considering this to be the project home.# 查看虚拟环境目录$ pipenv --venv/Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa 文件的初始状态$ cat Pipfile[[source]]url = "https://pypi.python.org/simple"verify_ssl = true$ cat Pipfile.lock&#123; "_meta": &#123; "hash": &#123; "sha256": "cb65967bdf3a7372749ce6144be4ee63f412aeeac624342fda3a2b58b1c43c15" &#125;, "requires": &#123;&#125;, "sources": [ &#123; "url": "https://pypi.python.org/simple", "verify_ssl": true &#125; ] &#125;, "default": &#123;&#125;, "develop": &#123;&#125;&#125;% 2、下面当项目里安装第三方模块(testpro-jrC8Ehsa) song@mingming $ pip install requests# 此时查看虚拟环境中的 lib 库，即/Users/song/.local/share/virtualenvs/testpro-jrC8Ehsa/lib/python2.7/site-packages/ 就能看到安装的包了# 如果不想进入虚拟环境，但同时想往虚拟环境里执行命令的话，pipenv 也提供了对应的命令$ pipenv run [command]$ pipenv run pip install requests 3、查看Pipfile的变化[[source]]url = "https://pypi.python.org/simple"verify_ssl = true[packages]requests = "*" 4、紧接锁定当前包的版本$ pipenv lockLocking [dev-packages] dependencies...⠹Locking [packages] dependencies...⠼Updated Pipfile.lock! 可以看到 Pipfile.lock 的变化，产生了一个 hash 值&#123; "default": &#123; "requests": &#123; "version": "==2.13.0", "hash": "sha256:1a720e8862a41aa22e339373b526f508ef0c8988baf48b84d3fc891a8e237efb" &#125; &#125;, "develop": &#123;&#125;, "_meta": &#123; "sources": [ &#123; "url": "https://pypi.python.org/simple", "verify_ssl": true &#125; ], "requires": &#123;&#125;, "hash": &#123; "sha256": "da2810af0c3b5333e0de2fce9bea2a228812e2014e5f5fe3b1c533badc6c24e4" &#125; &#125;&#125;% 这个时候，如果换个目录，换个环境，如果将我现在这个环境的依赖全部带过去$ cp project/Pipfile /new_project/dir/$ pipenv install 新的项目目录即可按照文件里包的版本全部将对应的依赖撞到新的环境中，达到迁移的目的 中间出过问题，可能和我用的环境 zsh 有关，作者也说这是个实验性项目，不可避免的问题，不过看起来还是非常赞的，期待这个项目变得越来越好，如果有项目上，再继续更新 &emsp;&emsp; 参考阅读 pipenv github page pipenv doc]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>pipenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django 分页]]></title>
    <url>%2Fnote%2Fdjango-%E5%88%86%E9%A1%B5.html</url>
    <content type="text"><![CDATA[终于有一天你恍然大悟，或许成长的一部分就是这样，你不断跟熟悉的人告别，跟熟悉的地方告别，然后走上一个陌生的舞台，见陌生的人，听陌生的歌，看陌生的风景，最后把陌生变为熟悉。在生活的锤炼下，你看到谁和谁分开都不会太奇怪，不管这个世界发生什么，你都会有勇气面对新的一天。 学习分页器时候有很多选择，有插件形式，很简单就能处理；但是在学习 django ，自带的分页器还挺好用，但是在做用户展现时也碰到了很多的问题，整理出来如下 django 分页器1.1 paginator 分页 代码位于 django/core/paginator.py 里，这里直接看到文档直接上手 这里没有用户，选在数据库中生成300个测试用户来做展示测试# python manage.py shellIn [1]：from django.contrib.auth.models import UserIn [2]: for i in range(1,300):... User.objects.create_user("testuser&#123;&#125;".format(i), "test&#123;&#125;@test.com".format(i), '123456') 下面开始进行分页展示In [2]: from django.core.paginator import PaginatorIn [3]: userlist = User.objects.all()#每10个对象分为1页In [4]: pages = Paginator(userlist, 10)#得到里面总共有多少个模型对象In [5]: print pages.count300#总页数In [6]: print pages.num_pages30#页面列表，可以拿来遍历得到全部页码In [7]: print pages.page_range[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]#得到第1页包含的模型对象，该对象集合可以用于遍历得到里面的模型对象In [8]: user_page = pages.page(1)#得到该对象集合当前是哪一页In [9]: print user_page.number1In [10]: print user_page.has_previous&lt;bound method Page.has_previous of &lt;Page 1 of 30&gt;&gt;#判断是否有下一页In [11]: print user_page.has_next()True#判断是否有前一页In [12]: print user_page.has_previous()False 上面很直观的看到了一些 paginator 的用法，常规的值需要了解以下几个方法即可 Paginator 对象方法 page 对象方法 1.2 分页进阶 貌似看分页是处理好了，能正常显示了，但有个问题，当展示内容越来越多的时候，分页导航栏也会越来越多，所以完善的一个分页应该包含如下 用户在哪一页，则当前页号高亮以提示用户所在位置，比如上图显示用户正处在第二页。 当用户所处的位置还有上一页时，显示上一页按钮；当还有下一页时，显示下一页按钮，否则不显示。 当分页较多时，总是显示当前页及其前几页和后几页的页码，其他页码不显示。 所以处理逻辑变成了如下 首页、末页、上一页，下一页都循环最原始从数据库中取出的 list 来循环获取数据 而最终展示在用户面前的这个循环列表是处理过的，长度是指定长度的 list，这样就能完成我们要的分页展示 最终代码成了如下，只列出了分页的代码APP/views.pyclass UserListView(ListView): template_name = "user/userlist.html" model = User paginate_by = 10 # 每页展示多少对象 before_index = 4 # 当前页往前几页 after_index = 3 # 当前页往后几页 # context_object_name = "userlist" def get_context_data(self, **kwargs): context = super(UserListView, self).get_context_data(**kwargs) # 重写父类方法，并覆盖父类的 context 属性 context['page_range'] = self.get_page_range(context['page_obj']) return context def get_page_range(self, page_obj): """分页处理逻辑""" # 开始序列号 = 当前页码号 - 后置序列号 start_index = page_obj.number - self.before_index # 应对开始序列异常的情况，最小不能为 0 if start_index &lt; 0: start_index = 0 # 最终在页面上供展示的循环的 list page_range = page_obj.paginator.page_range[start_index: page_obj.number + self.after_index] return page_range HTML 只贴出分页部分 &lt;div class="panel-default"&gt; &lt;center&gt; &lt;ul class="pagination"&gt; &#123;% if page_obj %&#125; &lt;li&gt;&lt;a href="/user/list/?page=1"&gt;首页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;# 如果有上一页则显示上一页标签 #&#125; &#123;% if page_obj.has_previous %&#125; &lt;li&gt;&lt;a href="/user/list/?page=&#123;&#123; page_obj.previous_page_number &#125;&#125;"&gt;上一页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125;&#123;# &#123;% for p in page_obj.paginator.page_range %&#125;#&#125; &#123;% for p in page_range %&#125; &lt;li &#123;% if page_obj.number == p %&#125; class="active" &#123;% endif %&#125;&gt;&lt;a href="/user/list/?page=&#123;&#123; p &#125;&#125;"&gt;&#123;&#123; p &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &#123;# 如果有下一页则显示下一页标签 #&#125; &#123;% if page_obj.has_next %&#125; &lt;li&gt;&lt;a href="/user/list/?page=&#123;&#123; page_obj.next_page_number &#125;&#125;"&gt;下一页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;% if page_obj %&#125; &lt;li&gt;&lt;a href="/user/list/?page=&#123;&#123; page_obj.paginator.num_pages &#125;&#125;"&gt;末页&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &lt;/ul&gt; &lt;/center&gt; &lt;/div&gt; 这里注意两个对象 page_obj 和 page_range page_obj 是原始的从 User.object.all() 取出的全部 list 数据 page_range 是上面的分页逻辑处理后给页面进行循环的 list 对象 如果还需要更多的处理逻辑都可以在 get_page_range 方法里进行添加，这里只实现了我需要的基本分页逻辑。结果就不上图了，效果如上面的需求。 &emsp;&emsp; 参考阅读 pagination 中文文档 pagination 英文文档 Django博客开发实战：文章列表分页和代码语法高亮]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>dango</tag>
        <tag>paginator</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 部署小议]]></title>
    <url>%2Fnote%2Fgit_hexo-%E9%83%A8%E7%BD%B2%E5%B0%8F%E8%AE%AE.html</url>
    <content type="text"><![CDATA[“为自己的目标努力着，全身心投入一件事情的时候，就不再整天想睡懒觉，不再熬夜看偶像，也不用刻意去想怎样好好生活，删掉那些原以为离不开的东西，然后觉得，这才是生活原本的样子啊。” ​​​​—— 德卡先生的信箱 &emsp;&emsp;之前 hexo 或者其他的静态博客部署的问题，最先开始都是部署到 github 上，但github 在国内这种网络环境下偶尔总有点膈应，之所以想在 Coding(之前的 GitCafe)上再部署一份，是出于两个原因考虑：一是为了百度搜索爬虫能抓取自己博客上的内容，因为Github 屏蔽了百度爬虫，部署在国内才能被抓取到；二是为了国内访问加速，部署之后国内访问走 Coding，国外访问走 Github。这样既实现了访问速度的提升，内容的抓取，又能实现内容和代码两个地方备份，何乐而不为呢。 &emsp;&emsp;简单了解下，coding 上部署 hexo 这类静态博客有两种方式来部署。第一种是 pages 服务的方式，操作简单，可绑定自己的域名；第二种是演示方式，操作比较复杂，要想自动部署还需要配置 webhook，并且必须升级会员才能绑定自定义域名。所以选择用 pages 方式。 1.1 准备 coding 上的仓库 和GitHub Pages相同，Coding Pages也分用户站(用户页)和项目站(项目页)。 用户站需要创建一个和用户名完全相同的项目，一个用户名下只能有一个，创建好后在其 coding-pages 分支(这里和 GitHub 不同，GitHub 的用户站是 master 分支)下部署 html 页面后即可通过 username.coding.me 访问。 项目站可在任意项目中开启，也是部署 html 页面到 coding-pages 分支，然后可以通过 username.coding.me/projectname 访问。 1、coding 上注册账号，记住个性后缀，待会很用到 2、上传机器的 SSH 公钥到 coding，这里不再赘述 3、测试连接,是否能看到 success 返回$ ssh -T git@git.coding.net 1.2 推送内容到 coding1、编辑配置文件，增加推送到 coding 这里 hexo 怎么生成内容前文有，这里编辑站点配置文件 # 在部署这里增加成如下样式deploy: type: git repo: github: git@github.com:mingmings/note.git,gh-pages coding: git@git.coding.net:mingmingsong/mingmingsong.git,coding-pages # 开始部署$ hexo deploy 2、 启用 coding-pages 的功能后台页面上启用 pages 服务，coding 官方文档写的很清楚 user page 和 project page 的区别，我这里因为用的是 coding-pages 和 gh-pages 分支，所以我用的其实是 project-pages 的形式。所以我的访问应该是 &lt;username&gt;.coding.me/&lt;project&gt; 1.3 链路优化 这里已经推送到了 coding，那么接下来就想实现上面说到的国内访问 coding，国外访问就访问 github，这样不同的链路访问都能获得相对理想的速度。因为每次更新博客更新都会同时推送到 coding 和 github，内容完全一致 1、这里就必须使用 dns 解析了 这里多数人用 dnspod，我之前买域名是从万网购买的，所以直接从万网的后台来设置 dns 解析，原理相同 核心就是这里的链路类型，不同的线路指向不同的类型，这里 dnspod 和 万网以及其他可以提供域名解析的提供商应该都会有这个提供。到这里整个部署到 coding 就算完成了 1.4 以子目录形式部署 blog 我的 blog，无论是在之前 github 上还是现在的 coding 上，发觉别人访问我的域名mingmings.org 都是一个静态主页，我的 blog 其实是在 mingmings.org/note 下，blog 看似是在子目录中 这里其实原理是混用了 user-pages 和 project-pages，这里稍微解释下，原理和 github 是相同的 user-pages 的仓库，根据 coding 的规定，user-pages 的仓库名必须是 &lt;username&gt;.coding.me，这个规则同样适用 github，只不过 github 的 user-pages 的名是 &lt;username&gt;.github.io，所以访问地址应该是 &lt;username&gt;.coding.me，我绑定域名 mingmings.org，相当于我整个站的首页 mingmings.org/note 因为不是一个域名，只是相当于子目录，所以指向了 project-pages 的仓库，这里 coding 没有对 project 的仓库名称做限制，所以可以随便起，我这里就是 note.git 但是分支可以是 master 和 coding-pages，因为 github 上要求的 project-pages 的分支必须是 gh-pages ，所以我习惯这里也就沿用了 coding-pages 分支，相当于我整个站下的 note，所以访问域名因为上面域名的绑定这里就成了 mingmings.org/note。 # 所以到这里应该理解配置文件格式为什么后面的分支是这样deploy: type: git repo: github: git@github.com:mingmings/note.git,gh-pages coding: git@git.coding.net:mingmingsong/mingmingsong.git,coding-pages 到了这，完整的同时部署到 coding 和 github 上就完成了，并能根据线路优化访问，收工~ &emsp;&emsp; 参考阅读 Coding Pages 开始使用 Coding Pages hexo同时部署到coding(gitcafe)和github 在 Coding 上搭建 Hexo 个人博客！]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>coding</tag>
        <tag>gitcafe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 博客的第三方功能]]></title>
    <url>%2Fnote%2Fgit_%E5%A4%9A%E8%AF%B4%E8%AF%84%E8%AE%BA%E5%A2%9E%E5%8A%A0-UA.html</url>
    <content type="text"><![CDATA[趁阳光正好。趁微风不噪。趁繁花还未开至靡。趁现在还年轻，还可以走很长的路。&emsp;&emsp;多说评论是静态博客常用的评论，而且还提供了丰富的样式。下图就是其中一种效果图，摘自网络 多说的自定义样式可以显示访问者的浏览器和系统信息的显示，可以增加评论的积极性和趣味性，之前迷糊了很久，今天详细完整的把这个记录下来，大致流程有以下几步 一、多说系统 国内普遍使用的评论系统，这里为了增加多说的 UA 等信息 1.1 本地化多说的 embed.js 先说说这个 embed.js 是个啥，多说社会化评论框核心脚本 embed.js 文件是个多说官方提供的公用文件，如果官方渠道过于拥挤，或者服务器故障（这个已经有过了~~），就会导致页面加载过慢或者完全无法加载，如果我们将其下载下来放到自己的空间上，就会提高加载速度，同时也可以对多说评论框做一些个性化调整 1、下载 embed.js 多说官方：http://static.duoshuo.com/embed.js 然后保存下来，上传到自己的的空间里，你可以上传到 github 上，也可以上传到第三方的云存储上。 2、修改多说的调用地址# 修改下载下来的 embed.js 中的调用地址ds.src = '你的存放路径/embed.js'; 3、验证再次访问刷新页面，如果多说评论是正常可用的，那么就证明 embed.js 本地化成功 1.2、自定义多说后台自定义CSS样式 同样的，多说允许自定义评论框的样式，效果图中很明显的样式可以自定义 打开多说后台的【设置-基本设置-自定义 css】即可 我目前用的样式/*Head Start*/#ds-thread #ds-reset ul.ds-comments-tabs li.ds-tab a.ds-current &#123; border: 0px; color: #6D6D6B; text-shadow: none; background: #F3F3F3;&#125;#ds-thread #ds-reset .ds-highlight &#123; font-family: Microsoft YaHei, "Helvetica Neue", Helvetica, Arial, Sans-serif; ;font-size: 100%; color: #6D6D6B !important;&#125;#ds-thread #ds-reset ul.ds-comments-tabs li.ds-tab a.ds-current:hover &#123; color: #696a52; background: #F2F2F2;&#125;#ds-thread #ds-reset a.ds-highlight:hover &#123; color: #696a52 !important;&#125;#ds-thread &#123; padding-left: 15px;&#125;#ds-thread #ds-reset li.ds-post,#ds-thread #ds-reset #ds-hot-posts &#123; overflow: visible;&#125;#ds-thread #ds-reset .ds-post-self &#123; padding: 10px 0 10px 10px;&#125;#ds-thread #ds-reset li.ds-post,#ds-thread #ds-reset .ds-post-self &#123; border: 0 !important;&#125;#ds-reset .ds-avatar, #ds-thread #ds-reset ul.ds-children .ds-avatar &#123; top: 15px; left: -20px; padding: 5px; width: 36px; height: 36px; box-shadow: -1px 0 1px rgba(0,0,0,.15) inset; border-radius: 46px; background: #FAFAFA;&#125;#ds-thread .ds-avatar a &#123; display: inline-block; padding: 1px; width: 32px; height: 32px; border: 1px solid #b9baa6; border-radius: 50%; background-color: #fff !important;&#125;#ds-thread .ds-avatar a:hover &#123;&#125;#ds-thread .ds-avatar &gt; img &#123; margin: 2px 0 0 2px;&#125;#ds-thread #ds-reset .ds-replybox &#123; box-shadow: none;&#125;#ds-thread #ds-reset ul.ds-children .ds-replybox.ds-inline-replybox a.ds-avatar,#ds-reset .ds-replybox.ds-inline-replybox a.ds-avatar &#123; left: 0; top: 0; padding: 0; width: 32px !important; height: 32px !important; background: none; box-shadow: none;&#125;#ds-reset .ds-replybox.ds-inline-replybox a.ds-avatar img &#123; width: 32px !important; height: 32px !important; border-radius: 50%;&#125;#ds-reset .ds-replybox a.ds-avatar,#ds-reset .ds-replybox .ds-avatar img &#123; padding: 0; width: 32px !important; height: 32px !important; border-radius: 5px;&#125;#ds-reset .ds-avatar img &#123; width: 32px !important; height: 32px !important; border-radius: 32px; box-shadow: 0 1px 3px rgba(0, 0, 0, 0.22); -webkit-transition: .8s all ease-in-out; -moz-transition: .4s all ease-in-out; -o-transition: .4s all ease-in-out; -ms-transition: .4s all ease-in-out; transition: .4s all ease-in-out;&#125;.ds-post-self:hover .ds-avatar img &#123; -webkit-transform: rotateX(360deg); -moz-transform: rotate(360deg); -o-transform: rotate(360deg); -ms-transform: rotate(360deg); transform: rotate(360deg);&#125;#ds-thread #ds-reset .ds-comment-body &#123; -webkit-transition-delay: initial; -webkit-transition-duration: 0.4s; -webkit-transition-property: all; -webkit-transition-timing-function: initial; background: #F7F7F7; padding: 15px 15px 15px 47px; border-radius: 5px; box-shadow: #B8B9B9 0 1px 3px; border: white 1px solid;&#125;#ds-thread #ds-reset ul.ds-children .ds-comment-body &#123; padding-left: 15px;&#125;#ds-thread #ds-reset .ds-comment-body p &#123; color: #787968;&#125;#ds-thread #ds-reset .ds-comments &#123; border-bottom: 0px;&#125;#ds-thread #ds-reset .ds-powered-by &#123; display: none;&#125;#ds-thread #ds-reset .ds-comments a.ds-user-name &#123; font-weight: normal; color: #3D3D3D !important;&#125;#ds-thread #ds-reset .ds-comments a.ds-user-name:hover &#123; color: #D32 !important;&#125;#ds-thread #ds-reset #ds-bubble &#123; display: none !important;&#125;#ds-thread #ds-reset #ds-hot-posts &#123; border: 0;&#125;#ds-reset #ds-hot-posts .ds-gradient-bg &#123; background: none;&#125;#ds-thread #ds-reset .ds-comment-body:hover &#123; background-color: #F1F1F1; -webkit-transition-delay: initial; -webkit-transition-duration: 0.4s; -webkit-transition-property: all; -webkit-transition-timing-function: initial;&#125;/*Head End*/ 1.3、多说显示 UA UA，即显示评论者所使用的代理信息（如 操作系统、浏览器）等，效果如上图 这里 Next 主题的作者已经帮我们集成好了，只需要编辑主题配置文件_congig.yml 如下：# Make duoshuo show UA# user_id must NOT be null when admin_enable is true!# you can visit http://dev.duoshuo.com get duoshuo user id.duoshuo_info: ua_enable: true admin_enable: true user_id: xxxxxx admin_nickname: Root 只要设置 ua_enable 为 true 即可显示 UA 信息。 admin_enable 是用于显示 Root 文字，表明评论者是博主【默认显示的是博主，我给改成 Root 了】，此字段需要同时配置 user_id。 请访问 多说开发者中心，登录并访问 我的主页 获取 user_id ， 此 ID 是网址最后那串数字。 最后上一张我的多说评论 二、不蒜子统计 根据不蒜子的介绍，使用起来非常简单。只需要两行代码（一行脚本、一行HTML显示）搞定计数。 2.1 增加代码在引入 JS 的地方添加下列脚本即可，以我的 hexo 博客为例：themes/next/layout/_partials/footer.swig # 在文件顶部引用&lt;script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"&gt;&lt;/script&gt;&lt;div class="copyright"&gt;&lt;span id="busuanzi_container_page_pv"&gt; 本文阅读量：&lt;span id="busuanzi_value_page_pv"&gt;&lt;/span&gt;&lt;/span&gt;&amp;nbsp; | &amp;nbsp;&lt;span id="busuanzi_container_site_pv"&gt; 本站访问量: &lt;span id="busuanzi_value_site_pv"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/div&gt; 效果如下 &emsp;&emsp; 参考阅读 多说自定义CSS头像和多说评论显示UA 多说CSS修改 多说回复后显示浏览器及操作系统信息（Useragent） 多说社会化评论框核心脚本embed.js本地化方法 多说社会化评论框添加 站长回复 标记 Hexo 集成多说评论 + 多说分享 + 美化多说 不蒜子统计]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>多说</tag>
        <tag>UA</tag>
        <tag>站长信息</tag>
        <tag>美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github pages]]></title>
    <url>%2Fnote%2Fgit_github-pages.html</url>
    <content type="text"><![CDATA[日子总是像从指尖渡过的细纱，在不经意间悄然滑落。那些往日的忧愁和误用伤，在似水流年的荡涤下随波轻轻地逝去，而留下的欢乐和笑靥就在记忆深处历久弥新。 &emsp;&emsp;现在的博客用的是 github 上的 github page 服务，准确说是 user page服务，今天突然有需求弄个 organizations page，所以从新建组织到使用 page 的服务全部弄了遍，因为 user page 和 organizations page 流程大体相同，所以将二者重新整理下 一、准备部分1.1 准备 organizations 账号 从蒋鑫大大的文章中可以看到：组织是非登录账号，不能像创建普通登录账号那样直接创建，而是需要以 GitHub 用户身份登录，然后再创建自己的组织，创建者成为组织天然的管理者。所以第一步根据自己的 github 账号创建一个组织 基础信息邀请成员，这部可以跳过到此，一个 organizations 就创建完成了，下面就可以按照自己的需要创建 repo，创建 team 等一些列操作，蒋鑫大大的文章中写的很清晰，这里不再赘述 1.2 使用 pages 服务1、创建 repo，用来存储生成的 page 生成的代码 这里的步骤和 user page 的步骤相同，user page 是创建自己 username.github.io，这里就是 organization_name.github.io 2、初始化 repo，提交代码 # 下载 repogit clone git@github.com:&lt;organizations_name&gt;/&lt;organizations_nam&gt;.github.io.git# 新增内容echo "organizations pages success..." &gt; index.html# 提交并推送git add index.htmlgit commit -m "first commit"git push origin master 稍等片刻，浏览器访问https://&lt;organization_name&gt;.github.io/ 可以看到organizations pages success... 到此，就全部完成了organization pages 基础部分了，至于下面用什么框架来生成内容都看列为看官的兴趣爱好了，我的博客使用的是基于 nodejs 的 hexo 来生成静态博客的内容，当然了，对 organization page 也是可行的，不过静态博客的框架还有很多，看自己习惯哪个了… 1.3 使用静态博客框架 其他框架可能得参考下往上的文章了，这里我是用的 hexo，就理清怎么用 hexo 搭建吧，往上的详细教程特别多，这里不再赘述，主要还是要弄清楚思路和流程 &emsp;&emsp;刚才其实上面说了，整个流程大致是【准备 github 账号 -&gt; 准备 repo -&gt; 本地使用静态博客框架生成博客内容 -&gt; 推送到 repo，展现 -&gt; 自定义域名、主题、优化等】 &emsp;&emsp;上面的内容已经完成了 github 仓库的内容，剩余的内容可以全部在本地完成，本地无非是需要个环境来用框架生成博客内容，本地预览等等一些列功能，主流的博客框架都支持这些基本的功能。我这里环境是 osx，其他环境可能得看官自己尝试一下 1、准备 node 环境 这里可以用 brew install node 来装，也可以源码，也可以下载官方提供的 mac 专用的包来，也可以先装 nvm 等版本控制器，这里推荐使用 nvm 使用 brew 安裝 NVM$ brew install nvm 将下面内容加入 .bash_profile（或 .zshrc）export NVM_DIR=~/.nvmsource $(brew --prefix nvm)/nvm.sh 重新載入生效$ source .bash_profile$ source .zshrc 测试即可$ nvmNode Version ManagerUsage: nvm help Show this message nvm --version Print out the latest released version of nvm nvm install [-s] &lt;version&gt; Download and install a &lt;version&gt;, [-s] from source. Uses .nvmrc if available nvm uninstall &lt;version&gt; Uninstall a version nvm use &lt;version&gt; Modify PATH to use &lt;version&gt;. Uses .nvmrc if available nvm run &lt;version&gt; [&lt;args&gt;] Run &lt;version&gt; with &lt;args&gt; as arguments. Uses .nvmrc if available for &lt;version&gt; nvm current Display currently activated version nvm ls List installed versions nvm ls &lt;version&gt; List versions matching a given description nvm ls-remote List remote versions available for install nvm deactivate Undo effects of `nvm` on current shell nvm alias [&lt;pattern&gt;] Show all aliases beginning with &lt;pattern&gt; nvm alias &lt;name&gt; &lt;version&gt; Set an alias named &lt;name&gt; pointing to &lt;version&gt; nvm unalias &lt;name&gt; Deletes the alias named &lt;name&gt; nvm reinstall-packages &lt;version&gt; Reinstall global `npm` packages contained in &lt;version&gt; to current version nvm unload Unload `nvm` from shell nvm which [&lt;version&gt;] Display path to installed node version. Uses .nvmrc if availableExample: nvm install v0.10.32 Install a specific version number nvm use 0.10 Use the latest available 0.10.x release nvm run 0.10.32 app.js Run app.js using node v0.10.32 nvm exec 0.10.32 node app.js Run `node app.js` with the PATH pointing to node v0.10.32 nvm alias default 0.10.32 Set default node version on a shellNote: to remove, delete, or uninstall nvm - just remove ~/.nvm, ~/.npm, and ~/.bower folders 安装 nodejs$ nvm install 0.11.16nvm ls v0.10.33 v0.11.0 v0.11.11-&gt; v0.11.16 systemdefault -&gt; v0.11.0stable -&gt; 0.10 (-&gt; v0.10.33) (default)unstable -&gt; 0.11 (-&gt; v0.11.16) (default) 2、安装 hexo 安装完了 nvm，node ，下面用的就是 npm 来安装包，推荐把 npm 的源换成国内的淘宝源吧，具体原因你们懂的 $ npm install hexo-cli -g #如果这里用的官方源，可能会经常失败 二、开始写作 完成了上面所有，那么现在博客框架所需的东西已完成，接下来就可以开始写作了 1、生成本地博客$ hexo init blog # 本地会生成一个目录$ cd blog$ ll.├── _config.yml # 站点配置文件├── package.json # 应用程序的信息├── scaffolds # 模版。新建文章时，Hexo 会根据 scaffold 来建立文件├── source # 资源文件夹是存放用户资源的地方| ├── _drafts| └── _posts└── themes # 主题。Hexo 会根据主题来生成静态页面。$ npm install # 安装博客所需要的插件$ hexo server # 生成本地的端口和服务，用于查看博客 2、写文章$ cd blog# 新建文章$ hexo new [layout] &lt;title&gt;$ vim source/_posts/&lt;title&gt;.md# 注意上面这几行，可能生成的会不同，这几个参数就是控制文章的分类，标题，创建时间，tags---title: xxxxtags: [xxx,xxx]date: 2017-03-01 16:05:39category: xxx--- 更加详细的可以在这里找到 https://hexo.io/zh-cn/docs/configuration.html 3、这里文章如果写完了，接下来生成内容# 生成静态文件$ hexo generate# 启动服务器。默认情况下，访问网址为： http://localhost:4000/。$ hexo server这里本地查看文章的状态，格式啊等等，如果确认无误了，表明文章本地生成完全没有问题了，如果有问题，可以接着修改再次本地查看，直到满意为止 更多命令请查看 https://hexo.io/zh-cn/docs/commands.html 4、将本地生成好的内容推送到远端仓库中，这里就是 github 中的那个 repo# 编辑站点配置文件$ vim blog/_config.yml# 找到如下的部分# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repo: git@github.com:&lt;username&gt;/&lt;username&gt;.github.io branch: master# 修改完保存执行以下命令$ hexo deploy 如若推送成功，稍等片刻，再次访问 pages 服务的域名，就可以看到刚才本地生成的内容了，以后写作-生成内容-推送 就是这么个流程… &emsp;&emsp;剩下的就是自定义域名啊，切换主题啊，优化等等，每个人口味不同，这里大家都去 google 上找找相关的文章，很多很多，后续的部分都不会影响写作，以后有机会在写吧… &emsp;&emsp; 参考阅读 User, Organization, and Project Pages word hello - 组织和团队 GitHub Pages]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>github page</tag>
        <tag>user page</tag>
        <tag>organization page</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深圳南山]]></title>
    <url>%2Fnote%2Ftravel-%E6%B7%B1%E5%9C%B3%E5%8D%97%E5%B1%B1.html</url>
    <content type="text"><![CDATA[“漂亮的衣服等等再穿，好玩的地方要准备好了再去，总把希望寄托在以后，日子一天天地过去，生活没有任何改变。原来是我疏忽了，哪有那么多未来啊有的只是现在。” ​​​​—— 德卡先生的信箱 &emsp;&emsp;第一次来深圳，时间是 2016 年 11 月 11，特地选了双 11 这天，虽然本意是出差，也带着体验生活的目的，给自己了解这个城市的时间，想想这样的的机会以后也不太多，就决定过来，初来这个城市的印象还挺特别，之前的了解很有限，而来之前特地关注天气，和正值此时的北京温度相差20度，以我常年怕热的体质可想而知，索性带着半箱（29寸）的短袖裤衩和半箱健身物品（长时间出门健身装备一定不能少）的衣物直奔酒店 &emsp;&emsp;因为项目的原因，和腾讯的互娱有一些业务往来，所以办公地点选在了互娱所在的科兴科学园内，科兴科学园位于深圳南山区，是一片新规划的高新区，南山高新园之于深圳类似当年的海淀中关村之于北京，而这段时间房价的飙升让这里的的房价已迈入10w/平大关，一下让这个看起来还不是那么繁华的区域里的房子变的炙手可热。 直奔酒店，地图上就是我每天从酒店出发到上班的地方，不过十分钟的走路路程，这对于北京动辄一两个小时的路程简直就是近在咫尺，当然了，这是公司的安排 园区一角 安排好了之处后，到了办公点看了下工作环境，也转了转这个腾讯的互娱事业部所在的园区，对于我来说，健身房比食堂更必不可少，工作之余走下楼就可以吃饭和健身，不耽误事，挺好科兴食堂 这是科兴科学园的食堂，作为工作餐，食堂整体伙食还可以，两三个礼拜吃个不重样还是没问题的，如果要更高的要求那就只能去园区的原味街上去找或者去其他地方了，原味街是整个科兴全区的 G 层都包括在内，店面嘛，总能找到你需要的 正式开始工作前，瞎晃悠园区，半天即可逛完，生活配套还挺全乎，日常多数需求都可以在这里完成。每天往返在酒店和园区之间的十分钟，也很容易就度过了头一个礼拜，接下来倒是想去的其他地方走一走，没想到工作一忙起来，惰性使然，到了快离开深圳的时候发觉也没走过多少地方… 平日工作时间比较紧凑，只有周日一天休息，去的地方不能太远，跑的最多的还是南山，每次搜罗好吃好玩的，离的又不远的，貌似都在海岸城这里，我又不太瞎跑，所以无非就只为了吃，不过说到吃，海岸城真还有几家不过值得推荐店，首当其冲这家 烤鱼大家都吃过，但是来了海岸城一定试试这家的烤鱼，味道的确有点不同，我去了几次，无一例外，只要是逛街时间，无论何时总是排队等吃鱼，还真不是夸张，几家其他的分店也是这个情况，吃了几次，发觉只有酱辣味的强力推荐，其他味道也还可以，但是不至于推荐，酱辣味有别于其他味道的烤鱼，来了一定要试试，不会让你失望的 另外，想让你的口感提升一个档次，就一定要搭配这瓶柠檬金桔，亲身体验，柠檬金桔，相信我~ 除了吃饭以外，深圳这段时间因为共享单车井喷的趋势，骑行的人群大大增加，逐渐改变行为的人们，街头巷尾到处可见，这点不得不书说道说道。深圳天气真的是非常好，可以用好的发指形容（原谅从北京吸霾过来的直观感受），另外市政也有为自行车修专用的自行车道，也有合适的深海湾沿线，头顶着灿烂的阳光，吹着海风，悠悠的骑在小道上，列为看官想想知道这是一种什么样的体验~ 从体育场进入小道，却发觉人比想象的更多，走走停停，不过这么好的天气，本身就是放松心情，何须着急呢，也可以享受走走停停的乐趣嘛 其实像我如果呆一个地方，不太到处走动，但是第一次来深圳，总希望看到些不同的东西，不过因为跑的少，还是没有看到很多地方，比如大小梅沙，世界之窗，华强北啊等等，本文主要是写我的直观体验，就到这吧，毕竟又不是游记，有机会再来体验，再接着写…]]></content>
      <categories>
        <category>在路上</category>
      </categories>
      <tags>
        <tag>深圳南山</tag>
        <tag>腾讯</tag>
        <tag>科兴科技园</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016年终总结]]></title>
    <url>%2Fnote%2F%E5%B7%A5%E4%BD%9C_2016%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93.html</url>
    <content type="text"><![CDATA[记住，等你的身体出了什么毛病，你就会意识到什么烦心事都是屁，都是吃饱了撑的，都是闲的，健康活着比什么都重要。 &emsp;&emsp;又是一年过去，在深圳近三个月的出差生活让我对这座年轻的城市有了一个长足的认识，恐怕以后不会再有这样的机会在一个陌生城市出差这么久了，等到春节回来想起来还没有写年终总结呢，遂在深圳的最后回望下今年。 &emsp;&emsp;不总结就看不到毛病，对自己今年的评价，只能说完全连及格线都达不到，倒不是因为自己期望过高，而是自己压根没有任何突出的成果和成绩，很是惭愧，不过惭愧归惭愧，毛病，弱点，还是得列出来警示自己 &emsp;&emsp;先说今年的目标吧，16年年初给自己原本制定了这样的几个目标 从运维大兵变成了运维组长，带好小团队 转向运维开发，多偏向这块的工作 坚持健身，持续增肌 多看书，发展一门兴趣爱好 &emsp;&emsp;目标是有了，但一年下来，我发觉远不及格。先说职位的变动吧，变成组长，不能再单向思维做到底了，眼光得放得更高，更长远，而不能局限一时，这点上，基本没开窍，在超哥的三番五次提醒下，仍旧没有完全的转变过来，不少时候仍旧像之前那样做事，看不到全局，一头扎进去做事情，忘了方向。除了单纯的任务分配，协调，跟进以及部门间沟通外，成员的谈话，了解，情感建设等等一概没有。都说管理是门学问，而我连门都没跨进去，单这点而言就觉得还有很长的路要走，要学习。 &emsp;&emsp;技能方面，devops 已然是职业所趋，虽然在超哥的带领下，也开始了运维开发方面的工作，不过，自认为仍不窥得门径，django 的框架方面虽然可以照猫画虎进行功能的开发，但是效率并不高，代码也不那么完善，而且采用了 class-based view 的方式在网上并不能找到类似的例子，外加抽象出逻辑层这块，理解力有限，天资愚钝，总是理解不到其中的精髓，这方面在接下来的日子里得重点在项目中强化 &emsp;&emsp;唯一能说道的恐怕只剩健身了，一直坚持着一周五天一周期的训练计划，偶有中断，就连出差，拖着一个29的箱子里，一半是健身的装备，这块能给自己打个80分。 &emsp;&emsp;自从下半年，游戏开始忙了后，看书明显少了，俗话“三天不读书，智商输给猪”，我想这样我连猪都不如了，在一天夜里惊醒后开始恢复读书习惯，并能讲思维导图灵活贯通到读书的始终，让读书收益最大化，只可惜这点发现的有点晚… 总之今年浑浑噩噩的度过了一年，个人感觉浪费了半年的时光，被被人甩开的差距可想而知，而且随着离京的日程越来越近，春节之后按计划是去成都开始工作的，也开始一段新的生活。我也开始重新调整自己，总结不足改善，需要克服更多的挑战，列计划发现自己能做到的不多，所以不再列多少多少计划，一年能完成1-2件大事，我觉得就挺好，16年浪费了太多，教训惨重，17年不能再浑浑噩噩了，坚持学习，坚持写博… 最后说一句，如果有成都的小伙伴，来找我一起健身，一起耍哈~]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grafana 升级 3.x 后使用对比]]></title>
    <url>%2Fnote%2Fgrafana-%E5%8D%87%E7%BA%A7-3-x-%E5%90%8E%E4%BD%BF%E7%94%A8%E5%AF%B9%E6%AF%94.html</url>
    <content type="text"><![CDATA[对的人要晚一点遇到，但是也不要太晚，希望你出现的时候，我们已经成熟的可以理智的计划彼此的未来，也年轻到对遇见了解，依然怀有热泪盈眶的感激。 之前使用 grafana 的时候是 2.6 的版本，当时使用的直观感受上虽然很流弊，但是仍旧可以有很多改进的地方，最近处于监控系统的整改，重新开始在展现上使用 grafana，官网版本已经到了 3.0.4，遂直接使用，看文档描述变化了不少，正在慢慢体会… zabbix plugin for grafana1.1 开始安装和之前的安装并与差别，可以通过下载二进制包，配置仓库源等等，我是 centos 的系统，直接下载 RPM 包安装即可 grafana 3 之后的变化在于讲之前的扩展以 plugins 的形式进行调用，并可以进行集中管理，例如升级，查看，调用，删除等，类似于VIM 的 plugins 的形式，这点大大方便了日后的各个功能的扩展和推广，这是我第一个发现变化较大的地方，插件的安装也比较特殊。安装各个 plugin 都是通过 CLI tools 来完成的，所以先介绍这个工具 1.2 CLI tools官方描述这是一种快速安装 plugin 而提供的一个工具，在 v3 之前，必须是按照文档描述，将 plugin 目录内容拷贝到 grafana 的安装目录下的 plugin 目录下，所以这个工具出现省去了很多麻烦，这点个赞。 在 linux 系统上，CLI tools 是通过命令 grafana-cli 来工作的，默认插件安装目录在 /var/lib/grafana/plugins ，也可以通过参数 --path 自定义指定安装目录 简单的通过帮助命令查看几个常用的命令# grafana-cli --helpNAME: Grafana cli -USAGE: grafana-cli [global options] command [command options] [arguments...]VERSION: 3.0.4AUTHOR(S): Grafana Project &lt;https://github.com/grafana/grafana&gt;COMMANDS: plugins Manage plugins for grafana help, h Shows a list of commands or help for one commandGLOBAL OPTIONS: --pluginsDir "/var/lib/grafana/plugins" path to the grafana plugin directory [$GF_PLUGIN_DIR] --repo "https://grafana.net/api/plugins" url to the plugin repository [$GF_PLUGIN_REPO] --debug, -d enable debug logging --help, -h show help --version, -v print the version 演示几个常用的命令，其余类似列出可用的插件，可能得出墙# grafana-cli plugins list-remoteid: alexanderzobnin-zabbix-app version: 3.0.0-beta8id: bosun-app version: 0.0.17id: bosun-datasource version: 0.0.5id: crate-datasource version: 0.0.1id: fastweb-openfalcon-datasource version: 1.0.0id: grafana-clock-panel version: 0.0.8id: grafana-example-app version: 1.0.1id: grafana-influxdb-08-datasource version: 1.0.2id: grafana-kairosdb-datasource version: 1.0.1id: grafana-piechart-panel version: 1.1.1id: grafana-simple-json-datasource version: 1.1.2id: grafana-worldmap-panel version: 0.0.11id: kentik-app version: 1.0.4id: ns1-app version: 0.0.3id: opennms-datasource version: 2.0.1id: percona-percona-app version: 1.0.0id: raintank-snap-app version: 0.0.2id: raintank-worldping-app version: 1.0.9id: stagemonitor-elasticsearch-app version: 0.26.0id: udoprog-heroic-datasource version: 0.1.0Restart grafana after installing plugins . &lt;service grafana-server restart&gt;安装插件# grafana-cli plugins install alexanderzobnin-zabbix-appinstalling alexanderzobnin-zabbix-app @ 3.0.0-beta8from url: https://grafana.net/api/plugins/alexanderzobnin-zabbix-app/versions/3.0.0-beta8/downloadinto: /var/lib/grafana/plugins✔ Installed alexanderzobnin-zabbix-app successfullyRestart grafana after installing plugins . &lt;service grafana-server restart&gt;显示本地已安装插件# grafana-cli plugins lsinstalled plugins:alexanderzobnin-zabbix-app @ 3.0.0-beta8# ll /var/lib/grafana/plugins/total 4drwxr-xr-x. 7 root root 4096 Jun 17 14:45 alexanderzobnin-zabbix-app升级所有插件# grafana-cli plugins update-all升级单个插件# grafana-cli plugins update &lt;plugin-id&gt;移除所有插件# grafana-cli plugins remove &lt;plugin-id&gt; 1.3 Zabbix plugin for Grafanagrafana 只作为核心程序，我们所需要的展示 zabbix 的数据是作为一个 feature plugin 在 grafana 社区里查看并下载到，作者 Alexander Zobnin，详细地址请点击参考阅读 根据插件主页介绍。插件就是展示不同的 zabbix 类型的数据，并且还有个 live demo 安装分为两步1、用 CLI tools 安装grafana-cli plugins install alexanderzobnin-zabbix-app 2、界面中启用 启用完成后，插件中自带了几个模板的样式，可以直接导入 到了这里，剩下的看看文档配置就可以了 第二个变化是配置 data source 和之前也略有变化当配置完成 zabbix 的 data source 后会自动进行 test connect 并反馈结果，另外也从选项也会比之前多出几个额外选项，配合完成其他功能 &emsp;&emsp; 参考阅读 grafana download grafana plugins grafana 社区 CLI tools Zabbix plugin for Grafana]]></content>
      <categories>
        <category>dashboard</category>
      </categories>
      <tags>
        <tag>grafana 3.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控系统改造]]></title>
    <url>%2Fnote%2F%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F%E6%94%B9%E9%80%A0.html</url>
    <content type="text"><![CDATA[因为害怕被人误解，你把自己过得很卑微。 先说说我们遇到的主要几个大问题 监控系统收集设置的 trigger 过多，同一时间触发的很多 触发 trigger 后的 action 就算是设置的报警分层明细，也耐不住数量级过大，所以收到的短信或者微信巨多，根本没法处理，报警处理不及时 升级 zabbix 3.0+ 后没有对应的 zatree 展示控件对应新版本，没法查看更加人性化或可定制化的展示界面 当然还有其他小问题，但是都没有上述列出来的需求迫切，所以围绕着这几个需求我们罗列了几个我们认为重要的可备选方案 监控系统改进1.1 数据收集&emsp;&emsp;这部分我们还是选择 zabbix 的的收集机制，毕竟我们这里的环境虽不是特别大的量，但是不同的云厂商，国内外的环境都包含在内，所以 zabbix server、zabbix proxy、zabbix agent 的机制能很好的解决网络上的问题，且丰富的配置参数和简单的界面操作，相比自己实现，要容易也稳定许多，我们仍旧打算采用 zabbix 来收集数据到 mysql 1.2 告警&emsp;&emsp;这部分是我们的重灾区，报警开始需要分级发送机制，所以设定了很多发送 action 的条件，但是仍旧是不能解决问题过多的情况，所以针对这个情况，我们放弃了 zabbix 自身的触发 action 的机制，不再设置 action。换做我们自己进行读 zabbix 库，取出我们需要的数据在另一个系统里进行筛选，合并，过滤，最后只发送一条信息，后续出现相同问题，不再重复发送，这称之为报警收敛，这部分目前打算先以仍旧以 python 程序读取 mysql 的内容再次进行处理 1.3 数据展现&emsp;&emsp;这部分一个没有告警重要但是可以让监控系统更加人性化的组成部分，在性能方面需要大量的历史数据进行对比，目前的情况 zabbix 的原生 graph 和 screen 是满足不了更多的定制需求，鉴于之前使用过 grafana 的缘故，grafana 更新到 3.0 后对我的吸引力也更大，所以暂定展现使用 grafana 来提升一下监控系统的逼格，毕竟目前我们对展现和前端自己完全自定义不具备条件和技术能力 1.4 项目遇到的问题和难点 首先对 zabbix 的 mysql 库了解并不深刻，大致看过表结构，但是了解并不够透彻，需要加深了解，因为取出对应的数据就得能写出对应的 sql； 对 zabbix mysql 里捞出来的数据进行分组处理，从未做过相关的项目，缺乏具体细节的实现； 展现层 grafana 算是一个独立的知识点了，包括安装，进阶使用，优化，API，到最后的自动部署等，得需要一段时间来熟悉； 上述苦难点一个个的克服，但是昨天无意玩 zabbix 3.0 有个意外收获 zabbix 3.0 的 debug 模式下，可以看到了查询数据的 sql 语句，这对我们现在想捞数据来说帮了大忙了 &emsp;&emsp;项目的后期实现思路我会陆续更新，愿和小伙伴一起学习一起进步 参考阅读 What’s New in Zabbix 3.0 grafana grafana zabbix plugin]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控系统改造</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016 开篇]]></title>
    <url>%2Fnote%2F%E5%B7%A5%E4%BD%9C_2016-%E5%BC%80%E7%AF%87.html</url>
    <content type="text"><![CDATA[无为，不是无所作为，而是“顺天之时，随地之性，因人之心”不肆意妄为 &emsp;&emsp;随着工作和健身的深入，渐渐的写博客的内容越来越少了，各种”没空”，”没环境”，”太累” 等拖延的词语开始冒出，最近到期的云主机又重新让我觉得还是得捡起来写博的习惯，所性放弃云主机部署博客环境，换回原先的 github page 的环境，这两天刚重新配置好，精简下重新上路…… &emsp;&emsp;打开归档一看，到 2015 年后再没有更新了，已经大半年了，再看看之前写的博文，也含有基础性的安装文档，甚至有一段时间给当成了笔记，虽不说笔记不好，现在觉得分享出来应当是值得分享的。更多的应该是自己的心得和体会，所以也决定开始改变风格，不注重发类似安装类的文章，或者说即使是这一类型，也不在像之前的 step by step 的方式，我觉得能从各种文档上看到的东西就没发的必要了，也就说说注意事项等等。而更多的应当是分享一些报错和解决方案，探讨和设计，需求解决方法和面临的困境和思考，新技术领域和方向等等，我觉得这对我而言是非常有必要的。 &emsp;&emsp;回望这段时间，个人迈出去的最大的变化的就是把健身当成了一个生活习惯并义无反顾，且是热爱上了这项撸铁的运动，也因为健身意识到同时抓多个事情不如认真的做好一件事，更觉得 Done is better than perfect 的内在含义, 当然健身给我带来的变化远不止如此，还有很多就不一一列举了…… &emsp;&emsp;能有条不紊的规划着未来，能按照计划做自己喜欢的事情，我觉得这是我眼下最大的满足，扔掉了繁杂的流程，化繁为简，带着一份愉悦，我回来了……]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 报错及解决]]></title>
    <url>%2Fnote%2Fgit_hexo-%E6%8A%A5%E9%94%99%E5%8F%8A%E8%A7%A3%E5%86%B3.html</url>
    <content type="text"><![CDATA[我们一步一步走下去，踏踏实实的走去，用不抗拒生命交给我们的重负，才是第一个勇者。到了暮然回首的那一瞬间，生命必然给我们公平的答案额又一次乍喜的心情，那是的山和水，又恢复了是山是水，而人生已然走过，是多么美好的一个秋天。——三毛 之前的笔记本环境崩溃过一次，发觉好多之前整理的笔记弄丢了，没办法只得重新开始折腾，遂把这次在弄的东西整理一下，这篇主要是再次折腾 hexo 时候出现的一些问题和报错 一、安装部署报错1.1 本地调试报错 原文来自这里，http://blog.csdn.net/u012246342/article/details/51543370，其他软件占用了 4000 端口，导致 hexo -s 无法启动 解决办法启动 hexo s 的时候，用这个命令，换一个端口即可hexo s -p 5000 1.2 deploy 出错 升级到 hexo 的 3.x 版本，发觉按照正常的安装 deploy 后报错，根据提示，google 了下，发觉很多人给出了这个问题答案，https://github.com/hexojs/hexo/issues/1154 首先要确定 _config.yml 的 deploy: 后面有一个空格deploy: type: git repo: git@github.com:&lt;your github username&gt;/&lt;your github username&gt;.github.io.git branch: gh-pages 如果还报错，应该就是没有装 hexo-deployer-git 怎么安装：$ npm install hexo-deployer-git --save 然后再：$ hexo deploy 二、其他问题2.1 Cannot find module deploy 时候报错如下，但是不影响使用，参见 https://github.com/hexojs/hexo/issues/1326 &#123; [Error: Cannot find module './build/Release/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125;&#123; [Error: Cannot find module './build/default/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125;&#123; [Error: Cannot find module './build/Debug/DTraceProviderBindings'] code: 'MODULE_NOT_FOUND' &#125; 解决办法安装 hexo 的时候使用$ npm install hexo --no-optional 不过这个点在我本地没生效，issue 里多数都可以解决，目前还未找到原因 更多错误的解决办法详见参考阅读的 Xuanwo&#39;s Blog 2017-04-26 更新 上述错误在我新换的机器上仍旧出现，再次 google 查询，发觉这个错误已经有人总结了下，这里列举官网和网友的解答，本地测试完成后真的完美解决了 根据官方文档的描述，解决办法就是上述贴的$ npm install hexo --no-optional，但是不生效的话，issue 里有个哥们指出了这个办法，按照这个办法可以解决掉 $ npm install hexo –no-optionalif it doesn’t worktry$ npm uninstall hexo-cli -g$ npm install hexo-cli -g 我经过两次卸载再安装，发觉再次使用错误不在复现，完美解决这里我在列举下我本地的环境 $ npm install hexo-cli -g –no-optional hexo-util@0.6.0 postinstall /Users/song/.nvm/versions/node/v4.4.4/lib/node_modules/hexo-cli/node_modules/hexo-utilnpm run build:highlight |hexo-util@0.6.0 build:highlight /Users/song/.nvm/versions/node/v4.4.4/lib/node_modules/hexo-cli/node_modules/hexo-utilnode scripts/build_highlight_alias.js &gt; highlight_alias.json /Users/song/.nvm/versions/node/v4.4.4/bin/hexo -&gt; /Users/song/.nvm/versions/node/v4.4.4/lib/node_modules/hexo-cli/bin/hexohexo-cli@1.0.2 /Users/song/.nvm/versions/node/v4.4.4/lib/node_modules/hexo-cli├── abbrev@1.1.0├── object-assign@4.1.1├── minimist@1.2.0├── bluebird@3.5.0├── tildify@1.2.0 (os-homedir@1.0.2)├── hexo-log@0.1.2 (bunyan@1.8.10)├── chalk@1.1.3 (escape-string-regexp@1.0.5, ansi-styles@2.2.1, supports-color@2.0.0, strip-ansi@3.0.1, has-ansi@2.0.0)├── hexo-util@0.6.0 (html-entities@1.2.1, striptags@2.2.1, camel-case@3.0.0, cross-spawn@4.0.2, highlight.js@9.11.0)└── hexo-fs@0.1.6 (escape-string-regexp@1.0.5, graceful-fs@4.1.11, chokidar@1.6.1) $ hexo –versionhexo: 3.3.1hexo-cli: 1.0.2os: Darwin 15.6.0 darwin x64http_parser: 2.5.2node: 4.4.4v8: 4.5.103.35uv: 1.8.0zlib: 1.2.8ares: 1.10.1-DEVicu: 56.1modules: 46openssl: 1.0.2h &emsp;&emsp; 参考阅读 hexo 中文文档 Xuanwo’s Blog Error with DTrace (Mac OS X) Hexo installed on Mac, throw error “Cannot find module ‘./build/Release/DTraceProviderBindings’” #1922]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>hexo 报错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[健身补剂百科]]></title>
    <url>%2Fnote%2F%E5%81%A5%E8%BA%AB_%E5%81%A5%E8%BA%AB%E8%A1%A5%E5%89%82%E7%99%BE%E7%A7%91.html</url>
    <content type="text"><![CDATA[生活，就是心怀最大的善意在荆棘中穿行。即使被刺伤，亦不改初衷。 周围健身的人其实还是不是特别多，可能大家都还没有这个习惯吧，所以基本一个人去健身房，即使健身的人，对很多概念也不是特别清楚，所以打算设定一个分类是专门学习健身相关方面的分享，如果有一起健身的朋友呢，不妨可以交流下。 长久以来对健身补剂的印象就比较模糊，我刚开始健身的时候也知道那么一点，而后慢慢的寻找相关资料，最近买了肌肉兄弟的蛋白粉，附赠的一份补剂百科也算是解决了这个麻烦，想分享一下，个人觉得还是十分有用的。 一、什么是运动补剂1.1 什么是“补剂”&emsp;&emsp;“补剂”的英文是 Sports Supplements。也称“营养品”。准确的称呼，应该是“食品补充剂”，英文是：Dietary supplements。补剂起源于美国，1994 年美国通过了：食品补充剂健康教育法。要明确的是： 补充剂都属于食品类，而不属于药物，无任何激素等违禁药物成分。 &emsp;&emsp;谈到补剂首先想到的就是三个字：副作用。第一跟前面误认为补剂是药物的认识有关系。第二就是用量的问题。例如：杏仁是好东东吧，一次吃两斤里面的极微量氰化物也会让你进医院，补剂也是如此，需要根据自己的身体状况，训练水平进行合理的搭配和正确使用是没有问题的。 &emsp;&emsp;正确的使用量：需要根据自身体重，训练强度合理使用，不能依靠自我判断使用，有的顾客只是运动后才使用，那么效果就不会很好 一般是早上一勺，随餐服用，当牛奶喝。运动后半小时 1-2 勺，睡前一勺。用 30 度的温水，凉水或者牛奶冲服，一勺加 200ml 左右的水。千万不能用热水！非训练日，早上一勺，睡前一勺。 1.2 补剂的分类目前市面上主流的运动补剂基本上可以分为 6 大类补剂 蛋白补充类 蛋白粉 增肌粉 增重粉 氨基酸类 氮泵类 肌酸类 支链氨基酸类 谷氨酰胺 燃脂类 生热燃脂类 碳水化合物阻断类 促激素类 内源性 外源性（额外介绍不是补剂范围） 维生素类 水溶性维他命类 脂溶性维他命类 矿物质类 二、蛋白补充类2.1 蛋白粉&emsp;&emsp;市面上蛋白粉基本上都来源自牛奶。蛋白粉主要指乳清蛋白粉。乳清蛋白粉纯度高、吸收率高、氨基酸组成合理等诸多优势被推为“蛋白之王”易消化，高生物价值、高蛋白质功效比和高利用率，是蛋白质中的精品含有人体所需的必须氨基酸，氨基酸组成模式与骨骼肌中的氨基酸组成模式几乎完全一致，易被人体吸收，蛋白粉也分为三大类 快速吸收蛋白质 缓释吸收蛋白粉 慢速吸收蛋白粉 1、快速吸收蛋白质&emsp;&emsp;最常见的乳清蛋白粉是快速吸收蛋白粉，更快速是分离蛋白和水解蛋白，后两者价格基本是纯乳清蛋白粉的 1.5 - 2 倍。快速吸收蛋白粉适合训练后立刻使用，训练后 30 分钟内是补充蛋白质的黄金期，也叫窗口期，此时吸收速度自然是越快越好。分离蛋白水解蛋白价格相对高，是很多健美发烧友愿意选择这两种作为训练后黄金补充期的口粮。 2、缓释吸收蛋白粉&emsp;&emsp;最常见的 矩阵 可断定是一款缓释蛋白粉。一种多重复合蛋白粉，含快速吸收蛋白质（乳清·分离乳清等），又含慢速吸收蛋白质（酪蛋白·鸡蛋白等），缓释蛋白粉是一款全天用蛋白粉，快速吸收成分可满足白天代餐和睡前补充需求。要求较高、经济条件好自然是区分使用为最佳选择，训练后快速，白天代餐及睡前用缓释。刚训练不久，缓释蛋白全天覆盖也是可以的！ 3、慢速吸收蛋白粉&emsp;&emsp;以纯酪蛋白为代表，慢速吸收蛋白粉最适合睡前使用！快速吸收蛋白粉在 30-60 分钟内吸收完毕，慢速吸收蛋白粉在体内停留 6-8 小时，身体恢复重要手段是睡眠，身体生长激素分泌量恰恰都是最高峰，代谢率会大大提高！ 2.2 增肌粉&emsp;&emsp;增肌粉和蛋白粉是同源，成分表内容几乎一样只是比例不同！蛋白质含量在 60% 以上，脂肪 + 糖 + 碳水总量不超过 20% 的产品称为“蛋白粉”。脂肪 + 糖 + 碳水总量超过 20% 称为“增肌粉”或“增重粉”。 注：建议瘦体质或者短期内不介意皮质含量只冲击体重的童鞋选择增肌粉 三、氨基酸类3.1 氮泵 氮泵功效：增强肌肉充血泵感，氮泵有效成分 高浓度无水咖啡因 氮氧化物 精氨酸 &emsp;&emsp;提高训练兴奋度肌肉爆发力的起效成分：无水咖啡因。提高大脑兴奋度，注意力等，咖啡因可使运动阀值降低，提高肌肉的耐力以及爆发力。&emsp;&emsp;提高肌肉充血泵感以及扩充血管的起效成分：氮氧化合物 + 精氨酸，力量训练最怕怎么练都不充血，越练越没激情。这两种成分复合效果就是：血管扩张，增加动脉血流量、使更多血液涌入目标肌群，达到提高充血泵感的目的！ 3.2 肌酸 肌酸功效：可快速增加肌肉力量、促进新肌增长、加速疲劳恢复、提高爆发力。 &emsp;&emsp;肌酸广泛存在于各种食品中，肌酸从无负面新闻以至各大体育组织赛事都不禁用肌酸。被誉为最有效的运动补剂之一！肌酸主要成分如下 精氨酸 甘氨酸 甲硫氨酸 &emsp;&emsp;肌酸可由人体自行合成，或者食物中摄取。肌酸是人体内自然产生的必须氨基酸，肌酸在人体中存储越多，力量及运动能力也越强。研究学表明 ATP（三磷酸腺苷） 是肌肉运动最直接的能量源，ATP 量极低，训练时会消耗殆尽，休息时 ATP 会重新合成恢复到正常水平。肌酸可提高 ATP 合成率，是肌肉重新能量充沛，肌肉耐力提高的原因，肌酸加速肌肉训练后的迅速恢复，帮助肌肉更好的生长 3.3 支链氨基酸 支链氨基酸功效：最大程度保护肌肉，降低肌肉分解！ &emsp;&emsp;支链氨基酸，又名（BCAA）主要含有以下几种组成 亮氨酸（L-Leucine） 缬氨酸（L-Valine） 异亮氨酸（L-Isoleucine） &emsp;&emsp;纯支链氨基酸产品品牌之间差别不大，区别支链氨基酸哪种更好？需看亮氨酸含量，亮氨酸占得比例越高，对蛋白质合成率提高越快！支链氨基酸比例在 3:2:1 或者8:1:1 之间，支链氨基酸在增肌或者减脂期都是必须产品，减脂期一面降低饮食热量，一面提高训练强度，肌肉消耗在所难免，支链氨基酸最大程度减缓肌肉的分解 3.4 谷氨酰胺 谷氨酰胺功效：帮助肌肉吸收更多营养恢复，并且促进肌纤维的修复 &emsp;&emsp;谷氨酰胺(Glutamine) 是健美运动和健美爱好者的重要营养补剂。它（以下称谷氨酰胺）是肌肉中最丰富的游离氨基酸，约占人体游离氨基酸总量的 60%。空腹血浆谷氨酰胺浓度为 500－750umol/L。谷氨酰胺不是必需氨基酸，在疾病、营养状态不佳或高强度运动等应激状态下，机体对谷氨酰胺的需求量增加，以致自身合成不能满足需要，主要成分如下 谷氨酸 缬氨酸 异亮氨酸 &emsp;&emsp;谷氨酰胺 100% 粉末建议搭配蛋白粉或者果汁使用。可显著提高肌肉细胞水合状态，帮助肌肉吸收更多的营养促进肌肉纤维的修复；并且能在夜间最大化自身生长激素的分泌，促进肌肉生长，并且长时间的训练导致的免疫下降也可通过谷氨酰胺进行提升。 使用方法：训练前 5-10g 或者睡前 5-10g，根据不同的体重训练强度调节即可。 支链氨基酸和谷氨酰胺二选一可以么？理论上是不可以的，针对性不同。如果非要二选一，增机器建议服用谷氨酰胺，减脂期更倾向于支链氨基酸 四、燃脂类补剂4.1 生热燃脂类 生热燃脂类功效：耐力提高，出汗多等 &emsp;&amp;emsp美容院基本必须品，严格说已经脱离了运动补剂的范畴了，此类主要成分是氢氧基酸果酸(Alpha Hydroxy Acid),这种成分可进入深层皮肤，去除皮下油脂.减脂期原则： 1.注意饮食规律 2.高强度训练建议力量运动(消耗体内糖分)有氧运动（有益于调动脂肪燃烧供能） 3.燃脂类补剂的辅助促进训练是核心，饮食是基础，补剂是辅助促进。1 款复合型兼职补剂 +1 款 CLA 基本减脂补剂搭配训练，CLA 搭配饮食 主要奇效成分 咖啡因：减脂关键是最大化促使脂肪细胞释放存储的脂肪，训练前摄入咖啡因可以在训练中促使脂肪细胞最大化释放之前存储的脂肪 育亨宾：有效提高脂肪燃烧代谢率！成分提取自西非植物育亨宾树皮。使用育亨宾后脂肪代谢率几乎提高到两倍。 注：肝脏及心脏疾病怀孕期及哺乳期不建议使用这款燃脂神器 绿茶提取物：提高代谢率提高卡路里消耗量，保护关节和促进肌肉恢复 左旋肉碱：促进脂肪进入线粒体，训练中被有效的燃烧消耗掉，提高训练前左旋肉碱摄入量，帮助最大化代谢脂肪，左旋肉碱是一种氨基酸温和无刺激，可由身体自行产生，也可通过肉食中提取，牛羊肉含量较高 注：绿茶提取物和左旋肉碱是最温和的产品，无刺激燃脂类补剂成分。市面上有很多两种或单一成分的产品，搭配足量的有氧训练强度，才可发挥最大效果。 辣椒素 使用方法基本相同：早晨一次或者训练前一次使用感受基本如下：明显的兴奋、心跳加速，发热，有时候会有轻微胃部灼烧感或者眩晕等 专业复合型燃脂产品，基本使用后感官刺激不同，体脂差异会影响最终效果 4.2 碳水阻断类 此类产品的作用帮助你阻断摄入过量的碳水化合物转化为脂肪存储！ &emsp;&emsp;真正引起脂肪存储的罪魁祸首并不是油腻食物，是高碳水（尤其是快速吸收型碳水，如白米饭等），因此类碳水化合物摄入后迅速提高血糖，从而引起体内胰岛素水平的大幅度提高，此类碳水非常容易吸收消化，吸收完毕后，胰岛素水平又会迅速下降，胰岛素大幅度的波动，减脂期通常建议大家使用燕麦、红薯等缓释吸收碳水的根本原因！目前市面上此类补剂并不是很多，基本成分都大致相同，主要起效的成分是：白豌豆提取物成分(Kidey Bean Extract),至于实际效果，建议适当饮食。 4.3 脂肪阻断类这类补剂成分较为单一，基本就是Chitosan（壳聚糖，一般由虾、螃蟹提炼），壳聚糖在肠道内与脂肪及胆汁酸集合，可阻断脂肪消化与吸收，清理胆道，降低中性脂肪及低密度脂蛋白。美国BB网此类产品只有4款目前较为火爆的CLA（共轭也有算），有事i在于不仅避免存储脂肪，提高脂肪的燃烧率，提高瘦肌肉比列、密度和质量！将共轭亚油酸仅仅归为脂肪阻断剂，其实委屈它了。 五、促进类补剂5.1 睾酮素健美运动中男士关于增加肌肉所需的 5 种主要激素 睾酮素 生长激素 胰岛素生长因子 黄体激素 胰岛素 &emsp;&emsp;目前合法属于属于运动补剂范畴内的促激素产品都是针对睾酮素进行研发并使用的，睾酮素主要由睾丸酮合成分泌，女性体内也有睾酮素，仅会分泌极少量。正常男性体内睾酮素水平平均是女性的 20 倍。健美运动中肌肉增长睾酮素影响肌肉合成效率，睾酮素可加快蛋白合成，提高肌肉修复生长速度，睾酮素为增肌的“源动力”。 为什么使用产品额外刺激身体分泌更多的睾酮素，原因如下： 1、高强度力量训练者&emsp;&emsp;力量训练可刺激身体分泌更多的睾酮素，帮助肌肉更快恢复和生长，深蹲是最好的天然促睾酮训练动作，高强度的力量训练时过渡训练反而会导致体内睾酮素水平大幅度下降，以至于身体自身的分泌量不能满足肌肉的生长需要！ 注：建议高强度训练者使用促激素补剂，促使身体分泌更多的睾酮素帮助肌肉恢复生长 2、年龄偏大的健美爱好者&emsp;&emsp;男性 30 岁是临界点，30 岁后的男性的睾酮素分泌量基本以每年 2% 递减，建议年龄偏大的健美爱好者使用促激素产品来帮助身体分泌更多的睾酮素。补剂和激素产品区别，促激素类补剂是内源性产品，通过使用产品来激发自身产生更多的睾酮素以促进肌肉修复和生长。激素类称为外源性产品，本身就是人工合成的睾酮素。吃进线程的睾酮素，非自身分泌获得，大量使用会导致脱发、睾丸萎缩等问题。大量口服人工合成睾酮素后，自身睾酮素水平会非常高，此时大脑中枢发送到睾丸的指令是：体内睾酮素指令含量充足，睾丸会停止工作，长时间服用会导致出现睾丸萎缩的情况。停用人工合成的睾酮素后，自身睾丸会重新开始工作。 促激素补剂并非激素，而是激发自身分泌更多激素！ 本人保持更新 &emsp;&emsp; 参考阅读 百度百科 - 支链氨基酸 百度百科 - 谷氨酰胺 百度百科 - 睾酮素]]></content>
      <categories>
        <category>生命在于运动</category>
      </categories>
      <tags>
        <tag>健身</tag>
        <tag>健身补剂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub / GitLab 的 Webhooks 进行网站自动化部署]]></title>
    <url>%2Fnote%2Fgit_GitHub-GitLab-%E7%9A%84-Webhooks-%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%AB%99%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2.html</url>
    <content type="text"><![CDATA[这世界上没有什么一步登天的幸福，你唯一可以创造未来的方式，就是脚踏实地向前走。 一直没写这个东西，今天阅兵完第一天上班，整天处于神游状态，想想还是弄点啥，把这个折腾出来然后更新博客还是可以的，最终做到的效果就是，每当有新的 commit push 到 master 分支的时候，就自动在服务器上进行 git pull 拉取最新的代码，来更新我的博客 一、web hooks1.1 过程可以看到使用了 webhooks 之后明显省去了上机器手动 PULL 的过程 1.2 脚本 这个脚本的目的在于能够处理 github/gitlab 因 push event 产生的一个 HTTP POST 请求，而后触发一系列操作，在我这个场景里，就是 pull 代码即可，当然也可以完成其他事情 我是 PHP 的脚本来完成的，本身不会 PHP，花了点时间弄这个脚本，主要机器上跑的 LNMP 的架构，所以 PHP 省事，不用安装其他东西，而且找了很多网上的脚本已不能用了，看了看 github 发送 post 请求的参数在变化了，所以如果不可用，请根据 github 官方的 request 里的内容来修改脚本，当然组合可以很多，有人用 nginx + lua 的，还有 flask 的，还有 nodejs 的，当然了，只要能处理 POST 请求，无所谓哪种，看个人喜好而已。 脚本如下：&lt;?php// Set Variables$LOG_FILE = dirname(__FILE__).'&lt;/path/log/hook_result.log&gt;';$LOCAL_ROOT = "&lt;/path/blog?";$LOCAL_REPO_NAME = "&lt;repo_name&gt;";$LOCAL_REPO = "&#123;$LOCAL_ROOT&#125;/&#123;$LOCAL_REPO_NAME&#125;";$REMOTE_REPO = "git@github.com:&lt;username&gt;/&lt;username&gt;.github.io.git";$BRANCH = "master";// json decode info from Github$info = json_decode(file_get_contents("php://input"), true);$hooks_username = $info['commits'][0]['author']['username'];// 验证来源if ($hooks_username == '&lt;username&gt;') &#123; echo "ok"; // 判断本地仓库是否存在，并且分支匹配 $branch = explode('/', $info['ref']); if( is_dir($LOCAL_REPO.'/.git') &amp;&amp; $branch[2] == $BRANCH ) &#123; //exec command $pull_cmd = "cd &#123;$LOCAL_REPO&#125; &amp;&amp; sudo git pull"; exec($pull_cmd, $array); print_r($array); //write log file_put_contents($LOG_FILE, date("[Y-m-d H:i:s]")." success pull: ".$_SERVER['REMOTE_ADDR']."\n", FILE_APPEND|LOCK_EX); &#125;&#125; else &#123; echo "not ok"; // If the repo does not exist, then clone it into the parent directory $clone_cmd = "cd &#123;$LOCAL_ROOT&#125; &amp;&amp; sudo git clone &#123;$REMOTE_REPO&#125;"; exec($clone_cmd); file_put_contents($LOG_FILE, date("[Y-m-d H:i:s]")." invalid access: ".$_SERVER['REMOTE_ADDR']."\n", FILE_APPEND|LOCK_EX);&#125;?&gt; 请将 &lt;&gt; 里的内容修改为自己的实际路径，另外，因为我 PHP 进程启动的用户是不能去执行 git pull 的，请放开 PHP 配置文件里的 disable_function 以及检查是否有权限进行同步，否则报错，在 github response 上没法看到，纠结了很久 另外，请保证这个 PHP 文件能被访问到，如 http://x.x.x.x./test_hooks.php 这个请求地址待会就是我们要通过 github 发送 POST 请求的地址 1.3 github 设置1、项目里新增一个 webhooks 2、查看 http request 3、每次发送请求得到的 response 到此，每次像 github 中推送更新就可以完成整个 webhooks 的流程 每次推送更新查看服务器日志,有如下的日志表示推送成功192.30.252.41 - - [11/Sep/2015:10:10:16 +0800] "POST /test_hooks.php HTTP/1.1" 200 5 "-" "GitHub-Hookshot/66235e3" - 然后可以查看 github 上的 webhooks 日志，这里的信息是刚才上面的 PHP 定义的 &emsp;&emsp; 参考阅读 GitHub Developer About webhooks wufuli.com 的博客 携程设计委员会 博客 - 葱丝瓣酱 博客 - 过儿 尘埃落定 MANA - DOT]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>gitlab</tag>
        <tag>webhooks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 报警之微信报警]]></title>
    <url>%2Fnote%2Fzabbix-%E6%8A%A5%E8%AD%A6%E4%B9%8B%E5%BE%AE%E4%BF%A1%E6%8A%A5%E8%AD%A6.html</url>
    <content type="text"><![CDATA[你只有先上轨道，才能追上那些在前面的理想生活。不是谁都能体面地倔强着生活，但谁都可以用坚持和努力，实现自己的那份倔强 日常都是短信和邮件的报警，虽然已经可以满足需求，但是对于现在微信这么流行的情况下能用微信报警自然更方便，更加迅速和实时，毕竟现在微信基本上天天都会使用，而且流量现在也比较便宜 一、微信设置1.1 微信号介绍看 微信·公众平台 首页介绍也看到微信·公众平台 有三种类型 服务号 公众平台服务号，是公众平台的一种帐号类型，旨在为用户提供服务。 1个月（自然月）内仅可以发送4条群发消息。 发给订阅用户（粉丝）的消息，会显示在对方的聊天列表中。相对应微信的首页。 服务号会在订阅用户（粉丝）的通讯录中。通讯录中有一个服务号的文件夹，点开可以查看所有服务号。 服务号可申请自定义菜单。 订阅号 公众平台订阅号，是公众平台的一种帐号类型，旨在为用户提供信息。 每天（24小时内）可以发送1条群发消息。 发给订阅用户（粉丝）的消息，将会显示在对方的“订阅号”文件夹中。点击两次才可以打开。 在订阅用户（粉丝）的通讯录中，订阅号将被放入订阅号文件夹中。 企业号 企业号适用于企业与员工或上下游供应链之间的沟通。 企业可以主动发消息给员工，消息量不受限制。 企业号出现在微信会话列表首层，在通讯录中有单独的分类。 可以自定义菜单。 拥有多个子号。 5、更加关注与安全，需要双方认证。 关于三种类型账号的区别，可自行查看相关仔细说明，就监控而言，订阅号和企业号都能满足需求，但是企业号限制更少，发送消息更加方便，限制更少，外加上个人可以申请一个关注者 50 人限制的企业体验号，免费的哟，对于监控人员而言，这已经是足够了，所以后续都以 微信企业号来进行讲述 zabbix + 微信企业号 报警的步骤。 1.2 开通企业微信号根据提示进行注册，注意有些选项已经提示很清楚了，一旦设置就不能修改，所以填写这些选项之前想清楚，其他按照提示即可 二、设置报警2.1 设置企业微信号配置 zabbix 完成微信报警之前得先对企业号进行一点设置 1、申请完成这里唯独要注意的选择 【团队】 2、邮箱激活3、扫描二维码登录4、新建一个组织架构这里我新建了一个【运维组】,新增一名成员，作为报警成员。设置完成之后用户本身即可通过二维码进行扫码关注，双方验证通过，即可 5、新建一个应用，用作监控，获取应用 id 6、指定该应用的管理员，获取 corpid、sceret 这里有几个参数后面是需要的，应用的 id、corpid、sceret，下面开始操刀动手 2.2 发送微信消息 微信·企业号开发文档 微信·企业号 接口调试工具 通过文档和提供的调试工具，可以看到玩法，首先得获取 token ，然后才能进行下一步，目前的功能只需要实现发送微信消息即可，那么先获取 token，再对特定的人发送微信消息即可完成 1、获取 token，网友 安安 已经给出了怎么去获取 token 的步骤和方法和脚本，token 是一个有有效时间的密钥用于后续操作认证。 Https请求方式:POST URL:https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=ACCESS_TOKEN 参数 必须 说明 access_token 是 调用接口凭证 安安给出的获取 access_token 如下，后期脚本也是在这个基础上进行扩充 #!/usr/bin/env python#coding:utf-8#blog: www.anbooks.cn import sysimport urllibimport urllib2import timeimport jsonfrom optparse import OptionParser reload(sys)sys.setdefaultencoding('utf-8') class Token(object): def __init__(self, corpid, corpsecret): self.baseurl = 'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=&#123;0&#125;&amp;corpsecret=&#123;1&#125;'.format(corpid, corpsecret) self.expire_time = sys.maxint def get_token(self): if self.expire_time &gt; time.time(): request = urllib2.Request(self.baseurl) response = urllib2.urlopen(request) ret = response.read().strip() ret = json.loads(ret) if 'errcode' in ret.keys(): print &gt;&gt; ret['errmsg'],sys.stderr sys.exit(1) self.expire_time = time.time() + ret['expires_in'] self.access_token = ret['access_token'] return self.access_token 2、发送 text 微信·企业号还支持发送其他类型的信息等，对于监控而言，发送 text 已经足够 post 数据根据文档的例子 &#123; "touser": "UserID1|UserID2|UserID3", "toparty": " PartyID1 | PartyID2 ", "totag": " TagID1 | TagID2 ", "msgtype": "text", "agentid": "1", "text": &#123; "content": "Holiday Request For Pony(http://xxxxx)" &#125;, "safe":"0"&#125; 三、微信企业号功能3.1 企业号消息服务在系统公告中看到企业号的一些帮助信息，觉得企业微信号功能还是很强大的，比如这个企业号消息服务，官方已经有详细的说明，这里不在赘述，开通请看这里 开通微信企业号消息服务 可以非常方便不是好友的情况下实现发送非常定制化的消息，并且可以自己定制发送的人的级别等等，非常多的定制规则 不加好友进行聊天 3.2 企业号第三方应用企业微信一开始就开放了 第三方应用平台 ,其中官方的 详细介绍 也写的比较清楚，这里用到的最明显的就是和 RTX 进行双向同步，可以利用微信直接回复 RTX 消息，需要安装一个插件 RTX微信企业号插件下载 目前更多的功能我也没用到，更多的功能请自行查看系统公告，里面官方的说明写的也很详细 &emsp;&emsp; 参考阅读 斌哥 微信报警 小东的专栏 杨容 微信报警 安安 运维者 微信·企业号 开发文档 微信·企业号 接口调试工具 微信·企业号 系统公告 微信·公众平台 接口调试工具 微信·公众平台 开发文档]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix 微信报警</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python web 程序的几种部署方式解读]]></title>
    <url>%2Fnote%2Fpython-web-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%87%A0%E7%A7%8D%E9%83%A8%E7%BD%B2%E6%96%B9%E5%BC%8F.html</url>
    <content type="text"><![CDATA[别为不属于你的观众，演不擅长的人生！ 这两年的运维人员多数人都折腾过 python 的 web 框架，python 的兴起也是一方面，但是多数人仅仅只是写，部署到线上算是另一码事，看到这篇文章介绍的比较全面，转载之，转载自 鲁塔弗的博客 一、简介1.1 简介python 有很多 web 开发框架，代码写完了，部署上线是个大事，通常来说，web 应用一般是三层结构 web server —-&gt;application —–&gt; DB server 主流的 web server 一个巴掌就能数出来，apache，lighttpd，nginx，iis application, 中文名叫做应用服务，就是你基于某个 web framework 写的应用代码 DB server 泛指存储服务，web 开发中用 mysql 比较多，最近几年因为网站规模扩大，memcache，redis 这种 key-value 等存储也流行开来 放在最前面的 web server 主要有 3 个功能 高效率处理静态文件,web server 基本上都是用 c 开发，调用是 native 的函数，对 IO，文件传输都做针对性的优化 充当一个简易的网络防火墙，可以 deny 一些 ip，简单的控制并发连接数量等等，聊胜于无 处理高并发短连接请求，把成千上万用户的 request 通过内网的几十个长连接进行转发，原因一个是 web server 处理高并发很专业，另外一个原因是大部分的 application 所用的框架都不具备处理高并发的能力 实际上，市面上有部分 web framework 由于内置了支持 epoll/kqueue 等高效网络库，而具备了处理高并发的能力，比如说 python 的 tornado，java 系的 tomcat,jetty 等等，有人就去掉前端的 web server，直接裸奔，但是在部署公网应用时候，最好别这样做，因为前面提到的 1,2 两个原因，用户 brower 到 web server 的网络状况是千奇百怪，你无法想象的， web server 强烈建议使用 nginx，原因有三 性能非常卓越，非常稳定 安装简单，依赖包少 conf 文件非常容易配置，比 apache/lighttpd 都要简单 1.2 部署 mod_python这是 apache 内置的模块，很严重的依赖于 mod_python 编译使用的 python 版本，和 apache 配套使用，不推荐 cgi这个太 old，不推荐，而且 nginx 不支持 cgi 方式，只能用 lighttpd 或者 apache fastcgi这个是目前流行最广的做法，通过 flup 模块来支持的，在 nginx 里对应的配置指令是 fastcgi_pass spawn-fcgi这个是 fastcgi 多进程管理程序，lighttpd 安装包附带的，和 flup 效果一样，区别是 flup 是 python 代码级引入，spawn-fcgi 是外部程序。spawn-fcgi 用途很广，可以支持任意语言开发的代码，php, python, perl,只要你代码实现了 fastcgi 接口，它都可以帮你管理你的进程 scgi全名是 Simple Common Gateway Interface，也是 cgi 的替代版本，scgi 协议很简单,我觉得和 fastcgi 差不多，只是没有怎么推广开来，nginx 对应的配置指令是 scgi_pass，你想用就用，flup 也支持。 httpnginx 使用 proxy_pass 转发,这个要求后端 appplication 必须内置一个能处理高并发的 http server，在 python 的 web 框架当中，只能选择 tornado. tornadopython 程序员喜欢发明轮子，tornado 除了是一个 web framework 之外，它还可以单独提供高性能 http server，所以，如果你采用其他 python 框架写代码，比如说 bottle，也一样可以通过 import tornado 来启动一个高性能的 http server，同样的可以采用 http 协议和 nginx 一起来部署。扩展开来，python 包里面能处理高并发的 http server 还有很多，比如说 gevent，也可以被其他框架引用来支持 http 方式部署。 现实当中，用 java 来做 web 程序，通常就用 http 和 nginx 配合，应用服务器选择 tomcat 或者 jetty uwsgi,包括4部分组成 uwsgi协议 web server内置支持协议模块 application服务器协议支持模块 进程控制程序 nginx 从 0.8.4 开始内置支持 uwsgi 协议，uwsgi 协议非常简单，一个 4 个字节 header + 一个 body，body 可以是很多协议的包，比如说 http，cgi 等（通过 header 里面字段标示），我曾经做个一个小规模的性能对比测试，结果表明，uwsgi 和 fastcgi 相比，性能没有太明显的优势,也可能是数据集较小的原因 uwsgi 的特点在于自带的进程控制程序.它是用 c 语言编写，使用 natvie 函数，其实和 spawn-fcgi/php-fpm 类似。所以 uwsgi 可以支持多种应用框架，包括( python, lua, ruby, erlang, go )等等 Gunicorn和 uwsgi 类似的工具，从 rails 的部署工具 (Unicorn) 移植过来的。但是它使用的协议是 WSGI，全称是 Python Web Server Gateway Interface ，这是 python2.5 时定义的官方标准( PEP 333 )，根红苗正，而且部署比较简单，http://gunicorn.org/ 上有详细教程 mod_wsgiapache 的一个 module，也是支持 WSGI 协议,源码地址在 https://code.google.com/p/modwsgi/ 1.3 fastcgi 协议和 http 协议在代码部署中的的优劣对比 fastcgi 虽然是二进制协议，相对于 http 协议，并不节省资源。二进制协议，只能节省数字的表达，比如 1234567，用字符串表示需要 7 个 Byte，用数字就是 4 个 Byte，而字符串到哪里都一样 fastcgi 在传输数据的时候，为了兼容 cgi 协议，还要带上一堆 cgi 的环境变量，所以和 http 协议相比，用 fastcgi 传输数据并不省，反而多一些 fastcgi 唯一的优点是，它是长连接的，用户并发 1000 个 request，fastcgi 可能就用 10 个 链接转发给后端的 appplication，如果用 http 协议，那来多少给多少，会向后端 appplication 发起 1000 个请求 http 代理转发方式，在面对超高并发的情况下会出问题，因为 tcp 协议栈当中，port 是 int16 整型 你本地新建一个 connect，需要消耗一个端口，最多能到 65536。外部并发几十万个请求，port 池耗干，你的服务器只能拒绝响应了 文章最后作者喜欢个人站点程序习惯是用 fastcgi 协议部署 python 程序，简单省事，选择技术方案，一定要选择最简单最常见的。推荐大家尝试 Gunicorn ，这是未来发展方向。 &emsp;&emsp; 参考阅读 鲁塔弗的博客]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python web 部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python web 开发中常用的第三方库]]></title>
    <url>%2Fnote%2Fpython-web-%E5%BC%80%E5%8F%91%E4%B8%AD%E5%B8%B8%E7%94%A8%E7%9A%84%E7%AC%AC%E4%B8%89%E6%96%B9%E5%BA%93.html</url>
    <content type="text"><![CDATA[大部分人在二三十岁上就死去了，因为过了这个年龄，他们只是自己的影子，此后的余生则是在模仿自己中度过，日复一日，更机械，更装腔作势地重复他们在有生之年的所作所为，所思所想，所爱所恨 这篇除了学习之外，也算是一个扫盲的帖，由于运维出生，写东西也都是仅仅是写点东西，而不从开发的角度看待这个问题，没有构建工具，没有完善的部署，都是单干，很明显不走开发流程，所以看到这篇帖子转发过来 一、Python Web开发中常用的第三方库经常有朋友问，如果用 Python 来做 Web 开发，该选用什么框架？用 Pyramid 开发 Web 该选用怎样的组合等问题？在这里我将介绍一些 Python Web 开发中常用的第三方库。基本适用于 Django 以外的 Web 框架 (Pyramid, Flask, Tornado, Web.py, Bottle 等). 1.1 ORM SQLAlchemy在 ORM 方面，首选 SQLAlchemy，没有之一!支持 SQLite, PostgreSQL, MySQL, Oracle, MS-SQL, Firebird, Sybase 等主流关系数据库系统支持的 Python 环境有 Python2、Python3，PyPy 以及 Jython。主要的特性请移步 Key Features of SQLAlchemy推荐和数据库迁移工具 Alemic 搭配使用 MongoEngine如果你用 MongoDB，推荐 MongoEngine. 1.2 Template Engine在模板引擎方便选择也是比较多， 有 Chameleon、Jinja2、Mako等可供选择，用过 Chameleon 和 Jinja2，性能都非常好. 1.3 Form Engine WTForms，推荐！ 1.4 Cache Engine &amp; Session Store Beaker 缓存和 Session 管理首选 Beaker， 没有之一！ 可以搭配文件、 dbm 、memcached、内存、数据库、NoSQL 等作为存储后端. 如果你用Pyramid 作为 Web 框架，那么可以直接使用 pyramid_beaker. 二、Others2.1 环境构建 buildout 很强大，参考 用Buildout来构建Python项目 virtualenv 这个大家应该都用过，简单易用 2.2 任务队列 Celery （芹菜）一个分布式异步任务队列， 很强大！ RQ 这是一个轻量级的任务队列，基于Redis， 可以尝试一下。 2.3 WebServer Gunicorn , 推荐！ uWSGI mod_wsgi，搭配 Apache 一起使用 2.4 工具 Fabric, 可以通过它完成自动化部署和常规的运维等工作。《Fabric-让部署变得简单》_PPT Supervisor 一个强大的进程管理工具，用来管理各种服务（比如Gunicorn、Celery等），服务挂掉时 Supervisor 会帮自动重启服务。 2.5 导出报表数据 Tablib，这个挺好用，支持导出Excel, JSON, YAML, HTML, TSV, CSV格式数据， 我创建了一个 Pyramid 插件可以集成到 Pyramid 项目中使用 pyramid_tablib 导出 PDF 有 reportlab、PyPDF2 2.6 第三方身份验证 velruse, 支持各大网站的身份验证， 国内部分我已经加入了 Weibo、Douban、QQ、Taobao、Renren，并 merge 到主版本库中。欢迎使用！ 2.7 helper webhelpers, 提供了一系列实用函数， 文档地址 To Be Continued… &emsp;&emsp; 参考阅读 lxneng.com]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python web 开发第三方库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 自定义 item key 监控 MySQL 详解]]></title>
    <url>%2Fnote%2Fzabbix%20%E8%87%AA%E5%AE%9A%E4%B9%89%20item%20key%20%E7%9B%91%E6%8E%A7%20MySQL%20%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[人生在世，最可耻的事情，莫过于你明明有公平的机会实现梦想，却因自己的不努力而错失，然后回头告诉所有人，它一文不值 其实这个用到频率还是蛮多的，但是一直没有机会去写，这次重新弄了一次，在同事的帮助下明白了更多的东西，所以打算从头写个详细的过程，争取一次性说个明白，key 的关键性不用多说，key 的灵活性决定你可以监控的内容 一、item key1.1 介绍 A flexible parameter is a parameter which accepts an argument. For example, in vfs.fs.size[] the asterisk symbol ‘‘ indicates a flexible parameter. ‘*’ is any string that will be passed as an argument to the parameter. 大致的意思是 key 是一种灵活的，可以接受参数形式的一种参数形式。例如,在vfs.fs。大小 [] 星号 “” 符号表示一个灵活的参数。‘*’ 是任何字符串,将作为参数传递给参数。正确定义示例: vfs.fs.size[/] vfs.fs.size[/opt] 1.2 格式给出官方的一个简易图 所以看出构造 key 的关键在于 parameters，所以自定义 key 关键在于构造这这个 parameters。下面的内容都会从一个详细的实例构造一个自定义的 key 监控 mysql 的状态 1.3 抓取数据脚本 数据的抓取是基本引用，没有数据的传递后面都是虚的，所以这是自定义 key 的底层核心就是脚本了 新增 agent 端关于监控 mysql 的 userparameter_mysql.conf 文件，存放到 ${zabbix_conf_path}/zabbix_agentd.d/下，整个目录结构如下： ├── scripts│ └── check_mysql.sh├── zabbix_agentd.conf└── zabbix_agentd.d ├── userparameter_mysql.conf #!/bin/bashmysql="/usr/local/mysql/bin/mysql"mysqladmin="/usr/local/mysql/bin/mysqladmin"zabbix_sender="/usr/bin/zabbix_sender"# 定义位置参数,可以从 server 传递MYSQL_USER=$2MYSQL_PASSWORD=$3MYSQL_PORT=$4var=$5MYSQL_Host="127.0.0.1"# 如果 server 端没有传递用户名和口令过来就赋值[ "$&#123;MYSQL_USER&#125;" = '' ] &amp;&amp; MYSQL_USER=用户名[ "$&#123;MYSQL_PASSWORD&#125;" = '' ] &amp;&amp; MYSQL_PASSWORD=口令if [ ! -x "$mysql" ];then rpm -q mysql &amp;&amp; mysql=`which mysql` || exit 1 mysqladmin=`which mysqladmin`fimysqlclient="$&#123;mysql&#125; -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PASSWORD&#125; -h$&#123;MYSQL_Host&#125; -P$&#123;MYSQL_PORT&#125;"Zabbix_Server=$(awk -F"," '/Server=/ &#123;print $2&#125;' /etc/zabbix/zabbix_agentd.conf|egrep -v "(^$)")Hostname=$(egrep "\bHostname=\b" /etc/zabbix/zabbix_agentd.conf|awk -F"=" '&#123;print $2&#125;')# 函数的值作为zabbix 的 item 项的 keyfunction status &#123; [ "$&#123;var&#125;" = '' ] &amp;&amp; echo ""|| $mysqlclient -e 'show status'|grep -v Variable_name|grep "\b$&#123;var&#125;\b"|awk '&#123;print $2&#125;'&#125;function ping &#123; $mysqladmin -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PASSWORD&#125; -h$&#123;MYSQL_Host&#125; -P$&#123;MYSQL_PORT&#125; ping|grep alive|wc -l&#125;function version &#123; $&#123;mysql&#125; -V | cut -f6 -d" " | sed 's/,//'&#125;function slave_delay &#123; info=$($mysqlclient -e "show slave status\G;" | grep -E "Seconds_Behind_Master" | awk '&#123;print $2&#125;') if [[ $info =~ [0-9]+ ]]; then echo $info exit 0 else# $&#123;mysql&#125; -u$&#123;MYSQL_USER&#125; -p$&#123;MYSQL_PASSWORD&#125; -h$&#123;MYSQL_Host&#125; -e "show slave status\G;" | grep "Seconds_Behind_Master" | cut -d':' -f 2|sed "s/^ //g" echo "-1" exit 1 fi&#125;function slave_running_status &#123; status=$($mysqlclient -e "show slave status\G;") if [ "$&#123;status&#125;" == "" ];then echo 0 fi Slave_IO_Running="$($mysqlclient -e "show slave status\G;" | grep "\bSlave_IO_Running\b"|column -t|awk '&#123;print $2&#125;'| tr 'A-Z' 'a-z')" Slave_SQL_Running="$($mysqlclient -e "show slave status\G;" | grep "\bSlave_SQL_Running\b"|column -t|awk '&#123;print $2&#125;'| tr 'A-Z' 'a-z')" Slave_Last_IO_Error=$($mysqlclient -e "show slave status\G;" | grep -E "\bLast_IO_Error\b"|column -t|sed "s/Last_IO_Error://g") Slave_Last_SQL_Error=$($mysqlclient -e "show slave status\G;" | grep -E "\bLast_SQL_Error\b"|column -t|sed "s/Last_SQL_Error://g") Slave_Last_IO_Error_Timestamp=$($mysqlclient -e "show slave status\G;" |column -t| grep -E "\bLast_IO_Error_Timestamp\b") Slave_Last_SQL_Error_Timestamp=$($mysqlclient -e "show slave status\G;" |column -t| grep -E "\bLast_SQL_Error_Timestamp\b") if [ "$&#123;Slave_Last_IO_Error&#125;" != "" -o "$&#123;Slave_Last_SQL_Error&#125;" != "" ];then# msg="Slave_Last_IO_Error_Timestamp:=== $&#123;Slave_Last_IO_Error_Timestamp&#125;\n Slave_Last_IO_Error:=== "$&#123;Slave_Last_IO_Error&#125;"\n$&#123;Slave_Last_SQL_Error_Timestamp&#125;\nSlave_Last_SQL_Error:=== "$&#123;Slave_Last_SQL_Error&#125;""# $&#123;zabbix_sender&#125; -z $&#123;Zabbix_Server&#125; -p 10051 -s "$&#123;Hostname&#125;" -k mysql_slave_error -o "$&#123;msg&#125;" -vv echo 4 elif [ "$&#123;Slave_IO_Running&#125;" != "yes" -a "$&#123;Slave_SQL_Running&#125;" != "yes" ];then echo 3 elif [ "$&#123;Slave_IO_Running&#125;" == "no" ];then echo 2 elif [ "$&#123;Slave_SQL_Running&#125;" == "no" ];then echo 1 else echo 0 fi&#125;function help() &#123; echo "usage: $0 [status VAR|ping|version|slave_delay|slave_running_status] USER PASS PORT"&#125;case "$1" in status) status ;; ping) ping ;; version) version ;; slave_delay) slave_delay ;; slave_running_status) slave_running_status ;; *) help;;esac 这个脚本不难看懂，核心在于抓出来几个数据可以作为 zabbix 的 key，这样 zabbix server 在配置的时候可以使用这几个 key 拿到我们想要的所有结果，mysql 性能参数基本都在 status 中。 另外这个脚本来自松爷的 github 上的脚本改动而来，并且我这里在配置的时候，将 MySQL 的用户名和口令其实可以不放在脚本里，待会配置 templates 的时候可以传递，这样不同的 agentd 其实都可以不保存账号口令，安全性的话会好一点，所以要求所有的 agentd 上的 MySQL 都有这个监控的用户和相同的口令。 我们最好来验证脚本是否正确，再进行下一步# ./check_mysql.shusage: ./check_mysql.sh [status VAR|ping|version|slave_delay|slave_running_status] USER PASS PORT# ./check_mysql.sh ping 用户名 口令 33061# ./check_mysql.sh status 用户名 口令 3306 Questions2 再次注意这里传参格式，参考脚本中各个参数位置即可，status 需要额外提供一个参数 1.4 配置 userparameter 数据抓取的底层已经脚本可以搞定，下面来定义 zabbix 的 key，即 UserParameter 首先对 userparameter 有个认识，详情需要查看官方文档了 cat /etc/zabbix/zabbix_agentd.d/userparameter_mysql.confUserParameter=mysql.status[*],/etc/zabbix/scripts/check_mysql.sh status $1 $2 $3 $4 $5UserParameter=mysql.slave_delay[*],/etc/zabbix/scripts/check_mysql.sh slave_delay $1 $2 $3 $4 $5UserParameter=mysql.slave_running_status[*],/etc/zabbix/scripts/check_mysql.sh slave_running_status $1 $2 $3 $4 $5UserParameter=mysql.ping[*],/etc/zabbix/scripts/check_mysql.sh ping $1 $2 $3 $4 $5#UserParameter=mysql.versions[*],/etc/zabbix/scripts/check_mysql.sh version $1 $2 $3 $4 $5 这里需要注意的是各个位置参数根据脚本里传参的位置相互匹配，后面也就是 server 端也必须按照这个格式来进行传参才可以正常运行 1.5 验证数据抓取 这里这一步如果胸有成竹可以忽略，但是最好进行一下验证，否则配置模板那么长时间，结果最后还出错，挺麻烦的 # zabbix_get -s [mysql_server_ip] -k mysql.status[用户名,口令,3306,Questions]2 这里的 [] 中传入的第一个参数对应脚本里 $2 二、配置 templates 后端数据已验证完毕，接下来按照刚才的格式配置 templates 即可，唯一注意的可能就是需要设置一个 templates Macro 这里给出一张根据这个脚本修改过的 templates 图，注意 key 部分，根据脚本将用户名和口令传给了 agentd，同样注意位置参数和脚本相互匹配 因为假设所有的 agentd 上都有相同的用户名和密码，所以设定 template Macro，用以集中管理密码，这样每台机器上完全可以不保存口令和密码 我目前是在每台机器上新建了一个监控用户，可以放在初始化脚本里grant replication client on *.* to '用户名'@'127.0.0.1' identified by '口令'; 完成上面两个步骤之后，过一会查看 lasted data 数据部分是否会有数据，而且经过了这个之后，如果想增加监控项，脚本中可以无需改动，基本上性能指标数据都在脚本中 status 之后的参数里，可以根据个人喜好自行增减。这样一个完整的监控 mysql 的自定义 item 就全部完成 这个思路可以引申到使用 zabbix agentd 监控的任何客户端中，就先写到这里 &emsp;&emsp; 参考阅读 Zabbix Documentation 2.4 - Item key]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix 自定义 key</tag>
        <tag>zabbix mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grafana template setting]]></title>
    <url>%2Fnote%2Fgrafana-template-setting.html</url>
    <content type="text"><![CDATA[许多人的所谓成熟，不过是被世俗磨去了棱角，变得世故而实际了。那不是成熟，而是精神的早衰和个性的夭亡。真正的成熟，应当是独立的个性的形成，真实自我的发现，精神上的结果和丰收 不得不说这个官方文档都没有，只能借助作者的一段 YouTube 视频介绍，对整个 template 作一个简单的了解，线上机器开始同一平台机器多了之后开始不得不考虑这个功能，单一的手动加这个真心会崩溃的，所以花了点时间看了这个视频，思路很明确 一、grafana template1.1 准备zabbix 可以称得上企业级的监控，template 不可忽略，强大的高度定制化的模板系统可以批量应用大量的机器上，grafana 如果大批量的添加也必须使用这个功能，开始的时候都只是少量可以自己手动添加，现在想直接添加 20 台机器的监控，template 就不可或缺了。不过发现 grafana 的 template 定义和 zabbix 并不相同。 简单来讲，grafana 的 template 并不是全局生效，只能针对一个 dashboard ，至少暂时针对现在的 2.0.x 版本都是这样，详情见 grafana zabbix issue 这个状况有望再下一个版本进行改进，关于这点会持续关注。 目前的需求，就是挂上一个小 hadoop 集群，之前在 zabbix 中已添加完毕，所以需要在 grafana 中接入，之前是一台台添加，这次 20 台，再手动就是变态了。所以直接上 template，不过上面已经说到，没有文档，只有一段 YouTube 视频，再看看官方 issue，差不多也琢磨出来了。整理如下。先来个整体展示 1.2 新建 template 所谓的 template 是一组 variables 的集合，所以新建模板就是新建 variables 我按照 zabbix 的经验先按照组进行划分 Variable - name：新建变量的名称 - type：类型 - query：仅作查询变量，目前使用的就是这种 - interval：周期变量，目前我还没用，猜测可能用在时间周期那块 - custom：自定义变量 value options：变量选项 - query：这里可以根据通配符指定查询范围，应该也支持正则 - regex：就是具体的通配符写法了，我这里就是只取出 zabbix 中 Hadoop 组 - All value：会匹配出所有取出的元素，进而可以进行加工处理 Multi-value selection：多变量选择 - enable：开关，就是上图中那个前面的多选框，如果关闭，则只能单选，想在一张图中展示多选项，就是靠着这个选项 - multi format：变量匹配规则 - glob：一般格式 - regex value：正则规则 Display option：显示选项 - variable label：变量标签，可以显示同一个格式前缀 Value groups/tags：变量组，可以将一些变量扔到一个组里，再统一应用，这个我还没琢磨明白 preview value：预览，就是直接显示匹配到了哪些 到了这里我们已经可以匹配出我需要的 Hadoop 组了 下面就可以新建 host 来进行匹配出我们需要的主机了 这里比较给力的功能是直接可以继承刚才的 group 变量来进行 host 的查询匹配，和新建 group 不同的是 query 中的查询直接使用 $group 处理的结果 regex：直接匹配主机名，主机名来源于 zabbix 的 host 1.3 应用 template记得我上面说的，template variable 现在这个版本中只存在于 dashboard 中，所以得新建一个 dashboard，再来新建 template variable。 完成这两部之后新建一个 row 测试一下结果，我新建了一个 text panel，其他 panel 原理相同 general 信息随意，控制 panel 的位置和大小的 edit text中，我填写了如下信息 主机名： $host CPU：物理2 / 6 cores / 24 core RAM： 96G 因为他这是同一批次机器，配置都相同，就是主机名不同，所以我就偷懒了，其实按照我的理解，后面的 CPU 和 RAM 信息都可以用变量替换 完成之后你会发觉按照就会出现上面我的第一个图的效果，选择变量进行替换，就会看到主机名跟着变化，这样一个简单的 template variable 应用就可以了，所以后面可以想象，只要是可以抽象出来的都可以设置变量等，到时候只需要新建一个 dashboard 就可以完成所有机器的监控，只要变量写的够牛逼，够全面就可以 1.4 疑问和顾虑 没官方文档，所以最好的方式只能去看源码了，但是我不懂 go，所以现在暂且没去看，如果到了后面想玩转 grafana 的话只能去学点 go 看看源码了 对于后续 grafana 的使用会慢慢放出来，也欢迎有使用 grafana 的交流一起探讨探讨 &emsp;&emsp; 参考阅读 Templated Dashboards grafana template on youtube vedio]]></content>
      <categories>
        <category>dashboard</category>
      </categories>
      <tags>
        <tag>grafana template</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django 1.7 manage.py 详解]]></title>
    <url>%2Fnote%2Fdjango-1-7-manage-py-%E8%AF%A6%E8%A7%A3.html</url>
    <content type="text"><![CDATA[喷泉之所以美丽，是因为水有了压力。瀑布之所以壮观，是因为水有了落差。人的成长和进步也一样，人没有压力，潜能得不到开发，智慧就不能开花，最大的损失还是自己 django 自从 1.7 之后解决了很多问题，并且对于数据库的操作带来了几个新命令用以解决数据迁移问题，今天开始看看文档学习一下。部分内容来源于网络Django 自 1.7 之后增加了类似 South 的 migration 功能，修改 Model 后可以在不影响现有数据的前提下重建表结构。这真是个千呼万唤始出来的 feature 了 一、migration 介绍 Migrations 其实就是一堆帮助你完成数据库变更和数据迁移的命令，使得你可以用 “Django” 的方式来管理和变更数据库的 schema。 1.1 特性Migrations让事情变得简单可控： 它使得数据库 schema 的调整可以通过Django命令来完成 它使得数据库的 schema 和对应的 model 的变更被 track 起来：整个历史都可以版本化在 Git 里面 提供了一套匹配 schema 和对应的 fixture 的机制 如何和 CI 搭配起来，可以保证代码和数据一致性 1.2 创建 migrations 当有新的 models 创建或者变更的情况下，需要创建一个 migration # python manage.py makemigrations &lt;appname&gt;Migrations for 'fault_reports': 0001_initial.py: - Create model FaultReports - Create model Log - Create model User 执行完并生成个文件：&lt;appname&gt;/migrations/0001_initial.py 文件是一个夹杂着 mysql 语句的 python 文件，可以手动修改 查看建表语句python manage.py sqlmigrate &lt;appname&gt; 0001 这里有个注意的问题是那个 0001，其实是 app_lable，默认创建的时候为 0001，可以在 migrations 的目录下看到文件的前缀，其实就是 app_lable 检查所有的配置是否OKpython manage.py check 1.3 应用 migrations 创建对数据库修改及新建。只对新增的内容操作，这样以后有改动就不用删除数据库或表了 # python manage.py migrate(django182-py2710)➜ ops git:(develop) ✗ ./manage.py migrateOperations to perform: Synchronize unmigrated apps: staticfiles, messages Apply all migrations: admin, fault_reports, contenttypes, auth, sessionsSynchronizing apps without migrations: Creating tables... Running deferred SQL... Installing custom SQL...Running migrations: Rendering model states... DONE Applying contenttypes.0001_initial... OK Applying auth.0001_initial... OK Applying admin.0001_initial... OK Applying contenttypes.0002_remove_content_type_name... OK Applying auth.0002_alter_permission_name_max_length... OK Applying auth.0003_alter_user_email_max_length... OK Applying auth.0004_alter_user_username_opts... OK Applying auth.0005_alter_user_last_login_null... OK Applying auth.0006_require_contenttypes_0002... OK Applying fault_reports.0001_initial... OK Applying sessions.0001_initial... OK 如果是全新的 app，这两步已经结束了，不需要 syncdb 操作了。总结一下。流程如下 1、建立或者更新一个 model 2、运行 python manage.py makemigrations &lt;app_name&gt; 3、运行 python mange.py migrate &lt;app_name&gt; 来应用创建的 Migrations 4、重复前面的步骤 1.4 已有项目进行 migration 日后项目的过程中可能会修改 models 结构，那么就需要如下操作 1、运行 ./manage.py makemigrations &lt;appname&gt;，Django 会根据你当前 model 来创建那份 initial migrations file。 2、运行 ./manage.py migrate，Django 会把已经存在的数据库 table 当成是 makemigration 的产物，完成整个 migration 如果运行报错了，那么就需要做一个并不是真 migration 的 fake 了。./manage.py migrate --fake &lt;appname&gt; - Mark migrations as run without actually running them 1.5 更多细节如果你再次运行 python manage.py migrate，会发现什么都没有发生：这是因为在项目的数据库中有一张 django_migrations 仍然被更新。表，记录了哪些 Migrations 已经被应用过了：无论是运行了 migrate 还是 fake 的，这个表都会被插入一条记录。比如从 South 升级到使用 Django 自带的MigrationsDjango 会检查是否有更新。如果没有，它就 fake 一次，但 django_migrations 仍然被更新。 在少数情况下，确实有需要再次运行某个特定的 Migrations，我们可以在 django_migrations 里面把这个记录删除掉。 在极少数情况下，如果你有需要回退到特定的版本，比如最初的 zero 版本，可以用类似python manage.py migrate &lt;app_name&gt; zero &emsp;&emsp; 参考阅读 django-admin and manage.py Django 1.7 自带 migrations 用法及源码 Django 模型修改及数据迁移 Data Migration in Django 1.7 (1) Data Migration in Django 1.7 (2)]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django 1.7</tag>
        <tag>manage.py 详解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grafana 学习之旅]]></title>
    <url>%2Fnote%2Fgrafana-%E5%AD%A6%E4%B9%A0%E4%B9%8B%E6%97%85.html</url>
    <content type="text"><![CDATA[你要明白自己人生的剧本——不是你父母的续集，不是你子女的前传，更不是你朋友的外篇 认识 grafana 源自单位的周老师，当分配监控任务的时候，我被分配进行协助周老师进行监控系统改造，周老师最终敲定前端展示 grafana 来进行和我们运维敲定的 zabbix 进行整合来满足我们的特殊展示需求，由此我开始了 grafana 学习之旅 一、简介 先贴一下几个官方地址 Grafana Grafana-Zabbix 1.1 简介 An open source, feature rich metrics dashboard and graph editor for Graphite, InfluxDB &amp; OpenTSDB. 从官方的原话中看出来关键字就是 开源、功能丰富的 Dashboard、图形编辑器，所以同类型产品里自然就有 ELK 中的 K(Kibana)，两者对比先不说，grafana 的优势在于 go 语言 和 AngularJS，至于如何优势，都没用过，没法评测，只是当下两大热门技术组成的产品，外加上需求已拍板，如果更好的利用上满足我们的需求才是当前的重点 1.2 grafana 安装 经周老师给我们的介绍中可以看到目前 grafana 处于快速开发阶段，也是不太稳定的阶段，迭代速度很快，issue 也很多，所以也是带着试水的性质进行探索，这里直接用 RPM 包进行安装，官方的 安装文档 很详细 1、下载 可以直接下载 rpm 包，可以设置官方 yum 源，无所谓 yum install https://grafanarel.s3.amazonaws.com/builds/grafana-2.0.2-1.x86_64.rpm 先看看安装了哪些东西 二进制文件位置：/usr/sbin/grafana-server 启动脚本：/etc/init.d/grafana-server 默认环境变量文件：/etc/sysconfig/grafana-server 默认配置文件： /etc/grafana/grafana.ini 守护进程文件： grafana-server.service 日志文件： /var/log/grafana/grafana.log 默认指定的 sqlite3 DB 的配置文件： /var/lib/grafana/grafana.db 2.启动服务 service grafana-server startStarting Grafana Server: .... nohup: redirecting stderr to stdoutFAILED 我这里启动时候有个小插曲，启动报了如下的信息，但是日志里看到已经监听在 127.0.0.1:3000 的端口了，先不理会，直接打开端口即可 1.3 grafana zabbix 安装 2.0.x 版本对应的 安装文档 1、安装 grafana zabbix 下载 grafana-zabbix-master 包cp -a grafana-zabbix-master/zabbix/ /usr/share/grafana/public/app/plugins/datasource/ 我这里通过 rpm 包安装，路径在 /usr/share/grafana/ 2、编辑 plugin.json # vim /usr/share/grafana/public/app/plugins/datasource/zabbix/plugin.json "username": "登录用户名", "password": "登录口令",# service grafana-server restart 3、增加 datasource Name Description Name 数据源的名称 Default 默认 panel Url http url Access Proxy 即为 grafana 通过后台访问, Direct 即为浏览器直接访问 到此为止，一个数据源接入就完成了，下面就需要增加展示了，要不然怎么叫可编辑的 Dashboard 呢，下面来增加一个 test panel，先回家，回家之后补上，关键还是要熟悉官方文档 Graph Panel 参考阅读 Installing on RPM-based Linux (CentOS, Fedora, OpenSuse, RedHat) Grafana Configuration Grafana zabbix 2.0.x Adding the data source to Grafana Graph Panel]]></content>
      <categories>
        <category>dashboard</category>
      </categories>
      <tags>
        <tag>dashboard</tag>
        <tag>grafana</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雾都重庆]]></title>
    <url>%2Fnote%2Ftravel-%E9%9B%BE%E9%83%BD%E9%87%8D%E5%BA%86%E4%B9%8B%E8%A1%8C.html</url>
    <content type="text"><![CDATA[人生的路，说长不长，说短不短，一路上会有风和日丽，也会有雨雪风霜；会有艰难险阻，也会有一马平川。有人相伴也罢，一人独行也罢，人这一辈子，总有些事情需要你去面对，总有些无奈需要你去承受。无论怎样，都要守住自己的心。人生无常，心安即是归处。 想起来弄一篇这个来自一个偶然的想法，觉得这几年走过的地方记忆都不太深刻，没什么可以回忆的。另一方面，未曾看到的，未曾体验世界的色彩缤纷，何不到处走走，以求窥得这自然之一粟。用不太成熟的文字描述着不算太晚的脚步。 &emsp;&emsp;其实未曾想过把自己的脚程写出来的时候，虽然全国也走过好几个地方，但是都没有系统的，有目的性的去了解和探索当地，现在想来也比较尴尬，翻看过去的照片，感觉也没有留下多少有印象的记忆。所以从这篇开始，专门开一个分类将自己的走过的，路过的见闻呈现 &emsp;&emsp;其实我已是第三次去重庆，但这次去和朋友一起，目的比较明确，就是想去看看重庆当地特别的一些地方，品尝重庆特色的小吃，所以四天半的行程里基本上都是驾车到处跑，外加天公也算是比较给力，也是跑的蛮欢快 一、简介1.1 “重庆” 名称由来 先从百度上摘了一段关于重庆的介绍 重庆，简称 巴 和 渝 ，别称 山城、渝都、桥都，雾都，是中华人民共和国中央直辖市，中国国家中心城市、国家超大城市、世界温泉之都，国务院定位的国际大都市，国际航运中心、长江上游地区的经济中心和金融中心，以及艺术、通信、科技、文化、教育等中心，中西部大型水、陆、空综合交通枢纽。 因嘉陵江古称 渝水，故重庆简称 渝 。北宋崇宁元年（1102年），改渝州为恭州。南宋淳熙 16 年（1189年）正月，孝宗之子赵惇先封恭王，二月即帝位为宋光宗皇帝，称为“双重喜庆”，遂升恭州为重庆府，重庆由此而得名。 二、行程2.1 第一天 当天的行程主要去的地方就是歌乐山，传闻那个地方是重庆最早的诞生辣子鸡这道菜的地方，并且口味也是最正宗的，所以冲着这个，我们就驱车直奔歌乐山 &emsp;&emsp;原本准备去武隆看看，但是后来考虑到全程会太过疲惫，所以最后放弃了去武隆郊区的想法，改换成了市内。当天即使能看到阳光的情况下，也是雾气蒙蒙，果然入传闻雾都一般。 &emsp;&emsp;我们的行程都是当天直奔一个主题地点，路途上可以经过一些其他地方。并且我们更喜欢路边摊或者有口碑的小吃店，而不太中意那些看起来非常大和气派和富丽堂皇的地方，个人偏见那些地方不太能做出能让人口碑皆知的东西来。 &emsp;&emsp;我们入住的酒店位于红锦大道，星牌坊转盘北哈弗轻舟公交站旁的一家酒店。睡醒出发时间已接近中午，为了体验重庆早餐特色，选择了不太远的红旗河沟渝通宾馆上行路段金紫山重百仓库下面一点点的一家面馆的牛肉小面，也是朋友力荐的牛肉小面 &emsp;&emsp;特色真心是牛肉够大块，小面和我们认知的劲道的面不太一样。当然价格也是 17 元一碗，我不禁感慨这碗面不太便宜的同时，还是吃的一丁不剩（我还是可以吃点辣的），同行另一位北京小伙伴第一次来重庆可就没这么好运气了，就被这入渝后第一道菜的辣和油震惊了，只能就着冰饮吃完了牛肉。 &emsp;&emsp;吃完驱车直奔目的地。虽有土著带路，很明显，我们发现，这个区域并非土著服务区，所以又只能依赖导航，结果被导航带到了歌乐山的后门上，车还不让进，只能默默的爬上去，重庆本身就是山城，但是这个山的确让小伙伴和土著累得不行，不过歌乐山上除了观景台以外，更像个公园，遍地的社区健身器材，以及浓郁的植被覆盖，基本上没有其他可言，我们在不断盘旋上升的道路上相爬到最高点看看高处观看重庆全城的风貌。可爬到那的时候看到的一个光秃秃的小楼，需要门票费 5 元，只是比平时高了几层，但是真心是什么都没有，认为不值得，就没有上去，只能在满被植被挡住的空隙中看到了重庆全城的一角。 &emsp;&emsp;同样让我们失望的还有这座山的最高点，我们一路往上爬，台阶倒是没少走，就是一直不见顶，起初认为通往山顶的道路都不这么轻松，那么山顶景色肯定不会失望，结果爬了那么多台阶，绕过一个石门，发觉没有所谓的顶，就是楼梯之上的一个小小的平台上看到了一个碑 &emsp;&emsp;整座山只能当做我们认识重庆山城的一个铺垫，满山在寻找仙女湖的我们，希望能在当天有所收获，前几个景点是有点失望，不过既然来了，肯定至少找到点什么，循着指示牌，不停从山上往山下奔。（此处有视频，视频没有压缩太影响传输，稍后补上） &emsp;&emsp;传说中的仙女湖也是让我们醉的不轻，探寻的过程让我们一直对这个所谓的“湖”期待一直在上升，期盼如同北大未名湖一般，嵌在这个大山里。清新的可以让我们忽略掉这一路的艰辛。悲剧的结果是一个小小的池塘，完全不能称之为湖，不觉失望透顶，感觉在也不会再爱了。唯一感觉不同的是是旁边的一个依山建造的一栋建筑和大山里的羽毛球场地倒是让人眼前一亮 &emsp;&emsp;不过唯一难得觉得让我们对重庆印象深刻的是，上山下山的盘山道路，用小伙伴的话就是快有种 “飞机降落时候的那种耳鸣” （此处也是有视频，稍微压缩传上）。作为经常压平地的我们来说新鲜感十足，小伙伴的车技也被拉上了一个等级，再回平地开车也是棒棒哒。 &emsp;&emsp;闷热的天气，第一个景点就就饶了半山一圈并且啥也没看到也是感觉没那么好，好不容易钻上车一路往回跑，快到晚上吃饭的点了，作为重庆最有特色的火锅肯定是不能错过的，所以直奔龙头寺，土著终于到了活动区域，轻车熟路的带我们去往了一家叫 渝宗火锅 ，因为我有尝试过，所以提醒小伙伴，要不要清汤锅（这里请不要鄙视我，第一次去的确没适应，所以点了一份清汤锅，结果比全辣锅还贵，实在是没理解），结果土著告诉我，重庆餐厅没指望你会吃清汤锅，瞬间表示无语。。。下面来一张 渝宗火锅 的正面特写，北京这里的宽板凳一个造型 &emsp;&emsp;对重庆的火锅，感触还是比较深的，看上图就知道那个重油，重辣，重麻，上来送一碗香油，我无奈的感慨重庆人民感觉香油和花椒，辣椒不要钱似得。但是虽然话这么说，感觉还是不太一样的，蔬菜丢进去捞出来会辣的不轻，其余的东西放进去涮出来的味道配合香味，麻辣，烫，大汗淋漓的感觉的确超赞，难怪人民火锅都快成为重庆人民饭桌上必备的一道程序了。 &emsp;&emsp;到了下午下山其实下雨了，雾气蒙蒙心情也不辣么美丽，时间还不晚，就去了山下附近的磁器口逛了一会，由于凌晨两点半才抵达重庆的酒店，太潮也没睡好，第二天紧接着爬山，所以体力上有点受影响，直接回酒店休息，匆匆结束第一天的行程。 2.2 第二天 天公不作美，从昨天到今天整天小雨，所以爬南山的计划也就搁置了，只能开车在市区跑了跑 &emsp;&emsp;连绵的小雨明显不同于北方的性急的暴雨，哗啦啦的下完结束，重庆的小雨十分腼腆，一丢丢的洒，但是会一直持续不停 2.3 第三天洋人街，洪崖洞夜景，杨家坪的武龙虾和爬爬虾 2.4 第四天&emsp;&emsp;我们在重庆最后的这两天天公非常给面子，直接放晴 &emsp;&emsp;同时温度直接飙升，我们准备的一箱矿泉水喝完之后继续买了几瓶备着。睡到近中午之后起床去了天龙之路上旁边的一个早餐店吃了碗铺盖面，特地和老板说，老板不要辣，顶着老板的奇异目光，我们还是上了不辣的铺盖面，之前觉得这个名字好玩，结果果然是铺盖呐，一整张面皮的面，不过味道还算是不错的。话不多说上图 &emsp;&emsp;之前去过川美老校区，早就人去楼空，基本上小伙伴的愿望没有满足，我们仍旧不死心，又一次去忘了位于大学城的川美新校区，不得不承认，川美的新校区和老校区风格差太远了，老小区很普通，除了小区周围的居民楼全都被各种涂鸦，才知道这是川美附近。而新校区学生也是放假了，同比周围的其他学校，只能感慨艺术生的任性 &emsp;&emsp;映入眼帘的川美大门就能明显区分出艺术院校的特点，精心设计的大门，清一色的裸石和一堆瓶瓶罐罐进行组装出的围墙，复古青砖石墙和木制的小桥和凉亭，无一不不像我们宣示着这是一所艺术院校，仿佛每一处都想必是都要被设计一番，无处不彰显这里的艺术气息 满处石头堆砌的石墙 木质走道的顶棚 见到了川美的荷花池，总算是平复了之前寻找仙女湖的那种失落，这的确是块休息的好去处 &emsp;&emsp;经过了整个空荡的校园（话说重庆真不是盖的，就连诺大的川美新校区，整个学校路面都是起伏不平，如同滑板选手比赛的波浪地形一般起伏）。我们不停的上下逛着这个已没有多少人的新校区，不过唯一开放的就剩下各个学院的展览了，那里刚好留下了刚刚毕业的学生们的毕业设计，带着好奇的心情，我们参观了两个学院的毕业展，也带着美好的祝愿祝福这些刚毕业的川美学子在以后的路上蓬勃飞翔，这里给出川美一今年的毕业生的毕业作品 &emsp;&emsp;天气虽好，可重庆的艳阳天可真不是开玩笑的，逛完川美表示已经被晒出翔了。差不多已经是下午三四点的时候。当天晚上也是我们在重庆的最后一晚，由于之前没有去南山观夜景，所以今天的主要目标在重庆的最后一晚上看看重庆夜景，备上水源，直奔南山。 &emsp;&emsp;最后又开到了一段让我们觉得与众不同的沿山道路上，不过因为到达南山一棵树观景点的时候天还没黑，决定继续开上去（南山一棵树观景台在山腰上），在山上吃个晚饭，由土著发动人脉询问南山比较有名的小吃，决定了不是泉水鸡就是一家叫久久牛肉馆的地方，各种一顿搜罗和介绍，最后决定吃牛肉馆的牛肉，在重庆邮电大学的前面一点的距离的一个斜坡下面，看到了不太那么张扬的这家久久牛肉面馆，里面全是牛肉料理，点了一份灯影牛肉、泡椒牛肉，牛肉清汤。 &emsp;&emsp;灯影牛肉还是重庆特产，味道和传统的麻辣还不同，还有一丝甜味和香味，吃起来感觉怪不同的。 &emsp;&emsp;吃晚饭发觉还是很早，决定再把旁边的重邮给遛一遛，这里还没放假，所以随处可见的学生，简单来说重邮和普通学校唯一的区别就是爬往学生宿舍就是海平面上升了近 100 米，从入校门，一直是上楼梯，紧接着斜坡，在爬一段 45 度楼梯才能到食堂。真心是佩服这里的学生，如果是骑自行车，那真心上来是个痛苦的差事。觉得差不多了，天气也黑的差不多了，开车去一棵树观景点，悲剧的是车位直接被占满，又是单行道，只能开下去，在开上来，停在了山上吃饭的地方，走去了一棵树观景点。牛逼的是，门票 30元/人。到处都是可以收费的项目，重庆人民好经济头脑~ 而且不知道为什么，这里每天的人流量都会让这个不大的半山腰堵死，一方面是单向的缘故，一方面，山上下来观赏的人和慕名而来的人，直接能降这里塞满，也真是挺服帖的，下面带你们进入这里之后的一棵树正身，我开始找了半天不知道为什么叫一棵树，后来看了半天观望台上就那一棵树，赶紧脑补了一下百度 &emsp;&emsp;重庆南山一棵树观景台是来渝宾客观赏山城夜景的一大佳点。此景观园在不调整原有设施和风格基础上，将浏览空间向后延伸，设置野外休闲区，建有14个健身项目，拓宽了游览空间，形成了日观市容市貌，夜览山城夜景的游览格局。&emsp;&emsp;重庆南山一棵树观景台前身是 1997 年 1 月建成开放的一棵树观景台，此处因多年来保留一棵重庆市树－－黄桷树而得名。 偷一张百度的观景台全景，中间平台上的那棵树就是 其实这类观景台没有其他景色可言，除了站在高处能看到重庆的全景，除此之外并无其他，这里直接放出最后我们用手机拍下的图片 不过说实话，白天在市里的时候除了两江能看到不错的景色，觉得这座雾都洋溢着一种现代都市的氛围以外其他的时候不太明显，直到上了这里，在柔顺的夜色的拥抱下，这座山城散发着与白天不同的另一种与众不同的魅力，现代文明的山城也变得娇柔妩媚。才真的发觉其实还真的挺美的，不枉前几天的艰辛，值得一来的好去处~ 2.5 第五天&emsp;&emsp;下午的返程飞机，同行小伙伴一直有想体验过重庆的轻轨，体会轻轨从楼里穿越的感觉，所以最后赶往机场就选择轻轨路线，但是走之前，吃仍旧是我们比较关注的问题，走之前准备吃好一顿再走，听闻水煮鱼不错，外加土著的推荐，在观音桥步行街逛到一家水煮鱼的地方，不过感到这里不同的是，这里的水煮鱼吃完之后紧接着就变成了火锅了，加点汤又变成了火锅，而且之前的花椒过多，导致火锅的十分够味，我们又是直接买了一个冰沙一口冰一口辣…… 在轻轨里当然拍不出来轻轨穿楼而过的情形，果断去网上偷了几张神吐槽重庆轻轨的图 &emsp;&emsp;看这个也能明白重庆的地形也是够可以的，重庆各种刷新世界观的奇葩地形。轻轨穿楼，60度的上楼楼梯，各种上下坡，是这些天对雾都最直观的认识，房子可以在山顶上，山腰上，山脚下，楼的平均高度也是堪比任何国内其他城市。吃的自然不用说，够麻够辣够刺激（感觉要是天天吃有点吃不消的感觉）。另外这次玩的地方都是市区的以及近郊，下次有机会再去可以直奔郊区，口碑推荐的武隆的确也是有相当出色的景色的，下次再来拜访~ &emsp;&emsp;折腾了我久写这篇出去玩的经历，主要也是临时写，之前没有任何准备，不过我还是会坚持写下去的。好了，就写到这吧，词穷笔乏了都 ~ 参考阅读 百度百科 - 重庆 重庆南山一棵树观景台]]></content>
      <categories>
        <category>在路上</category>
      </categories>
      <tags>
        <tag>重庆之行</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 监控 nginx 和 php-fpm]]></title>
    <url>%2Fnote%2Fzabbix-%E7%9B%91%E6%8E%A7-nginx-%E5%92%8C-php-fpm.html</url>
    <content type="text"><![CDATA[人生所求，得之可喜，失之无忧。苦乐随缘，得失随缘。 监控常规的任务自然少不了 nginx 和 php-fpm 的监控，最近也是重新开始整理 zabbix，重新学习之，里面的脚本，配置文件以及模板都来源《zabbix 企业级分布式监控系统》一书，根据自身环境适当修改 一、监控 nginx server1.1 配置 nginx 和 php-fpmphp-fpm 中 [www] 段中配置文件新增[www]pm.status_path = /fpm_status.php nginx 配置新增 server 段server &#123; listen 127.0.0.1:80; allow 127.0.0.1; deny all; # 这里两行控制权限 # 开启 nginx 状态页 location /nginxstatus &#123; stub_status on; access_log off; &#125; # 开启 php-fpm 状态页 location ~ ^/(fpm_status) &#123; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; &#125;&#125; 访问测试，确保可以查看状态信息 curl http://127.0.0.1/nginxstatuscurl http://127.0.0.1/fpm_status.php 1.2 配置检测脚本和 userparameter 我配置了 agent 主动发送数据到 server 的 active 模式 首先看目录结构# tree /etc/zabbix//etc/zabbix/├── scripts│ ├── check_nginx_status.sh│ └── check_phpfpm.sh├── zabbix_agentd.conf└── zabbix_agentd.d ├── userparameter_nginx.conf └── userparameter_phpfpm.conf 下面分别对应每个文件 userparameter_nginx.conf UserParameter=nginx.accepts,/etc/zabbix/scripts/check_nginx_status.sh acceptsUserParameter=nginx.handled,/etc/zabbix/scripts/check_nginx_status.sh handledUserParameter=nginx.requests,/etc/zabbix/scripts/check_nginx_status.sh requestsUserParameter=nginx.connections.active,/etc/zabbix/scripts/check_nginx_status.sh activeUserParameter=nginx.connections.reading,/etc/zabbix/scripts/check_nginx_status.sh readingUserParameter=nginx.connections.writing,/etc/zabbix/scripts/check_nginx_status.sh writingUserParameter=nginx.connections.waiting,/etc/zabbix/scripts/check_nginx_status.sh waiting userparameter_phpfpm.conf UserParameter=phpfpm.status.pool,/etc/zabbix/scripts/check_phpfpm.sh poolUserParameter=phpfpm.status.process.manager,/etc/zabbix/scripts/check_phpfpm.sh process_managerUserParameter=phpfpm.status.start.since,/etc/zabbix/scripts/check_phpfpm.sh start_sinceUserParameter=phpfpm.status.accepted.conn,/etc/zabbix/scripts/check_phpfpm.sh accepted_connUserParameter=phpfpm.status.listen.queue,/etc/zabbix/scripts/check_phpfpm.sh listen_queueUserParameter=phpfpm.status.max.listen.queue,/etc/zabbix/scripts/check_phpfpm.sh max_listen_queueUserParameter=phpfpm.status.listen.queue.len,/etc/zabbix/scripts/check_phpfpm.sh listen_queue_lenUserParameter=phpfpm.status.idle.processes,/etc/zabbix/scripts/check_phpfpm.sh idle_processesUserParameter=phpfpm.status.active.processes,/etc/zabbix/scripts/check_phpfpm.sh active_processesUserParameter=phpfpm.status.total.processes,/etc/zabbix/scripts/check_phpfpm.sh total_processesUserParameter=phpfpm.status.max.active.processes,/etc/zabbix/scripts/check_phpfpm.sh max_active_processesUserParameter=phpfpm.status.max.children.reached,/etc/zabbix/scripts/check_phpfpm.sh max_children_reached check_nginx_status.sh #!/bin/bashsource /etc/bashrc &gt;/dev/null 2&gt;&amp;1source /etc/profile &gt;/dev/null 2&gt;&amp;1nginxstatus=http://127.0.0.1/nginxstatus# Functions to return nginx statsfunction checkavailable &#123; code=$(curl -o /dev/null -s -w %&#123;http_code&#125; $&#123;nginxstatus&#125;) if [ "$&#123;code&#125;" == "200" ] then return 1 else echo 0 fi&#125;function active &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Active' | awk '&#123;print $3&#125;'&#125;function reading &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Reading' | awk '&#123;print $2&#125;'&#125;function writing &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Writing' | awk '&#123;print $4&#125;'&#125;function waiting &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Waiting' | awk '&#123;print $6&#125;'&#125;function accepts &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $1&#125;'&#125;function handled &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $2&#125;'&#125;function requests &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $3&#125;'&#125;case "$1" in active) active ;; reading) reading ;; writing) writing ;; waiting) waiting ;; accepts) accepts ;; handled) handled ;; requests) requests ;; *) echo "Usage: $0 &#123;active |reading |writing |waiting |accepts |handled |requests &#125;"esac check_phpfpm.sh #!/bin/bashsource /etc/bashrc &gt;/dev/null 2&gt;&amp;1source /etc/profile &gt;/dev/null 2&gt;&amp;1LOG_FILE=/var/log/zabbix/phpfpmstatus.logcurl http://127.0.0.1/fpm_status.php &gt;$&#123;LOG_FILE&#125; 2&gt;&amp;1pool()&#123; awk '/pool/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;process_manager() &#123; awk '/process manager/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;start_since()&#123; awk '/^start since:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;accepted_conn()&#123; awk '/^accepted conn:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;listen_queue()&#123; awk '/^listen queue:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;max_listen_queue()&#123; awk '/^max listen queue:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;listen_queue_len()&#123; awk '/^listen queue len:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;idle_processes()&#123; awk '/^idle processes:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;active_processes()&#123; awk '/^active processes:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;total_processes()&#123; awk '/^total processes:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;max_active_processes()&#123; awk '/^max active processes:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;max_children_reached()&#123; awk '/^max children reached:/ &#123;print $NF&#125;' $&#123;LOG_FILE&#125;&#125;case "$1" inpool) pool ;;process_manager) process_manager ;;start_since) start_since ;;accepted_conn) accepted_conn ;;listen_queue) listen_queue ;;max_listen_queue) max_listen_queue ;;listen_queue_len) listen_queue_len ;;idle_processes) idle_processes ;;active_processes) active_processes ;;total_processes) total_processes ;;max_active_processes) max_active_processes ;;max_children_reached) max_children_reached ;;*) echo "Usage: $0 &#123;pool|process_manager|start_since|accepted_conn|listen_queue|max_listen_queue|listen_queue_len|idle_processes|active_processes|total_processes|max_active_processes|max_children_reached&#125;"esac 以上全部配置完成之后重启 agent 即可 1.3 添加模板，调用 松爷的书里提供了大量的模板，如果不想自己重写生成模板，直接拿着这个模板进行根据自身的环境修改即可 nginx 的模板 php-fpm 的模板 最后呈现出来的效果如下图(zatree中) 更多阅读 松爷的 zabbix repo]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix 监控 nginx 和 php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 监控技巧]]></title>
    <url>%2Fnote%2Fdb_redis-%E7%9B%91%E6%8E%A7%E6%8A%80%E5%B7%A7.html</url>
    <content type="text"><![CDATA[大部分的人對於所謂成功，只有兩个標準：小時候的分数和大了之后的錢数 在 NosqlFan 上看到这篇文章，深觉好文，对于学习 redis 的运维很有帮助，遂转载 一、Redis监控技巧本文来自 Bugsnag 的联合创始人 Simon Maynard 的系列文章，作者根据几年来对 Redis 的使用经历，对 Redis 监控方法进行了系统性的总结，干货很多，值得一看。 原文链接：Redis Masterclass – Part 2, Monitoring Redis 监控最直接的方法当然就是使用系统提供的 info 命令来做了，你只需要执行下面一条命令，就能获得 Redis 系统的状态报告。 redis-cli info 1.1 内存使用如果 Redis 使用的内存超出了可用的物理内存大小，那么 Redis 很可能系统会被 OOM Killer 杀掉。针对这一点，你可以通过 info 命令对 used_memory 和 used_memory_peak 进行监控，为使用内存量设定阈值，并设定相应的报警机制。当然，报警只是手段，重要的是你得预先计划好，当内存使用量过大后，你应该做些什么，是清除一些没用的冷数据，还是把 Redis 迁移到更强大的机器上去。 1.2 持久化如果因为你的机器或 Redis 本身的问题导致 Redis 崩溃了，那么你唯一的救命稻草可能就是 dump 出来的 rdb文件了，所以，对 Redis dump 文件进行监控也是很重要的。你可以通过对 rdb_last_save_time 进行监控，了解你最近一次 dump 数据操作的时间，还可以通过对 rdb_changes_since_last_save 进行监控来知道如果这时候出现故障，你会丢失多少数据。 1.3 主从复制如果你设置了主从复制模式，那么你最好对复制的情况是否正常做一些监控，主要是对 info 输出中的 master_link_status 进行监控，如果这个值是 up，那么说明同步正常，如果是 down，那么你就要注意一下输出的其它一些诊断信息了。比如下面这些： role:slave master_host:192.168.1.128 master_port:6379 master_link_status:down master_last_io_seconds_ago:-1 master_sync_in_progress:0 master_link_down_since_seconds:1356900595 1.4 Fork 性能当 Redis 持久化数据到磁盘上时，它会进行一次 fork 操作，通过 fork 对内存的 copy on write 机制最廉价的实现内存镜像。但是虽然内存是 copy on write 的，但是虚拟内存表是在 fork 的瞬间就需要分配，所以 fork 会造成主线程短时间的卡顿（停止所有读写操作），这个卡顿时间和当前 Redis 的内存使用量有关。通常 GB 量级的 Redis 进行 fork 操作的时间在毫秒级。你可以通过对 info 输出的 `latest_fork_usec` 进行监控来了解最近一次 fork 操作导致了多少时间的卡顿。 1.5 配置一致Redis 支持使用 CONFIG SET 操作来实现运行实的配置修改，这很方便，但同时也会导致一个问题。就是通过这个命令动态修改的配置，是不会同步到你的配置文件中去的。所以当你因为某些原因重启 Redis 时，你使用 CONFIG SET 做的配置修改就会丢失掉，所以我们最好保证在每次使用 CONFIG SET 修改配置时，也把配置文件一起相应地改掉。为了防止人为的失误，所以我们最好对配置进行监控，使用 CONFIG GET 命令来获取当前运行时的配置，并与 redis.conf 中的配置值进行对比，如果发现两边对不上，就启动报警。 1.6 慢日志Redis 提供了 SLOWLOG 指令来获取最近的慢日志，Redis 的慢日志是直接存在内存中的，所以它的慢日志开销并不大，在实际应用中，我们通过 crontab 任务执行 SLOWLOG 命令来获取慢日志，然后将慢日志存到文件中，并用 Kibana 生成实时的性能图表来实现性能监控。 值得一提的是，Redis 的慢日志记录的时间，仅仅包括 Redis 自身对一条命令的执行时间，不包括 IO 的时间，比如接收客户端数据和发送客户端数据这些时间。另外，Redis 的慢日志和其它数据库的慢日志有一点不同，其它数据库偶尔出现 100ms 的慢日志可能都比较正常，因为一般数据库都是多线程并发执行，某个线程执行某个命令的性能可能并不能代表整体性能，但是对 Redis来说，它是单线程的，一旦出现慢日志，可能就需要马上得到重视，最好去查一下具体是什么原因了。 1.7 监控服务 SentinelSentinel 是 Redis 自带的工具，它可以对 Redis 主从复制进行监控，并实现主挂掉之后的自动故障转移。在转移的过程中，它还可以被配置去执行一个用户自定义的脚本，在脚本中我们就能够实现报警通知等功能。 Redis LiveRedis Live 是一个更通用的 Redis 监控方案，它的原理是定时在 Redis 上执行 MONITOR 命令，来获取当前 Redis 当前正在执行的命令，并通过统计分析，生成web页面的可视化分析报表。 Redis FainaRedis Faina 是由著名的图片分享应用 instagram 开发的 Redis 监控服务，其原理和 Redis Live 类似，都是对通过 MONITOR 来做的。 1.8 数据分布弄清 Redis 中数据存储分布是一件很难的是，比如你想知道哪类型的 key 值占用内存最多。下面是一些工具，可以帮助你对 Redis 的数据集进行分析。 Redis-samplerRedis-sampler 是 Redis 作者开发的工具，它通过采样的方法，能够让你了解到当前 Redis 中的数据的大致类型，数据及分布状况。 Redis-auditRedis-audit 是一个脚本，通过它，我们可以知道每一类 key 对内存的使用量。它可以提供的数据有：某一类 key 值的访问频率如何，有多少值设置了过期时间，某一类 key 值使用内存的大小，这很方便让我们能排查哪些 key 不常用或者压根不用。 Redis-rdb-tools跟 Redis-audit 功能类似，不同的是它是通过对 rdb 文件进行分析来取得统计数据的。 参考阅读 Redis监控技巧]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis 监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的优雅技巧]]></title>
    <url>%2Fnote%2FPython%E7%9A%84%E4%BC%98%E9%9B%85%E6%8A%80%E5%B7%A7.html</url>
    <content type="text"><![CDATA[看到微信推送了这篇文章，觉得还是蛮多用处的，遂转载自微信公众号 python程序员,有些是已经知道的技巧，但是更多的是未曾注意的，直接转载 一、常用技巧1.1 枚举不要这么做 i = 0 for item in iterable: print i, item i += 1 而是这样： for i, item in enumerate(iterable): print i, item Enumerate 可以接受第二个参数，例如： &gt;&gt;&gt; list(enumerate("abc")) [(0, "a"), (1, "b"), (2, "c")] &gt;&gt;&gt; list(enumerate("abc", 1)) [(1, "a"), (2, "b"), (3, "c")] 1.2 字典/集合 解析你可能知道列表解析，但不知道字典/集合解析。字典/集合解析简单而且高效，例如： my_dict = &#123;i: i * i for i in xrange(100)&#125; my_set = &#123;i * 15 for i in xrange(100)&#125;# There is only a difference of ":" in both 1.3 强制浮点数除法如果我们除以一个整数，即使结果是一个浮点数，Python（2） 依旧会给我们一个整数。为了规避这个问题，我们需要这样做： result = 1.0/2 但是现在有一种别的方法可以解决这个问题，甚至在之前我都没有意识到有这种方法存在。你可以进行如下操作： from __future__ import division result = 1/2# print(result)# 0.5 需要注意的是这个窍门只适用于 Python 2。在 Python 3 中就不需要进行 import 操作了，因为它已经默认进行 import 了。 1.4 简单的服务器你想快速简单的分享目录下的文件吗？可以这样做： # Python2python -m SimpleHTTPServer# Python 3python3 -m http.server 这回启动一个服务器 1.5 Python 表达式求值我们都知道 eval ,但也许并不是所有人都知道 literal_eval. 可以这么做： import ast my_list = ast.literal_eval(expr) 而不是这样： expr = "[1, 2, 3]" my_list = eval(expr) 1.6 分析脚本按下面的方式运行脚本，可以很简单的对其进行分析： python -m cProfile my_script.py 1.7 对象自检在 Python中，可以通过 dir() 来检查对象，例如： &gt;&gt;&gt; foo = [1, 2, 3, 4]&gt;&gt;&gt; dir(foo) ["__add__", "__class__", "__contains__", "__delattr__", "__delitem__", "__delslice__", ... , "extend", "index", "insert", "pop", "remove", "reverse", "sort"] 1.8 调试脚本你可以使用pdb模块在脚本中设置断点来调试脚本，就像这样： import pdbpdb.set_trace() 你可以在脚本的任何地方加入 pdb.set_trace()，该函数会在那个位置设置一个断点。超级方便。你应该多阅读 pdb 函数的相关内容，因为在它里面还有很多鲜为人知的功能。 1.9 简化 if 结构如果必须检查一些值，可以用 if n in [1,4,5,6]: 而不是用复杂的if结构： if n==1 or n==4 or n==5 or n==6: 1.10 字符串/数列 逆序下面的方式可以快速反转一个列表： &gt;&gt;&gt; a = [1,2,3,4]&gt;&gt;&gt; a[::-1][4, 3, 2, 1]# This creates a new reversed list. # If you want to reverse a list in place you can do:a.reverse() 这种方式同样适用于字符串： &gt;&gt;&gt; foo = "yasoob"&gt;&gt;&gt; foo[::-1]"boosay" 1.11 优雅地打印下面的方式可以用优雅的方式打印字典和列表： from pprint import pprint pprint(my_dict) 这用于字典打印是非常高效的，如果你想从文件中快速优雅的打印出json，可以这样做： cat file.json | python -m json.tools 1.12 三元运算三元运算是 if-else 语句的快捷操作，也被称为条件运算。这里有几个例子可以供你参考: [on_true] if [expression] else [on_false]x, y = 50, 25small = x if x &lt; y else y 译文出处：http://www.ido321.com/1576.html本文根据@Nicolas Bevacqua的《nifty-python-tricks》所译，整个译文带有我自己的理解与思想，如果译得不好或有不对之处还请同行朋友指点。如需转载此译文，需注明英文出处：https://freepythontips.wordpress.com/2015/04/19/nifty-python-tricks/。 &emsp;&emsp; 参考阅读 Python的优雅技巧&amp;version=11020012&amp;pass_ticket=U2h1d9YESwwdxEEUmFkbvmgr9RdOy%2F%2Fm6oEfYQHruh2BtAabzG7wTkaFbdmO4W%2B%2F)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python 的优雅技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 持久化]]></title>
    <url>%2Fnote%2Fdb_redis-%E6%8C%81%E4%B9%85%E5%8C%96.html</url>
    <content type="text"><![CDATA[按照之前学习路线，数据的备份和恢复，所以对于 redis 这一块就会涉及到数据的保存、备份、恢复，那么自然就到了持久化（persistence）这里，并且之所以 redis 性能强劲很大程度上是因为将所有数据保保存在内存中的缘故，部分内容摘抄《redis 入门指南》和 解密Redis持久化所谓持久化，简单来讲就是将数据放到断电后数据不会丢失的设备中。也就是我们通常理解的硬盘上。redis 支持两种方式的持久化，一种是 RDB 方式，一种是 AOF 方式。 一、数据写操作1.1 redis 写数据流程 在理解持久化之前需要了解数据在 redis 里写入磁盘的过程 1、客户端向服务端发送写操作（数据在客户端的内存中） 2、数据库服务端接收到写请求的数据（数据在服务端的内存中） 3、服务端调用 write(2) 这个系统调用，将数据往磁盘上写（数据在系统内存的缓冲区中） 4、操作系统将缓冲区中的数据转移到磁盘控制器上（数据在磁盘缓存中） 5、磁盘控制器将数据写到磁盘的物理介质中（数据真正落到磁盘上） 二、RDB2.1 快照原理 redis 使用 fork 命令的 copy on write 机制，复制一份当前进程（父进程）的副本（子进程），子进程循环所有数据，将数据写入 RBD 文件 父进程继续接受并处理客户端发来的命令，而子进程开始将内存的数据存储写入硬盘的临时文件 当子进程写入完所有数据后会通过原子性 rename 系统调用将临时文件替换旧的 RDB 文件，到这里一次快照结束 RBD 明显的不足就是一旦数据库出现 crash 之类的，RDB 里保存的数据可能不是最新的，从上次 RDB 到 redis 停机这段时间的数据可能会丢失 2.2 快照配置RDB 方式持久化是通过快照（snapshotting）完成。当符合条件时候 redis 会将内存中的数据进行快照并存储在硬盘上。快照条件可以由用户配置文件制定，配置文件有两个参数，时间和改动的键。并且 RDB 是 redis 默认采用的持久化的方式 ################################ SNAPSHOTTING ################################### Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving at all commenting all the "save" lines.save 900 1save 300 10save 60 10000# 开启 LZF 压缩rdbcompression yes# 版本 5 的 RDB 会在文件尾部带上一个 CRC64 校验，但是会使得文件格式变得负责和牺牲一部分性能rdbchecksum yes# 文件名dbfilename dump.rdb# 指定 rdb 文件目录dir ./ 主体就是 时间 和 改变的键 多个 save 之间是 或 的关系 快照保存在 dump.rdb 文件中，可以通过配置 dir 和 dirfilename 分别指定 快照文件的存储路径 和 文件名 除了自动快照，可以手动执行 SAVE 和 BGSAVE 命令让 redis 执行快照 一旦 redis 异常退出，就会丢失最后一次快照以后更改的所有数据 这里值得注意的是 SAVE 命令会阻塞 redis 服务器进程，直到 RDB 文件创建完成为止，阻塞期间，服务器不能处理任何请求命令 BGSAVE 会 fork 一个子进程，然后子进程负责创建 RDB 文件，父进程继续处理命令请求 当 redis 处于 BGSAVE 期间，对 SAVE、BGSAVE、BGREWRITEAOF 这三个命令的处理方式和平时期间有所不同 在此期间，客户端发送的 SAVE 命令会被拒绝，防止二者产生竞争条件 在此期间，客户端发送的 BGSAVE 命令也会被拒绝，防止二者产生竞争条件 在此期间，客户端发送的 BGREWRITEAOF 会被延迟到命令执行完成之后执行 如果 BGREWRITEAOF 命令正在执行，那么客户端发送的 BGSAVE 命令会被服务器拒绝 三、AOF3.1 原理AOF 即 Append Only File，即追加写入的日志文件，并且 AOF 是可识别的纯文本文件 AOF机制的实现比较复杂，简单理解一下就是append - fsync - rewrite 开启 aof 后，命令的写命令都会先追加到服务器的 aof_buf 缓冲区末尾 fsync 是把 aof_buf 缓存区的数据写入 aof 文件中 rewrite 是将写操作合并，比如 set aa 1; set aa 2; 两个操作应该写成一个操作 set aa 2; 实现机制： Redis 将数据库做个快照，遍历所有数据库，将数据库中的数据还原为跟客户端发送来的指令的协议格式的字符串，然后 Redis 新建一个临时文件将这些快照数据保存，待快照程序结束后通过原子性 rename 系统调用将临时文件名修改为正常的 aof 文件 由于在快照进行的过程中可能存在新增的命令修改了数据库中的数据，则在快照程序结束后需要将新修改的数据 fsync 到 aof buf 以及 AOF 文件中。这样就支持了实时的持久化，至于何时 fsync ，这个是通过参数 appendfsync 控制 当 aof 文件到达一定大小的时候，redis 就会读取数据库关于 list 的值，会在后台单独启动一个子进程进行 aof_rewrite 重写操作；并且为了重写过程中，数据库又继续增加写命令，所以设置了一个 rewrite_buf，缓冲区在后台重写子进程启动时启用。也就是当 redis 接受到一个写命令的时候，会有如下的操作 执行客户端发来的命令 将执行后的写命令追加到 aof_buf 中 开启 rewrite 子进程，将写命令追加到 aof_rewrite_buf 中 子进程完成重写的工作之后，会通知父进程完成重写，此时父进程会完成以下的事情 将 aof_rewrite_buf 内容写入到新的 aof 文件中，这时候 aof 文件保存的数据库状态和服务器当前的状态保持一致 对新的 aof 文件进行改名，覆盖现有的 aof 文件，完成新旧 aof 文件替换 同时这也是 BGRERITEAOF 的工作原理 3.2 AOF 配置# 是否开启 aof 持久化，默认开启 RDB 持久化appendonly yes# aof 保存的文件名appendfilename appendonly.aof# aof 会将记录保存在文件中，由于系统缓存机制，数据没有真正的写入磁盘而是写入缓存，系统默认情况下每 30s 写入磁盘，但是如果这 30s 之内系统异常退出，则数据就会丢失，所以多久时间同步一次缓存到磁盘由下面参数控制，也就是同步缓存时机appendfsync &#123; everysec | always | no &#125; - redis 自身默认是 everysec，即每秒 - always 表示每执行写入都会执行同步，最安全，也是最慢 - no 不主动进行同步，即按照操作系统默认的 30s 方式来# 这个配置项是设置在 rewrite 的时候是否对新的写操作进行 fsync。no 表示进行 fsync，yes 表示不进行。默认是设置为 no。如果在 rewrite 过程中，不会对 aof 文件进行 fsync，这样对磁盘的写入操作不会快速的摆动磁头，减少了寻道时间，让 rewrite 可以快速的完成，但这样同时增加了风险，因为生成 aof 的时间可能会比较长的。如果在这过程中 os crash，部分 aof 数据还在 page cache 里，但还未写入到 disk 上则会丢失。no-appendfsync-on-rewrite no# 由于记录命令到 aof，所以自然 aof 会显得越来越冗余庞大，所以一定时间之后重写 aof 来使得可以优化 aof 大小# 表示当前 aof 文件大小超过上次重写的 aof 大小的百分之多少会再次进行重写，如果之前没有重写过，则以启动时的 aof 文件大小为依据auto-aof-rewrite-percentage 100# 限制了允许重写的最小 aof 文件大小auto-aof-rewrite-min-size 64mb 四、关于 RBD 和 AOF 比较 如果同时开启 AOF 和 RDB 持久化，那么 redis 会优先使用 AOF 文件来还原数据，只有 AOF 关闭时候，redis 才会使用 RDB 持久化 参考阅读 redis 持久化 官方文档 中文文档 官方配置文件 Redis持久化之大数据服务暂停问题 Redis数据持久化机制AOF原理分析一 AOF分析 解密 redis 持久化]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis 持久化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 常见问题集锦]]></title>
    <url>%2Fnote%2Fdb_redis-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E9%9B%86%E9%94%A6.html</url>
    <content type="text"><![CDATA[如果你感到疲惫、孤独，如果你感到迷茫、焦虑，如果你感到忧伤、无奈就！在这个飞速旋转的年代，人已经得到了太多太多浮华奢侈、丰富多彩，但常常忘却了一件东西——简单。真正的透彻，不是精深复杂，而是简单。幸福是知足，是家庭，是健康 仍旧按照我之前的习惯，学这块就有常见碰到的错误的一篇文章，也是不断进行补充。 一、启动问题1.1 没有指定配置文件 Warning: no config file specified, using the default config. In order to specify a config file use ./redis-server /path/to/redis.conf 从字面就可以看出来问题是在没有指定配置文件就启动了 redis-server，所以解决办法给定配置文件启动即可 1.2 内存使用 warning WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add ‘vm.overcommit_memory = 1’ to /etc/sysctl.conf and then reboot or run the command ‘sysctl vm.overcommit_memory=1’ for this to take effect. 顾名思义，内存过量使用的阀值，默认设置成了0，也就是没开启，因为低内存的情况下，后台持久化可能会失败，所以如果为了消除这个警告，那么可以在内核参数里添加一项 echo 'vm.overcommit_memory = 1' &gt;&gt; /etc/sysctlsysctl -p 二、持久化问题2.1 RDB 持久化阻塞服务手动执行 save，会调用 rdbsave 函数。该函数会阻塞主线程的工作，当快照较大的时候对性能的影响也是非常大的，甚至是间断暂停服务，所以 master 最好不要进行内存快照 2.2 AOF 持久化如果不重写 AOF 文件，这个持久化方式对性能的影响是最小的，但是 AOF 文件会不断增大，AOF 文件过大会影响 Master 重启的恢复速度。 三、主从复制问题 更多阅读 redis 中文网问与答 redis FAQ Redis 常见的性能问题和解决方法]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis 常见问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 3 添加文章时自动打开编辑器]]></title>
    <url>%2Fnote%2Fgit_hexo-%E6%B7%BB%E5%8A%A0%E6%96%87%E7%AB%A0%E6%97%B6%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E7%BC%96%E8%BE%91%E5%99%A8.html</url>
    <content type="text"><![CDATA[当还能拥有时…好好珍惜吧…爱情如此…友情如此…亲情更是如此…最关心你的人…别只是永远被你排诸于外…当失去了……流泪又能做什么…… 为 Hexo 添加博客时需要在终端输入命令 hexo new post &quot;Post title&quot;，输入之后需要手动定位到 source/_posts 中的相关文件，这个目录比较深，定位比较麻烦，而 _posts 目录下可能有上百个文件，找到刚刚添加的那个也得费点劲，如果能在键入新建文章的命令之后能自动打开刚刚新建的文件，那样就方便多了。 GitHub 上也有人也提出了 同样的想法 ，Hexo 的作者 tommy351 给出了一个解决方法，就是在 Hexo 博客的根目录下的 scripts 目录中新建一个 JavaScript 脚本（如果没有 scripts 目录则手动创建一个），在其中捕获 new 事件。 我现在用的 markdown 编辑器是来自韩国的作者的 haroopad， 当然 Mou 也挺好，应用无所谓，平台 osx 10.10，调用的命令是 open，hexo 版本 3.x vim site_path/scripts/haroopad.js内容如下var spawn = require('child_process').spawn;// Hexo 2.xhexo.on('new', function(path)&#123; spawn('vi', [path]);&#125;);// Hexo 3hexo.on('new', function(data)&#123; spawn('vi', [data.path]);&#125;); 当然了，这是 tommy351 给出的回答，但是在我这里无法正确打开编辑器，参照网友 hexo 2 的代码结果改了改就可以了，如果是其他 APP，直接替换就好 var spawn = require('child_process').spawn;// Hexo 2.xhexo.on('new', function(path)&#123; spawn('open -a "/Applications/Haroopad.app" ' + path);&#125;);// Hexo 3.xhexo.on('new', function(data)&#123; spawn('open -a "/Applications/Haroopad.app" ' + path.path);&#125;); 这样每次新建文章时候自动打开编辑器，不经意间省下来的时间集，也增强了体验，让写文章更能成为一种乐趣吧~ 更多阅读 在为Hexo博客添加文章时自动打开编辑器]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>hexo 脚本</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程池原理及 python 实现]]></title>
    <url>%2Fnote%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%8E%9F%E7%90%86%E5%8F%8A%20python%20%E5%AE%9E%E7%8E%B0.html</url>
    <content type="text"><![CDATA[python 多线程学习的一篇不错的文章，转载自 http://www.cnblogs.com/goodhacker/p/3359985.html 为什么需要线程池 目前的大多数网络服务器，包括Web服务器、Email服务器以及数据库服务器等都具有一个共同点，就是单位时间内必须处理数目巨大的连接请求，但处理时间却相对较短. 传统多线程方案中我们采用的服务器模型则是一旦接受到请求之后，即创建一个新的线程，由该线程执行任务。任务执行完毕后，线程退出，这就是是“即时创建， 即时销毁”的策略。尽管与创建进程相比，创建线程的时间已经大大的缩短，但是如果提交给线程的任务是执行时间较短，而且执行次数极其频繁，那么服务器将处于不停的创建线程，销毁线程的状态。 我们将传统方案中的线程执行过程分为三个过程：T1、T2、T3：T1：线程创建时间T2：线程执行时间，包括线程的同步等时间T3：线程销毁时间 那么我们可以看出，线程本身的开销所占的比例为 (T1+T3) / (T1+T2+T3)。如果线程执行的时间很短的话，这比开销可能占到 20%-50% 左右。如果任务执行时间很频繁的话，这笔开销将是不可忽略的。 除此之外，线程池能够减少创建的线程个数。通常线程池所允许的并发线程是有上界的，如果同时需要并发的线程数超过上界，那么一部分线程将会等待。而传统方案中，如果同时请求数目为 2000，那么最坏情况下，系统可能需要产生 2000 个线程。尽管这不是一个很大的数目，但是也有部分机器可能达不到这种要求。 因此线程池的出现正是着眼于减少线程池本身带来的开销。线程池采用预创建的技术，在应用程序启动之后，将立即创建一定数量的线程 (N1)，放入空闲队列 中。这些线程都是处于阻塞（Suspended）状态，不消耗 CPU，但占用较小的内存空间。当任务到来后，缓冲池选择一个空闲线程，把任务传入此线程中运行。当 N1 个线程都在处理任务后，缓冲池自动创建一定数量的新线程，用于处理更多的任务。在任务执行完毕后线程也不退出，而是继续保持在池中等待下一次的任务。当系统比较空闲时，大部分线程都一直处于暂停状态，线程池自动销毁一部分线程，回收系统资源。 基于这种预创建技术，线程池将线程创建和销毁本身所带来的开销分摊到了各个具体的任务上，执行次数越多，每个任务所分担到的线程本身开销则越小，不过我们另外可能需要考虑进去线程之间同步所带来的开销。 构建线程池框架一般线程池都必须具备下面几个组成部分： 线程池管理器:用于创建并管理线程池 工作线程: 线程池中实际执行的线程 任务接口: 尽管线程池大多数情况下是用来支持网络服务器，但是我们将线程执行的任务抽象出来，形成任务接口，从而是的线程池与具体的任务无关。 任务队列:线程池的概念具体到实现则可能是队列，链表之类的数据结构，其中保存执行线程。 我们把任务放进队列中去，然后开 N 个线程，每个线程都去队列中取一个任务，执行完了之后告诉系统说我执行完了，然后接着去队列中取下一个任务，直至队列中所有任务取空，退出线程。 这就是一般的线程池实现的原理，下面看一个实际的代码： 线程池的 python 实现代码 # !/usr/bin/env python# -*- coding:utf-8 -*-import Queueimport threadingimport timeclass WorkManager(object): def __init__(self, work_num=1000,thread_num=2): self.work_queue = Queue.Queue() self.threads = [] self.__init_work_queue(work_num) self.__init_thread_pool(thread_num) # 初始化线程 def __init_thread_pool(self,thread_num): for i in range(thread_num): self.threads.append(Work(self.work_queue)) # 初始化工作队列 def __init_work_queue(self, jobs_num): for i in range(jobs_num): self.add_job(do_job, i) # 添加一项工作入队 def add_job(self, func, *args): # 任务入队，Queue内部实现了同步机制 self.work_queue.put((func, list(args))) # 等待所有线程运行完毕 def wait_allcomplete(self): for item in self.threads: if item.isAlive():item.join()class Work(threading.Thread): def __init__(self, work_queue): threading.Thread.__init__(self) self.work_queue = work_queue self.start() def run(self): # 死循环，从而让创建的线程在一定条件下关闭退出 while True: try: # 任务异步出队，Queue内部实现了同步机制 do, args = self.work_queue.get(block=False) do(args) # 通知系统任务完成 self.work_queue.task_done() except: break#具体要做的任务def do_job(args): time.sleep(0.1)#模拟处理时间 print threading.current_thread(), list(args)if __name__ == '__main__': start = time.time() # 或者work_manager = WorkManager(10000, 20) work_manager = WorkManager(10000, 10) work_manager.wait_allcomplete() end = time.time() print "cost all time: %s" % (end-start) Work 类是一个 Python 线程池，不断地从 workQueue 队列中获取需要执行的任务，执行之，并将结果写入到 resultQueue 中。这里的 workQueue 和 resultQueue 都是线程安全的，其内部对各个线程的操作做了互斥。当从workQueue 中获取任务超时，则线程结束。 WorkerManager负责初始化Python线程池，提供将任务加入队列和获取结果的接口，并能等待所有任务完成。 在 Python 中使用线程时，这个模式是一种很常见的并且推荐使用的方式。具体工作步骤描述如下： 创建一个 Queue.Queue() 的实例，然后使用数据对它进行填充。 将经过填充数据的实例传递给线程类，后者是通过继承 threading.Thread 的方式创建的。 生成守护线程池。 每次从队列中取出一个项目，并使用该线程中的数据和 run 方法以执行相应的工作。 在完成这项工作之后，使用 queue.task_done() 函数向任务已经完成的队列发送一个信号。 对队列执行 join 操作，实际上意味着等到队列为空，再退出主程序。 在使用这个模式时需要注意一点：通过将守护线程设置为 true，将允许主线程或者程序仅在守护线程处于活动状态时才能够退出。这种方式创建了一种简单的方式以控制程序流程，因为在退出之前，您可以对队列执行 join 操作、或者等到队列为空。队列模块文档详细说明了实际的处理过程，请参见参考资料 更多阅读 python实现线程池的例子 [C++][Thread] 转：线程池原理及创建（C++实现） 使用 Python 进行线程编程]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python 线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 并行化]]></title>
    <url>%2Fnote%2Fpython%20%E5%AE%9E%E7%8E%B0%E5%B9%B6%E8%A1%8C%E5%8C%96.html</url>
    <content type="text"><![CDATA[Python 在程序并行化方面学习，恰逢看到这篇文章的角度看到 python 并行化的教学显得另辟蹊径。转载自 http://www.zhangzhibo.net/2014/02/01/parallelism-in-one-line/Python 在程序并行化方面多少有些声名狼藉。撇开技术上的问题，例如线程的实现和 GIL，我觉得错误的教学指导才是主要问题。常见的经典 Python 多线程、多进程教程多显得偏“重”。而且往往隔靴搔痒，没有深入探讨日常工作中最有用的内容。 传统的例子 简单搜索下 “Python 多线程教程” ，不难发现几乎所有的教程都给出涉及类和队列的例子 #Example.py'''Standard Producer/Consumer Threading Pattern'''import time import threading import Queue class Consumer(threading.Thread): def __init__(self, queue): threading.Thread.__init__(self) self._queue = queue def run(self): while True: # queue.get() blocks the current thread until # an item is retrieved. msg = self._queue.get() # Checks if the current message is # the "Poison Pill" if isinstance(msg, str) and msg == 'quit': # if so, exists the loop break # "Processes" (or in our case, prints) the queue item print "I'm a thread, and I received %s!!" % msg # Always be friendly! print 'Bye byes!'def Producer(): # Queue is used to share items between # the threads. queue = Queue.Queue() # Create an instance of the worker worker = Consumer(queue) # start calls the internal run() method to # kick off the thread worker.start() # variable to keep track of when we started start_time = time.time() # While under 5 seconds.. while time.time() - start_time &amp;lt; 5: # "Produce" a piece of work and stick it in # the queue for the Consumer to process queue.put('something at %s' % time.time()) # Sleep a bit just to avoid an absurd number of messages time.sleep(1) # This the "poison pill" method of killing a thread. queue.put('quit') # wait for the thread to close down worker.join()if __name__ == '__main__': Producer() 哈，看起来有些像 Java 不是吗？ 我并不是说使用生产者/消费者模型处理多线程/多进程任务是错误的（事实上，这一模型自有其用武之地）。只是，处理日常脚本任务时我们可以使用更有效率的模型。 问题在于 … 首先，你需要一个样板类； 其次，你需要一个队列来传递对象； 而且，你还需要在通道两端都构建相应的方法来协助其工作（如果需想要进行双向通信或是保存结果还需要再引入一个队列）。 worker 越多，问题越多按照这一思路，你现在需要一个 worker 线程的线程池。下面是 一篇 IBM 经典教程 中的例子——在进行网页检索时通过多线程进行加速。 #Example2.py'''A more realistic thread pool example '''import time import threading import Queue import urllib2 class Consumer(threading.Thread): def __init__(self, queue): threading.Thread.__init__(self) self._queue = queue def run(self): while True: content = self._queue.get() if isinstance(content, str) and content == 'quit': break response = urllib2.urlopen(content) print 'Bye byes!'def Producer(): urls = [ 'http://www.python.org', 'http://www.yahoo.com' 'http://www.scala.org', 'http://www.google.com' # etc.. ] queue = Queue.Queue() worker_threads = build_worker_pool(queue, 4) start_time = time.time() # Add the urls to process for url in urls: queue.put(url) # Add the poison pillv for worker in worker_threads: queue.put('quit') for worker in worker_threads: worker.join() print 'Done! Time taken: &#123;&#125;'.format(time.time() - start_time)def build_worker_pool(queue, size): workers = [] for _ in range(size): worker = Consumer(queue) worker.start() workers.append(worker) return workersif __name__ == '__main__': Producer() 这段代码能正确的运行，但仔细看看我们需要做些什么：构造不同的方法、追踪一系列的线程，还有为了解决恼人的死锁问题，我们需要进行一系列的 join 操作。这还只是开始…… 至此我们回顾了经典的多线程教程，多少有些空洞不是吗？样板化而且易出错，这样事倍功半的风格显然不那么适合日常使用，好在我们还有更好的方法。 何不试试 mapmap 这一小巧精致的函数是简捷实现 Python 程序并行化的关键。map 源于 Lisp 这类函数式编程语言。它可以通过一个序列实现两个函数之间的映射 urls = ['http://www.yahoo.com', 'http://www.reddit.com']results = map(urllib2.urlopen, urls) 上面的这两行代码将 urls 这一序列中的每个元素作为参数传递到 urlopen 方法中，并将所有结果保存到 results 这一列表中。其结果大致相当于： results = []for url in urls: results.append(urllib2.urlopen(url)) map 函数一手包办了序列操作、参数传递和结果保存等一系列的操作。 为什么这很重要呢？这是因为借助正确的库，map 可以轻松实现并行化操作。 在 Python 中有个两个库包含了 map 函数： multiprocessing 和它鲜为人知的子库 multiprocessing.dummy. 这里多扯两句： multiprocessing.dummy？ mltiprocessing 库的线程版克隆？这是虾米？即便在 multiprocessing 库的官方文档里关于这一子库也只有一句相关描述。而这句描述译成人话基本就是说:”嘛，有这么个东西，你知道就成.”相信我，这个库被严重低估了！ dummy 是 multiprocessing 模块的完整克隆，唯一的不同在于 multiprocessing 作用于进程，而 dummy 模块作用于线程（因此也包括了 Python 所有常见的多线程限制）。所以替换使用这两个库异常容易。你可以针对 IO 密集型任务和 CPU 密集型任务来选择不同的库。 动手尝试使用下面的两行代码来引用包含并行化 map 函数的库： from multiprocessing import Poolfrom multiprocessing.dummy import Pool as ThreadPool 实例化 Pool 对象： pool = ThreadPool() 这条简单的语句替代了 example2.py 中 build_worker_pool 函数 7 行代码的工作。它生成了一系列的 worker 线程并完成初始化工作、将它们储存在变量中以方便访问。 Pool 对象有一些参数，这里我所需要关注的只是它的第一个参数：processes. 这一参数用于设定线程池中的线程数。其默认值为当前机器 CPU 的核数。 一般来说，执行 CPU 密集型任务时，调用越多的核速度就越快。但是当处理网络密集型任务时，事情有有些难以预计了，通过实验来确定线程池的大小才是明智的。 pool = ThreadPool(4) # Sets the pool size to 4 线程数过多时，切换线程所消耗的时间甚至会超过实际工作时间。对于不同的工作，通过尝试来找到线程池大小的最优值是个不错的主意。 创建好 Pool 对象后，并行化的程序便呼之欲出了。我们来看看改写后的 example2.py import urllib2 from multiprocessing.dummy import Pool as ThreadPool urls = [ 'http://www.python.org', 'http://www.python.org/about/', 'http://www.onlamp.com/pub/a/python/2003/04/17/metaclasses.html', 'http://www.python.org/doc/', 'http://www.python.org/download/', 'http://www.python.org/getit/', 'http://www.python.org/community/', 'https://wiki.python.org/moin/', 'http://planet.python.org/', 'https://wiki.python.org/moin/LocalUserGroups', 'http://www.python.org/psf/', 'http://docs.python.org/devguide/', 'http://www.python.org/community/awards/' # etc.. ]# Make the Pool of workerspool = ThreadPool(4) # Open the urls in their own threads# and return the resultsresults = pool.map(urllib2.urlopen, urls)#close the pool and wait for the work to finish pool.close() pool.join() 实际起作用的代码只有 4 行，其中只有一行是关键的。map 函数轻而易举的取代了前文中超过 40 行的例子。为了更有趣一些，我统计了不同方法、不同线程池大小的耗时情况。 # results = [] # for url in urls:# result = urllib2.urlopen(url)# results.append(result)# # ------- VERSUS ------- # # # ------- 4 Pool ------- # # pool = ThreadPool(4) # results = pool.map(urllib2.urlopen, urls)# # ------- 8 Pool ------- # # pool = ThreadPool(8) # results = pool.map(urllib2.urlopen, urls)# # ------- 13 Pool ------- # # pool = ThreadPool(13) # results = pool.map(urllib2.urlopen, urls)结果：# Single thread: 14.4 Seconds # 4 Pool: 3.1 Seconds# 8 Pool: 1.4 Seconds# 13 Pool: 1.3 Seconds 很棒的结果不是吗？这一结果也说明了为什么要通过实验来确定线程池的大小。在我的机器上当线程池大小大于 9 带来的收益就十分有限了。 另一个真实的例子生成上千张图片的缩略图这是一个 CPU 密集型的任务，并且十分适合进行并行化。 基础单进程版本import os import PIL from multiprocessing import Pool from PIL import ImageSIZE = (75,75)SAVE_DIRECTORY = 'thumbs'def get_image_paths(folder): return (os.path.join(folder, f) for f in os.listdir(folder) if 'jpeg' in f)def create_thumbnail(filename): im = Image.open(filename) im.thumbnail(SIZE, Image.ANTIALIAS) base, fname = os.path.split(filename) save_path = os.path.join(base, SAVE_DIRECTORY, fname) im.save(save_path)if __name__ == '__main__': folder = os.path.abspath( '11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840') os.mkdir(os.path.join(folder, SAVE_DIRECTORY)) images = get_image_paths(folder) for image in images: create_thumbnail(Image) 上边这段代码的主要工作就是将遍历传入的文件夹中的图片文件，一一生成缩略图，并将这些缩略图保存到特定文件夹中。 这我的机器上，用这一程序处理 6000 张图片需要花费 27.9 秒。 如果我们使用 map 函数来代替 for 循环： import os import PIL from multiprocessing import Pool from PIL import ImageSIZE = (75,75)SAVE_DIRECTORY = 'thumbs'def get_image_paths(folder): return (os.path.join(folder, f) for f in os.listdir(folder) if 'jpeg' in f)def create_thumbnail(filename): im = Image.open(filename) im.thumbnail(SIZE, Image.ANTIALIAS) base, fname = os.path.split(filename) save_path = os.path.join(base, SAVE_DIRECTORY, fname) im.save(save_path)if __name__ == '__main__': folder = os.path.abspath( '11_18_2013_R000_IQM_Big_Sur_Mon__e10d1958e7b766c3e840') os.mkdir(os.path.join(folder, SAVE_DIRECTORY)) images = get_image_paths(folder) pool = Pool() pool.map(creat_thumbnail, images) pool.close() pool.join() 5.6 秒！ 虽然只改动了几行代码，我们却明显提高了程序的执行速度。在生产环境中，我们可以为 CPU 密集型任务和 IO 密集型任务分别选择多进程和多线程库来进一步提高执行速度——这也是解决死锁问题的良方。此外，由于 map 函数并不支持手动线程管理，反而使得相关的 debug 工作也变得异常简单。 到这里，我们就实现了（基本）通过一行 Python 实现并行化。 原文网址：https://medium.com/building-things-on-the-internet/40e9b2b36148 Update:译文已获作者 Chris 授权 https://medium.com/building-things-on-the-internet/40e9b2b36148#66bf-f06f781cb52b 更多阅读 一行 Python 实现并行化 Parallelism in one line 关于 GIL（Global Interpretor Lock，全局解释器锁）更多的讨论]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python 并行化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 配置文件详解]]></title>
    <url>%2Fnote%2Fzabbix-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3-%E8%BD%AC.html</url>
    <content type="text"><![CDATA[zabbix 配置文件不算特别长，但是很多选项还是很有必要去了解的，所以这里参考官方文档和 ttlsa 上的内容，整理如下 AlertScriptsPath默认值：/usr/local/share/zabbix/alertscripts说明：告警脚本目录 AllowRoot默认值：0 说明：是否允许使用root启动，0:不允许，1:允许，默认情况下她会使用zabbix用户来启动zabbix进程，不推荐使用root CacheSize取值范围： 128K-8G默认值：8M说明：配置缓存，用于存储host，item，trigger数据，2.2.3版本之前最大支持2G，目前最大支持8G，一般用不了多少的。 CacheUpdateFrequency取值范围：1-3600默认值：60说明：多少秒更新一次配置缓存 DBHost默认值：localhost说明：数据库主机地址 DBName默认值：无必填：是 DBPassword：默认值：孔说明：数据库密码 DBPort取值范围：1024-65535默认值:3306说明：SQLite作为DB，这个选项请忽略，如果使用socket链接，也请忽略。 DBSchema说明：Schema名称. 用于 IBM DB2 、 PostgreSQL. DBSocket默认值：/tmp/mysql.sock说明：mysql sock文件路径 DebugLevel取值范围：0-5默认值：3说明: 指定debug级别 0 – 基本信息 1 – critical信息 2 – error信息 3 – warnings信息 4 – 调试日志，日志内容很多，慎重使用 5 – 用于调试web和vmware监控 ExternalScripts默认值： /usr/local/share/zabbix/externalscripts说明： 外部脚本目录 Fping6Location默认值：/usr/sbin/fping6说明：fping6路径，不懂fping的人可以百度一下，如果zabbix非root启动，请给fping6 SUID FpingLocation默认值：/usr/sbin/fping说明:和上面的一样 HistoryCacheSize取值范围：128K-2G默认值：8M说明：历史记录缓存大小，用于存储历史记录 HistoryTextCacheSize取值范围：128K-2G默认值：16M说明：文本类型历史记录的缓存大小，存储character, text 、log历史记录. HousekeepingFrequency取值范围：0-24默认值：1说明：housekeep执行频率，默认每小时回去删除一些过期数据。如果server重启，那么30分钟之后才执行一次，接下来，每隔一小时在执行一次。 Include说明：include配置文件，可以使用正则表达式，例如：/usr/local/zabbix-2.4.4/conf/ttlsa.com/*.conf JavaGateway说明：Zabbix Java gateway的主机名，需要启动Java pollers JavaGatewayPort取值范围：1024-32767默认值：10052Zabbix Java gateway监听端口 ListenIP默认值：0.0.0.0说明：监听地址，留空则会在所有的地址上监听，可以监听多个IP地址，ip之间使用逗号分隔，例如：127.0.0.1,10.10.0.2 ListenPort取值范围：1024-32767默认值：10051说明：监听端口 LoadModule说明：加载模块，格式: LoadModule=，文件必须在指定的LoadModulePath目录下，如果需要加载多个模块，那么写多个即可。 LoadModulePath模块目录，参考上面 LogFile日志文件，例如：/data/logs/zabbix/zabbix-server.log LogFileSize取值范围：0-1024默认值：10表示禁用日志自动rotation，如果日志达到了限制，并且rotation失败，老日志文件将会被清空掉，重新生成一个新日志。 LogSlowQueries取值范围：0-3600000默认值：0多慢的数据库查询将会被记录，单位：毫秒，0表示不记录慢查询。只有在DebugLevel=3时，这个配置才有效。 MaxHousekeeperDelete取值范围： 0-1000000默认值：5000housekeeping一次删除的数据不能大于MaxHousekeeperDelete PidFile默认值：/tmp/zabbix_server.pidPID文件 ProxyConfigFrequency取值范围：1-604800默认值：3600proxy被动模式下，server多少秒同步配置文件至proxy。 ProxyDataFrequency取值范围：1-3600默认值:1被动模式下，zabbix server间隔多少秒向proxy请求历史数据 SenderFrequency取值范围：5-3600默认值：30间隔多少秒，再尝试发送为发送的报警 SNMPTrapperFile默认值：/tmp/zabbix_traps.tmpSNMP trap发送到server的数据临时存放文件。 SourceIP出口IP地址 SSHKeyLocationSSH公钥私钥路径 SSLCertLocationSSL证书目录，用于web监控 SSLKeyLocationSSL认证私钥路径、用于web监控 SSLCALocationSSL认证,CA路径，如果为空，将会使用系统默认的CA StartDBSyncers取值范围：1-100默认值：4预先foke DB Syncers的数量，1.8.5以前最大值为64 StartDiscoverers取值范围：0-250默认值：1pre-forked discoverers的数量，1.8.5版本以前最大可为255 StartHTTPPollers取值范围：0-1000默认值：1pre-forked HTTP pollers的数量，1.8.5以前最大255 StartIPMIPollers取值范围：0-1000默认值：0pre-forked IPMI pollers的数量，1.8.5之前，最大为255 Timeout取值范围：1-30默认值：3agent，snmp，external check的超时时间，单位为秒 TmpDir默认值：/tmp TrapperTimeout取值范围：1-300默认值：300处理trapper数据的超时时间 TrendCacheSize取值范围：128K-2G默认值：4M历史数据缓存大小 UnavailableDelay取值范围：1-3600默认值：60间隔多少秒再次检测主机是否可用 UnreachableDelay取值范围：1-3600默认值：15间隔多少秒再次检测主机是否可达。 UnreachablePeriod取值范围：1-3600默认值：45检测到主机不可用，多久将它置为不可达 User默认值：zabbix启动 zabbix server 的用户，在配置禁止 root 启动，并且当前 shell 用户是 root 得情况下有效。如果当前用户是 ttlsa，那么 zabbix server 的运行用户是 ttlsa ValueCacheSize取值范围：0,128K-64G默认值：8M0 表示禁用，history value 缓存大小，当缓存超标了，将会每隔 5 分钟往 server 日志里面记录。养成看日志的好习惯。 更多阅读 zabbix_agentd.conf zabbix_server.conf ttlsa]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix_server.conf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网球初学小记]]></title>
    <url>%2Fnote%2F%E5%81%A5%E8%BA%AB_%E7%BD%91%E7%90%83%E5%88%9D%E5%AD%A6%E5%B0%8F%E8%AE%B0.html</url>
    <content type="text"><![CDATA[珍惜每一个逆境中的自己，因为那是继续前进下去的动力 一直很喜欢网球，虽也有打过羽毛球的经历，但是对网球的热情一直没有递减过，最后经过网友的推荐，选定了一个口碑不错的教练，终于开始了网球的学习之路，在这里呢我也将我学习的进度和经过和一些心得总结分享给各位 大多都是介绍上课的流程和内容，具体每个流程里的知识点，这里文字多数无法写出，需要自己结合书籍，视频，亲身训练，多做基本功的训练才可以后期中一气呵成，不要图求快，求稳打稳扎 day1 终于开始了上课的内容，也终于如同自己所说落实自己的兴趣爱好，每次上课还有点小激动呢 1、球拍介绍和握拍姿势介绍因为是问我是不是第一次打网球，简单的介绍了网球的历史，也染我自己去课外找这些东西，了解一下还是有好处的，主体时间用来教学，增加有效教学时间，这也是觉得靠谱的原因之一 2、热身运动和其他运动类似，需要拉伸几大块肌肉群，每次入场之前几分钟之内做好拉伸，看似虽小，其实很重要 3、基本颠球，接球姿势，击球，收拍动作介绍 a、网球的多数击球动作基础颠球，作为教练判断这个人的基本功和个人掌控球拍击球的位置和力度，慢慢的多颠球中养成肌肉记忆，打牢基本功，这里一定是注意的是保持手臂，拍子到击球的这个臂的距离基本不要动，不要缩胳膊来接球，而是移动脚步来进行找准击球点，保持一定的姿势进行迎接球； b、收拍就是在完成击球后拍子回到后背，行程一个优雅的弧形的动作，因为这个让每一次击球都具有观赏性 4、基本传球、颠球训练保持好能预判，找准击球点，就开始练习把球打出去的练习，不过依旧保持步伐、击球姿势，和基本颠球的情况下完成传球的训练 第一次上完课的收获，基本上都是感觉基本功还是要花时间巩固的，并且基本功对后面影响还是蛮大的 day2 虽然是第一次上课，第一次踏进网球场，不过凭借还可以的身体条件和羽毛球的一些经验，得到教练称赞身体素质完成了超前完成了内容，所以后期可能会增加课程内容进行补充，而且发觉一件事情，网球和健身一样会上瘾… 1、脚步移动动作练习这部分进行场地横向移动，倒退后撤的训练，以应对未来可能进行的快速移动，这部分还是挺耗费体力的，虽然我觉得我体力还是挺好的 2、基础颠球的复习直接在第一天的基础上进行颠一次球，和球的节奏一起上下蹲，在弹起的时候用之前的力度把球电器，球下降的时候重心下降，看清球在最高处的停顿一刹那 3、正手击球、收拍的练习第一天是击球，和收拍的讲解，今天就是一次性和教练一回合保证 50 个击球并收拍的动作，动作进行连贯起来。这部分真心不能着急，在教练给球的时候，过于急速求成导致中断了几次，导致单回合数量下降，稳定后单回合数量明显上升，这里切记要记住 4、反手击球、收拍的练习反手和正手略有不同，颠球，击球，收拍，站位，握拍呢，进行反手训练，并进行 50 个反手训练 5、发球和比赛规则介绍最后部分就是基本的发球常识和场地介绍，发球规则，和比赛规则的一些介绍 第二次课结束的明显感觉是，调整心态，不能过于在基本动作上追求捷径，得稳打稳扎，才能将单回合有效球提升 day3 下班高峰做公交也真是醉人呐，硬生生堵在路上迟到半个小时，心塞… 1、正反手击球复习继续巩固击球的步骤、分段技巧，注意因素 2、正反手拉拍动作过渡训练原有的正反手拉拍动作基础上，增加引拍的过度训练 3、正反手拉拍击球动作训练引拍的过渡事项，正反手完全动作的引拍，这里尤为注意动作的连贯性，稳拍，发力时机，这里注意左右手握拍的配合脚下动作的配合 4、发球初步发球的认识之后，发球技巧和注意事项 day4 五一前的最后一节课，正好还是基础复习的课程 1、正手全动作击球训练这部分已经引拍到最大角度的姿势结合之前训练的过渡引拍完整的一套动作进行慢速训练，着重强调下降期间胳膊和身体姿势的距离以及相关注意要点，这里我的手腕一直会出现一点问题，得加强注意 2、反手全动作击球训练和正手一样的反手巡训练 3、正规迎球姿势及归位正规比赛时候的展位，大致的走位，身体击球姿势等讲解 4、上旋、平击、侧击球要点抛球训练，不通的球的抛出位置不同，上旋球抛出约为12点方向，平击约为一点种方向。然后挥拍迎接球讲解和训练 day5 基本动作的纠错和平击发球 1、正手击球脚步动作变化训练这部分包括身体下蹲，重心转移，转体的纠错，毕竟练习有限，全程串起动作一些误区 2、反手击球脚步动作变化训练这部分不一样的是教的是双手握拍，注意肘部动作，转体 3、最佳击球点训练无规律自由落球，碎步移动找寻最佳击球位置，注意移动过程中的身体重心，乃至右臂离球 的位置，以及右臂的动作不能过度变化 4、平击发球训练先从平击开始入手发球，注意抛球的高度，右手切入的角度，拍面击球的角度是仰角而不是锐角，以及最后的收拍，开始练习注意尽可能放慢速度 day6 还是在不断矫正击球动作主体。我在快速击球中，就会出现动作变形，姿势不准确等情况 1、正反手击球训练复习矫正之前的正反手击球训练动作 2、正反手轮转切换训练还是击球训练，纠正错误的动作，另外随机正反手切换训练，在此基础上进行动作矫正 3、比赛开始准备姿势，脚步移动归位训练这一部分包括正手区域迎接动作变化，反手区域迎接动作变化，预备姿势的切换，打球归位的一套步伐联系 4、正规比赛发球动作完整的讲比赛时候发球的站位、角度、姿势进行梳理一遍，包括抛球，抗拍，起身，挥拍，收拍到最后全部完成的整套动作的训练 day7 没订到场地，只能是从 8 - 9 点开始，用上最后一小时，所以直接干脆继续处于正反手切随机发球击球动作训练和动作纠正 正手击球训练主体分为预判阶段1、移动步伐阶段2、击球阶段3，注意三个阶段的衔接，第三阶段的停顿缓冲等 反手击球训练 随机正反手训练 day8 严格来说，这是 7.5 天啦，上次只上了半天课，这部分主要是比赛中使用的全套正规动作 正手预备到迎球动作和脚步移动还是分为四个阶段，第一阶段预判，第二阶段起步和引拍，第三阶段击球，第四阶段归位。注意第二阶段起步弹跳起步的左右脚节奏感和起步顺序，第三阶段击球的重心所在 反手预备到迎球动作和脚步移动同正手一样，熟悉双手握拍和单手握拍的不同即可 发球到最后这部分还是没剩下多少时间，所以依旧进行基本发球训练 day9 今天到了线路了，除了基本的发球以外，加上了线路的控制 正反手击球训练基本功训练，姿势纠错 直线，内角，外角线路发球控制注意在击球的基础上，进行，手腕控制球拍的角度来实现击球线路 发球 day10 还是练得少，每次都靠上课这一会，进步实在是很有限，甚至还经常犯老毛病 动作纠错多数动作进行纠错，快速移动中进行纠错 常规比赛积分制这里就是仿照正规比赛，了解正规比赛赛制 发球训练 day11 今天是最后一节课了，也宣布着我的课程结束了，不过今天状态很不对，1点半从健身房出来，然后紧接着顶着大太阳热出翔了，最后实在受不了了，体力透支，就提前结束了 正反手自由击球训练快速，慢速球里接球方式，特殊的情况的一些处理 削球训练反手训练除了正常的击球意外，还可以进行削球，注意削球的时候球拍的微微变化和手肘的固定，就是不能乱动手肘 结课后日后的注意事项主要是我主要一个下蹲的问题；另外我的盆骨每次转都可能转的不彻底，所以转体这块也是我一个注意的问题；最后一个特别需要注意的时候，转体引拍一定要往后啦，我在不自觉期间就不会拉到那么大 经过断断续续的一个多月，结束了所有的课程，教练还是人还是不错的，比较细心，在这边点个赞啦，也顺便帮教练宣传一下哈 更多阅读 波利泰里尼网球手册]]></content>
      <categories>
        <category>生命在于运动</category>
      </categories>
      <tags>
        <tag>网球初学小记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell 中 sed & awk 实例集锦]]></title>
    <url>%2Fnote%2Fshell-%E4%B8%AD-sed-awk-%E5%B0%8F%E6%8A%80%E5%B7%A7.html</url>
    <content type="text"><![CDATA[别为不属于你的观众，演不擅长的人生！ shell 脚本中经常穿插一些 sed， awk ，关于这个两个工具也足有几本书来描述，所以这里单独放一篇出来进行总结一些日常用到的功能 一、grep1.1 过滤配置文件# 过滤掉注释和空行，保留有效配置grep -v "^#\|^$" /etc/zabbix/zabbix_agentd.conf 1.2 遍历搜索 当前目录下有个文件里有个文件里包含某个字段，但是不知道在哪个文件，对当前文件递归过滤出包含这个字段的文件 grep -r "segment" ./* 二、sed 添加的内容都用大写的 CONTENT 替换 2.1、在某一行的前一行或后一行添加内容# 匹配行前加sed -i '/2222222222/iCONTENT' test.txt# 匹配行前后sed -i '/2222222222/aCONTENT' test.txt 2.2、在某行（指具体行号）前或后加一行内容# 匹配行前加sed -i 'N;4iCONTENT' a.txt# 匹配行前后sed -i 'N;4aCONTENT' a.txt 2.3、删除指定行的上一行或下一行 这里用到了 sed 的高级用法，空间的用法 # 删除指定文件的上一行sed -i -e :a -e '$!N;s/.*n(.*directory)/1/;ta' -e 'P;D' server.xml# 删除指定文件的下一行sed -i '/pattern="%/&#123;n;d&#125;' server.xml 2.4 VIM 中的替换 syntax: [addr]s/源字符串/目的字符串/[option] syntax：:%s/源字符串/目的字符串/g [addr] 表示检索范围，省略时表示当前行。 "1，20" ：表示从第1行到20行；"%" ：表示整个文件，同“1,$”；".,$" ：从当前行到文件尾； s : 表示替换操作 [option] : 表示操作类型 - g 表示全局替换- c 表示进行确认- p 表示替代结果逐行显示（Ctrl + L恢复屏幕）；- 省略option时仅对每行第一个匹配串进行替换；- 如果在源字符串和目的字符串中出现特殊字符，需要用”\”转义 实例： #将That or this 换成 This or that:%s/\(That\) or \(this\)/\u\2 or \l\1/#将句尾的child换成children:%s/child\([ ,.;!:?]\)/children\1/g#将mgi/r/abox换成mgi/r/asquare:g/mg\([ira]\)box/s//mg//my\1square/g &lt;=&gt; :g/mg[ira]box/s/box/square/g#将多个空格换成一个空格:%s/ */ /g#使用空格替换句号或者冒号后面的一个或者多个空格:%s/\([:.]\) */\1 /g#删除所有空行:g/^$/d#删除所有的空白行和空行:g/^[ ][ ]*$/d#在每行的开始插入两个空白:%s/^/&gt; /#在接下来的6行末尾加入.:.,5/$/./#颠倒文件的行序:g/.*/m0O &lt;=&gt; :g/^/m0O#寻找不是数字的开始行,并将其移到文件尾部:g!/^[0-9]/m$ &lt;=&gt; g/^[^0-9]/m$#将文件的第12到17行内容复制10词放到当前文件的尾部:1,10g/^/12,17t$~~~~重复次数的作用#将chapter开始行下面的第二行的内容写道begin文件中:g/^chapter/.+2w&gt;&gt;begin:/^part2/,/^part3/g/^chapter/.+2w&gt;&gt;begin:/^part2/,/^part3/g/^chapter/.+2w&gt;&gt;begin|+t$ 三、awk四、findhttp://www.cnblogs.com/baibaluo/archive/2012/08/16/2642403.htmlhttp://blog.lichengwu.cn/architecture/2015/06/14/distributed-cache/ 更多阅读 sed与awk（第二版） The AWK Programming Language O’Reilly sed &amp; awk 2nd Edition 英文版 sed &amp; awk 101 hacks [O’Reilly sed &amp; awk 2nd Edition中文高清修订第3版]http://bbs.chinaunix.net/thread-1743038-1-1.html [awk1line &amp; sed1line 注解补充版&amp;cheat sheets]http://bbs.chinaunix.net/thread-1635180-1-1.html [sed1line翻译加注]http://bbs.chinaunix.net/thread-336126-1-1.html [sed手册]http://bbs.chinaunix.net/thread-605565-1-1.html [三篇awk学习资料]http://bbs.chinaunix.net/thread-1425973-1-4.html [思维导图：sed]http://bbs.chinaunix.net/thread-909637-1-1.htmlhttp://bbs.chinaunix.net/thread-1061338-1-1.html [思维导图：awk]http://bbs.chinaunix.net/thread-1166276-1-1.html [思维导图：sed &amp; awk]http://bbs.chinaunix.net/thread-1695244-1-1.htmlhttp://bbs.chinaunix.net/thread-1741478-1-1.html]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>sed小技巧</tag>
        <tag>awk小技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb 常见错误及解决办法]]></title>
    <url>%2Fnote%2Fdb_mongodb-%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95.html</url>
    <content type="text"><![CDATA[生活不是 MP3，不会一直播放我们喜欢的歌。它是台收音机，而我们应该调整好心态，去享受它带来的每个节目 本篇也是记录日常所碰到的 mongodb 一些相关的错误，整理到一起，后续也会陆续收录一些碰到过的其他问题 一、启动错误 报错：child process failed, exited with error number 100 日志信息输出 Unclean shutdown detected.Please visit http://dochub.mongodb.org/core/repair for recovery instructions. Sat Apr 20 09:40:31.286 [initandlisten] exception in initAndListen: 12596 old lock file, terminating 解决方式就是要以修复的方式启动 # 1、首先查看数据目录下会有一个 `mongod.lock` 文件，需要删除# 2、已 `repair` 的模式启动mongod -f mongod.conf --repair# 3、正常启动即可mongod -f mongod.conf 更多阅读 Manage mongod Processes]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb 常见错误集锦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 入门书籍和方法分享(转)]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E5%85%A5%E9%97%A8%E4%B9%A6%E7%B1%8D%E5%92%8C%E6%96%B9%E6%B3%95%E5%88%86%E4%BA%AB-%E8%BD%AC.html</url>
    <content type="text"><![CDATA[这篇看到一个别人的帖子，介绍了 MySQL 的一些方法和书籍，自己补充一些学习资源和网站，可能并不是特别完全，有更好的资源保持更新 一、SQL 入门在准备成为 MySQL DBA 之前，能熟练的编写 SQL 是一个必要条件。exists 和 join 之间的等价转换；基本的行列转换；SQL 循环等的熟练掌握对之后的运维和调优工作都有很大的帮助。 推荐书籍： SQL Cookbook一本循序渐进的 SQL 指导手册。每一种业务需求，书中都用 MySQL，SQL Server，Oracle 三种语法进行解析。可以顺序的作为学习书籍，也可以之后作为工具书籍查阅 The Art of SQL将 SQL 调优模拟成一场战役，进行战术分析。更多的是传授SQL架构设计方面的知识，实际的调优实例不多，翻译很烂，建议看原版 SQL应用重构 MySQL Stored Procedure Programming学习 MySQL 存储过程语法和编写的最好教材。虽然版本比较老，但是大部分的语法都没有变更，比较推荐 二、SQL 进阶 &amp; 精通如果你已经熟练掌握了基本的SQL编写技巧，就可以进入对于MySQL产品本身的入门学习了 推荐书籍: High Performance MySQLMySQL 界的圣经，目前已经出到第三版。非常详细的介绍了 MySQL 运维的各个部分，可以通读了解，也可以作为工具书进行查阅 深入浅出MySQL数据库开发、优化与管理维护中文原创书籍中比较适合入门的一本。教粗浅的介绍了 MySQL 的相关特性，比较适合 MySQL 运维的入门 MySQL技术内幕 innodb 存储引擎很详细的从代码层面分析了 Innodb 的内部结构，适合深入学习 innodb。 三、其他MySQL 入门除了通过书本学习理论知识以外还有其他各种方式可以进行学习推荐书籍： Our Episode一个类似于 MySQL 电台的节目 ，每周会定期出一个音频讨论一个 MySQL 话题。 是学习 MySQL&amp;学习英语 的好选择 MySQL Planet几乎涵盖了所有 MySQL 业界大牛的博客 RSS 汇总。强烈建议订阅 MOOC各类公开课程网站都会有免费得 MySQL 入门课程试听。这里就不一一列举了 四、运维 &amp; 数据思想推荐书籍： The Art of Capacity Planning作为运维免不了要做容量规划和容量预测。这本书是一个很好的开始 Beautiful Data: The Stories Behind Elegant Data Solutions数据库运维对于数据的敏感是一个重要特质。 五、第三方下载 http://ftp.nchu.edu.tw/Unix/Database/MySQL/Downloads/ http://mirrors.sohu.com/mysql http://mirrors.163.com/ http://mirrors.aliyun.com/ http://mirrors.yun-idc.com/ 官方站点 http://dev.mysql.com/downloads/mysql/ community server http://dev.mysql.com/downloads/repo/yum/ 官方yum源 http://dev.mysql.com/downloads/repo/apt/ 官方apt源 http://www.percona.com/]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mysql 入门书籍和方法分享</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 数据备份]]></title>
    <url>%2Fnote%2Fdb_redis-%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD.html</url>
    <content type="text"><![CDATA[研究 mysql、mongodb 的时候总是从安装，备份恢复，等开始学起的，redis 恰好也碰到了，所以正好整起，参考了网友的文章，参照官网内容，整理如下Redis 提供了两种持久化选项，分别是 RDB 和 AOF 一、RDB默认情况下 60 秒刷新到磁盘一次 [save 60 10000 当有1w条keys数据被改变时]，Redis 的数据集保存在叫 dump.rdb 一个二进制文件，这种策略被称为快照。 # 手动调用 Save 或 BGSAVE 命令的：redis-cli -h 127.0.0.1 -p 6379 -a pwd bgsave 快照易恢复，文件也小，但是如果遇到宕机等情况的时候快照的数据可能会不完整。 二、AOF另一种持久化方式 AOF，在配置文件中打开 [appendonly yes]。 AOF 刷新日志到磁盘的规则: appendfsync alwaysalways 表示每次有写操作都进行同步，非常慢，非常安全。 appendfsync everyseceverysec 表示对写操作进行累积，每秒同步一次 官方的建议的 everysec，安全，就是速度不够快，如果是机器出现问题可能会丢失 1 秒的数据。 # 手动执行 bgrewriteaof 进行 AOF 备份：redis-cli -h 127.0.0.1 -p 6379 -a pwd bgrewriteaof 三、恢复策略 如果只配置 AOF,重启时加载 AOF 文件恢复数据； 如果同时 配置了 RBD 和 AOF,启动是只加载 AOF 文件恢复数据; 如果只配置 RBD,启动是将加载 dump 文件恢复数据。 恢复时需要注意，要是主库挂了不能直接重启主库，否则会直接覆盖掉从库的 AOF 文件，一定要确保要恢复的文件都正确才能启动，否则会冲掉原来的文件。 四、备份脚本 参照网友文章 http://huoyingdk.blog.51cto.com/3932829/1089225 的脚本，改变而来，我这里只针对于开启了 AOF 持久化的情况 #!/bin/sh#-------------------------------------------------------# author: mingmings# url: http://mingmings.org/# mail: 369413651@qq.com# date: 2015-04-07# version: 1.0#-------------------------------------------------------DB_DIR=""BACKUP_DIR=""#-------------------------------------------------------for PORT in $(ps -ef | grep redis | grep -v grep | awk -F: '&#123;print $4&#125;')do# echo $&#123;PORT&#125; redis-cli -h 127.0.0.1 -p $&#123;PORT&#125; -a pwd bgrewriteaofdonesleep 5tt=$(date +"%F_%T")if [ ! -d $&#123;BACKUP_DIR&#125; ]; then mkdir -p $&#123;BACKUP_DIR&#125;fiecho "--------------------------$&#123;tt&#125;------------------------------" &gt;&gt; $&#123;BACKUP_DIR&#125;/redis_backup.logfor i in $(find $&#123;DB_DIR&#125; -name "*.aof")do #echo $&#123;i&#125; echo "cp $&#123;i&#125; $&#123;BACKUP_DIR&#125;/$(dirname $&#123;i&#125; | awk -F/ '&#123;print $NF&#125;')/$(basename $i)" &gt;&gt; $&#123;BACKUP_DIR&#125;/redis_backup.log if [ ! -d $&#123;BACKUP_DIR&#125;/$(dirname $&#123;i&#125; | awk -F/ '&#123;print $NF&#125;') ]; then mkdir -p $&#123;BACKUP_DIR&#125;/$(dirname $&#123;i&#125; | awk -F/ '&#123;print $NF&#125;') fi /bin/cp -f $&#123;i&#125; $&#123;BACKUP_DIR&#125;/$(dirname $&#123;i&#125; | awk -F/ '&#123;print $NF&#125;') echo "redis backup done..."done 更多阅读 Redis Persistence redis持久化]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis数据备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 错误集锦]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6.html</url>
    <content type="text"><![CDATA[此篇专门用来记录 MySQL 各方面出现的一些错误以及解决方法等 一、安装错误1.1、初始化库错误提示# /usr/local/mysql/scripts/mysql_install_db --user=mysql --datadir=/data/mysql3307/FATAL ERROR: Could not find ./bin/my_print_defaultsIf you compiled from source, you need to run 'make install' tocopy the software into the correct location ready for operation.If you are using a binary release, you must either be at the toplevel of the extracted archive, or pass the --basedir optionpointing to that location. 严格来说这不算是个错误，只是提示路径不对，或者加上基准路径的参数第一种解决方法就是移动到 cd ${INSTALL_DIR} 再次执行这个命令即可正确初始化库了 第二种解决方法直接加上基准路径，这里假如我安装的位置是 /usr/local/bin # /usr/local/mysql/scripts/mysql_install_db --user=mysql --basedir=/usr/local/bin --datadir=/data/mysql3307/ 1.2、初始化库错误提示 看到有人提到 MySQL 官方的 bug 里，详情见 Bug #31312 # 启动报错~/bin/mysqld_safe --user=mysql --ledir=/tools/mysql/mysql --defaults-file=/etc/mysql/mysql3307.cnf &amp;# 查看错误日志看到如下信息[ERROR] ~/mysql/bin/mysqld: unknown variable 'defaults-file=/etc/mysql/mysql3307.cnf'[ERROR] Aborting# 根据 bug 文档里内容更换参数位置重新启动即可~/bin/mysqld_safe --defaults-file=/etc/mysql/mysql3307.cnf --user=mysql --ledir=/tools/mysql/mysql/bin &amp; 1.3、mysql.sock 文件查找不到的情况ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' (2) 这里我碰到过的就有好几种情况会碰到找不到 sock 文件的，分别列举 1.最近一次是因为做了单机多实例的关系，所以修改了原先的 3306 的 sock 文件名称，重启服务后必须 -S sockfile 来指定文件启动，如果不指定，就会报这个错误，但其实这也不是个错误，要么指定一下，要么直接做个软链接即可 # 解决方法ln -s /tmp/mysql3306.sock /tmp/mysql.sock 2.第二种是真的 sock 文件丢失的情况，这时候查看 mysql 进程也基本上不存在 # 解决方法，通过安全模式启动mysqld_safe --user=mysql &amp;启动之后查看错误日志，一般情况下都会相关的错误信息，根据错误信息进行相关排查即可 二、主从复制错误2.1、冲突的 server-id Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the –replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it). 解决方法： 提示很明显 master 和 slave 有着同样的 server-id，修改成不同的 server-id 即可 2.2、从库读取 binlog 执行 sql 出错mysql&gt; show slave status;报错: Error xxx dosn't existmysql&gt; show slave status\G:Slave_IO_Running: YesSlave_SQL_Running: NOSeconds_Behind_Master: NULL 解决方法: stop slave;set global sql_slave_skip_counter=1;start slave; 这样 Slave 就会和 Master 去同步 Slave_IO_Running: YesSlave_SQL_Running: YesSeconds_Behind_Master 此项参数表明 slave 落后 master 的进度。是否为0，0表示已经同步状态。 提示： set global sql_slave_skip_counter=n; #n 取值 &gt;0 忽略执行 N 个更新 2.3、同步线程正常，但同步异常 转载自 http://itopic.org/mysql-master-slave-error.html 老彭的博客 主从同步异常，先去主库上去查状态。查看主库状态正常，binlog position 一直在变，进程状态也正常 mysql&gt; show master status;+------------------+-----------+--------------+------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB |+------------------+-----------+--------------+------------------+| mysql-bin.000364 | 232554068 | | |+------------------+-----------+--------------+------------------+mysql&gt; show processlist;+-------------+----------+-----------------------------------------------------------------------------+| Command | Time | State |+-------------+----------+-----------------------------------------------------------------------------+| Connect | 14536445 | Slave has read all relay log; waiting for the slave I/O thread to update it || Binlog Dump | 22459 | Master has sent all binlog to slave; waiting for binlog to be updated |+-------------+----------+-----------------------------------------------------------------------------+ 接下来查看重库状态，整体上看重库只是有延迟 mysql&gt; show slave status\G; Master_Log_File: mysql-bin.000364Read_Master_Log_Pos: 246924389Relay_Log_File: mysql-relay-bin.3831269Relay_Log_Pos: 244389572Relay_Master_Log_File: mysql-bin.000363Slave_IO_Running: YesSlave_SQL_Running: YesSeconds_Behind_Master: 23423mysql&gt; show processlist;+---------+-------+-----------------------------------------------------------------------------+------------------+| Command | Time | State | Info |+---------+-------+-----------------------------------------------------------------------------+------------------+| Connect | 22800 | Waiting for master to send event | NULL || Connect | 99 | Slave has read all relay log; waiting for the slave I/O thread to update it | NULL |+---------+-------+-----------------------------------------------------------------------------+------------------+ 但等一段时间查看重库却一直不更新，重启后 Seconds_Behind_Master 为 0， Slave_IO_Running 和 Slave_SQL_Running 状态均为 YES。确认了 Master_Host、Master_User 等参数，也匹配了 Master_Server_Id 都是正常的。而后查询 binlog mysqlbinlog mysql-relay-bin.3831269 --start-position=244389572 --stop-position=246924461 | moremysqlbinlog mysql-relay-bin.3831269 --start-datetime="2014-08-07 21:30:00" --stop-datetime="2014-08-07 21:35:00" --base64-output=decode-rows -v | more binlog 基于行的复制带上了 --base64-output=decode-rows -v 参数。 慢慢的还真的发现了点东西，发现有执行很多的删除语句，当通过 wc 统计时发现竟然有70多万。在通过业务查看是有执行一条 SQL ，删除表中的所有记录，数据太多，此时查看主从这个表的记录，主库为空，重库记录全在，那可能就是这个原因导致的。该操作可以跳过，于是尝试跳过之： mysql&gt;slave stop;mysql&gt;SET GLOBAL SQL_SLAVE_SKIP_COUNTER = 1;mysql&gt;slave start; 跳过后 Mysql 恢复正常，最后手动清空重库中该表的数据。至于为什么这个大的删除导致重库停止，还有待深究。 2.4、max_allowed_packet 限制导致主从同步出错 摘抄自 http://itopic.org/mysql-master-slave-error.html 老彭的博客 产生的原因也是执行了一个较大的更新，往数据库中更新几十兆的数据（可见更新的不合理），导致主从同步出错，查看重库状态显示 Last_IO_Error: Got fatal error 1236 from master when reading data from binary log:‘log event entry exceeded max_allowed_packet; Increase max_allowed_packet on master’ 提示修改 max_allowed_packet， 我们就可以看下这个参数的含义 mysql 服务是通过网络包来传输数据的(通信信息包是指发送至 MySQL 服务器的单个 SQL 语句或发送至客户端的单一行),mysql 协议能够识别的数据包的大小是由max_allowed_packet 控制的。当 MySQL 客户端或 mysqld 服务器收到大于max_allowed_packet 字节的信息包时,将发出 “log event entry exceeded max_allowed_packet;” 错误,并关闭连接。就像此次主从复制遇到的，IO 进程从主库获取日志，但是单个日志中的 sql 大小超过了 max_allowed_packet 的限制，于是报错, IO thread 进程停止，sql thread 显示为 yes。 对于客户端,如果通信信息包过大,在执行查询期间,可能会遇到 “丢失与 MySQL 服务器的连接” 错误。详细参数文档： http://dev.mysql.com/doc/refman/5.5/en/packet-too-large.html http://dev.mysql.com/doc/refman/5.5/en/server-system-variables.html#sysvar_max_allowed_packet 解决方案就是调整主从 server 上的该参数的值 # 命令行修改临时生效stop slave;set global max_allowed_packet=1*1024*1024;start slave;# 配置文件修改重启生效[mysqld]max_allowed_packet=1*1024*1024 参数的值有一些限制，默认值是 1048576，最小值 1024，最大值 1073741824，并且需要为 1024 的倍数，并且更改 master 这个值最好也需要更改 slave 的值，防止被 client 的配置值覆盖 三、登录错误3.1 登录异常 mysql&gt; show databases;报错信息如下 “Ignoring query to other database”，做任何操作都一样 登录输入少了参数 -u，变成了 mysql -root -p变更成 -u root 后恢复正常 &emsp;&emsp; 更多阅读 Troubleshooting Problems Connecting to MySQL InnoDB Troubleshooting]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>MySQL 错误集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 单机多实例]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E5%8D%95%E6%9C%BA%E5%A4%9A%E5%AE%9E%E4%BE%8B.html</url>
    <content type="text"><![CDATA[出现这个原因是因为在测试一个功能的时候，为了避开直接停主库导致的时间，所以在主库所在的机器上起了一个多实例，导入主库数据和异地一个备份库做主从测试，如果成功则替换掉原有主，所以总结如下 一、多实例背景1.1、环境mysql version: 5.5-30multi_instance: 3307 1，采用了数据伪分布式架构的原因，而项目启动初期又不一定有那多的用户量，为此先一组物理数据库服务器，但部署多个实例，方便后续迁移； 2，为规避 mysql 对 SMP 架构不支持的缺陷，使用多实例绑定处理器的办法（ NUMA 处理器必须支持，不过现在大部分处理器都支持的！），把不同的数据库分配到不同的实例上提供数据服务； 3，一台物理数据库服务器支撑多个数据库的数据服务，为提高 mysql 复制的从机的恢复效率，采用多实例部署；已经为双主复制的 mysql 数据库服务器架构，想部分重要业务的数据多一份异地机房的热备份，而 mysql 复制暂不支持多主的复制模式，且不给用户提供服务，为有效控制成本，会考虑异地机房部署一台性能超好的物理服务器，甚至外加磁盘柜的方式，为此也会部署多实例； 4，传统游戏行业的 MMO/MMORPG ，以及 Web Game，每一个服都对应一个数据库，而可能要做很多数据查询和数据订正的工作，为减少维护而出错的概率，也可能采用多实例部署的方式，按区的概念分配数据库； mysqld_multi用于管理多个 mysqld 的服务进程，这些 mysqld 服务进程程序可以用不同的 socket 或是监听于不同的端口，同时将数据文件分布到不同的磁盘以分散 IO。mysqld_multi 提供简单的命令用于启动，关闭和报告所管理的服务器的状态。从而减少生产环境的维护成本，方便后续的迁移和清理等工作，借助多实例绑定的方式提高服务器的整体资源利用率 1.2、多实例的配置的方式: 在 my.cnf 为所有实例提供配置 使用每一个实例一个配置文件 二、增加一个新实例2.1、增加配置[mysqld_multi]mysqld = /usr/local/mysql/bin/mysqld_safemysqladmin = /usr/local/mysql/bin/mysqladminuser = 管理用户password = 管理密码[mysqld3307]socket = /tmp/mysql.sock3307port = 3307pid-file = /tmp/mysql3307.piddatadir = /data/mysql3307#language = /usr/local/mysql/share/mysql/englishuser = mysql 每一个实例我们需要增加一个 [mysqldN] 的配置。N 是一个数字，从 1 开始，用来标识每个实例， mysqld_multi 通过这个数字编号可以具体的管理到每个实例。 我们需要为每个实例配置不同的 socket、port 和 pid-file，这是启动每个实例必须的基本选项，当然了可以为每个实例单独新增其他可选配置 2.2、新建数据目录mkdir -pv /data/mysql3307/chown -R /data/mysql3307/ 2.3、初始化新实例的数据库/usr/local/mysql/scripts/mysql_install_db --user=mysql --basedir=/usr/local/mysql --datadir=/data/mysql3307/ 更多多实例配置文件写法可以使用 mysqld_multi --example 获取 –help #显示帮助信息，很有用的参数 –example #多实例的配置例子，很有用的参数 –no-log #该参数可以使状态信息发送到终端显示，而不是发送到日志文件 –version #显示版本号 –password= –user= #这两项是指 mysqladmin 的用户和密码，当使用 mysqladmin 来管理时所使用的。 –tcp-ip # 通过 tcp-ip 的端口号连接 mysql 服务器，默认连接 msyql 服务器使用的是 unix socket 文件，这在 stop 和 report 操作时是非常有用的，适合的场景是 socket 文件丢失了，但是 mysql 任然在运行。 2.4、启动和停止多实例# 启动mysqld_multi start# mysqld_multi 可以指定外部文件，讲刚才的配置单独写进 mysqld_multi.cnf 里mysqld_multi --defaults-extra-file=/etc/mysqld_multi.cnf start 3307 mysqld_multi 会查找 my.cnf 里所有 [mysqldN] 的配置，并逐一进行启动。 # 查看实例运行状态# mysqld_multi reportReporting MySQL serversMySQL server from group: mysqld3307 is running 到了这里通过 mysqld_multi 只能 start 多实例库，但是不能 SHUTDOWN，为了增加 SHUTDOWN 权限，需要进行授权 # 增加授权# mysql -uroot -S /tmp/mysql.sock3307 -e "GRANT SHUTDOWN ON *.* TO '管理用户'@'localhost' IDENTIFIED BY '管理密码';"# mysql -uroot -S /tmp/mysql.sock3307 -e "FLUSH PRIVILEGES;" 这里授权的用户和密码就是之前配置文件里指定的账户和密码 2.5、管理# 如果实例没有正常启动到，我们可以在启动时增加日志来查看失败的原因：mysqld_multi --log=/tmp/multi_mysqld.log start# 如果想启动具体某个实例，我们只需要在启动时加上实例的编号即可：mysqld_multi start 3307# 同样的，我们可以指定需要停止的实例，只需要在命令加上实例的编号即可：mysqld_multi stop 3307# 再次查看# mysqld_multi reportReporting MySQL serversMySQL server from group: mysqld3307 is not running 2.6、多实例登录# 进入端口为 3307 的数据库mysql -uroot -p -h127.0.0.1 -P3307# 通过 sock 文件登录mysql -uroot -p -S /tmp/mysql3307.sock# 查看 socket 文件mysql&gt; SHOW VARIABLES LIKE 'socket';+---------------+---------------------+| Variable_name | Value |+---------------+---------------------+| socket | /tmp/mysql.sock3307 |+---------------+---------------------+1 row in set (0.00 sec)# 查看 pid 文件mysql&gt; SHOW VARIABLES LIKE '%pid%';+---------------+--------------------+| Variable_name | Value |+---------------+--------------------+| pid_file | /tmp/mysql3307.pid |+---------------+--------------------+1 row in set (0.00 sec) 更多阅读 Manage Multiple MySQL Servers PERCONA MYSQL PERFORMANCE BLOG MySQL多实例配置(一) MySQL多实例配置(二) 礁湖星云]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mysql单机多实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 重置 root 口令]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E9%87%8D%E7%BD%AEroot%E5%8F%A3%E4%BB%A4.html</url>
    <content type="text"><![CDATA[生与死是如此接近，我们总是会被某种事情吸引。我不否认人会死，但你必须尽力让自己过的精彩，因为当你明白你不能永生时，你就再也不会去过那种庸庸碌碌的日子了！ 虽然开始创建都会用工具创建 root 密码，但是不免会有丢失的情况，所以密码丢失后的找回肯定也是必备的事情 一、重置 Root 口令(通用)1.1 重启服务 普通用户密码丢失可以用 root 用户修改，这里特指 root 密码丢失 a、关闭MySQL进程 shell&gt; killall -TERM mysqld 或shell&gt; kill `cat /mysql-data-directory/host_name.pid` b、重新启动MySQL # 跳过权限表启动# $&#123;MYSQL_INSTALL_DIR&#125;/mysqld_safe --skip-grant-tables --skip-networking &amp; c、修改用户口令即可 1、用SET PASSWORD命令shell&gt; mysql -u rootmysql&gt; FLUSH PRIVILEGES;mysql&gt; SET PASSWORD FOR 'root'@'localhost' = PASSWORD('newpass'); 2、用 mysqladminmysqladmin -u root password "newpass"# 如果 root 已经设置过密码，采用如下方法mysqladmin -u root password oldpass "newpass" 3、用 UPDATE 直接编辑 user 表mysql -u rootmysql&gt; use mysql;mysql&gt; UPDATE user SET Password = PASSWORD('newpass') WHERE user = 'root';mysql&gt; FLUSH PRIVILEGES; 参考阅读 B.5.4.1 How to Reset the Root Password]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>MySQL 密码丢失，MySQL 密码找回</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 日志]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E6%97%A5%E5%BF%97.html</url>
    <content type="text"><![CDATA[这两天稍微看了下 MySQL 的日志情况，稍微整理一下，当然不同版本的 MySQL 服务器变量定义的也不太一样，会有不同的变化，需要查询相关文档 一、查询日志： 一般没有特别情况下，不建议开启 查看是否开启查询日志 # 查看全局日志的相关变量mysql&gt; show global variables like '%log%';# 查看当前会话日志相关的变量mysql&gt; show session variables like '%log%'; 主要有如下几个字段 # 是否启用查询日志| general_log | &#123;OFF | ON&#125;# 日志输出字段| log_output | &#123;FILE | TABLE | NONE&#125;# 当 log_output 有 FILE 字段的时候，日志信息记录的位置| general_log_file | /data/mysql/mysqld.log 二、慢查询日志 查询时间超出指定时间的查询操作记录的日志信息 # 查询指定慢查询时间mysql&gt; select @@global.long_query_time;+--------------------------+| @@global.long_query_time |+--------------------------+| 10.000000 |+--------------------------+1 row in set (0.00 sec)# 是否开启慢查询日志信息和位置| slow_query_log | &#123;OFF | ON&#125;| slow_query_log_file | /data/mysql/mysqld-slow.log| log_slow_queries | &#123;OFF | ON&#125; 三、错误日志 错误日志是一个文本文件，主要记录的内容 mysqld 启动和关闭过程中输出的信息 mysqld 运行中产生的错误信息 event scheduler 主从复制架构中 slave 服务器启动线程时产生的日志信息 默认使用 ${hostname}.err 并在数据目录中写入日志文件 # 日志位置| log_error | /data/mysql/mysqld.log# 是否将警告信息记录到错误日志里| log_warnings | &#123;1 | 0&#125; 1：就是把警告信息记录日志 0：警告信息不记录日志 3.1、修改错误日志 在 mysql 数据库中，错误日志功能是默认开启的。并且错误日志无法被禁止 # 修改错误日志路径[mysqld]log-error=/tmp/filename.err 3.2、管理错误日志 默认日志文件会不断累加，mysql 5.5.7 之后提供了两种方式重新生成写入新日志文件 # mysql 命令行mysql&gt; FLUSH LOGS;# shell 命令行mysqladmin flush-logs 四、二进制日志 数据目录下大多都以 mysql-bin.00000x 文件命名，并且记录了可能能引起数据改变的内容 1、二进制文件构成： mysqlm-bin.000001 //二进制文件mysqlm-bin.000002mysqlm-bin.index //二进制文件索引文件 2、日志记录格式： 基于”语句”记录 基于”行”记录 “混合”记录 3、开启二进制日志 服务器变量 # vim /etc/my.cnflog-bin=/path/mysql-bin //名称可以随意# 全局指定二进制文件开关| log_bin | ON# 二进制文件记录格式| binlog_format | STATEMENT - STATEMENT：语句模式 - MIXED：混合模式 - ROW：行模式# 会话的二进制文件开启开关| sql_log_bin | ON# 临时关闭会话 sql_log_binmysql&gt; SET SESSION sql_log_bin=0;# 单个二进制文件大小，超过这个数值将进行滚动，最大1G，最小4k| max_binlog_size | 1073741824# 日志缓存大小| max_binlog_cache_size | 18446744073709547520# 语句缓存大小| max_binlog_stmt_cache_size | 18446744073709547520# 是否在事务提交时及时从缓存中同步到磁盘，0 表示不同步，任何正值表示记录多少个语句之后同步一次| sync_binlog | 0 二进制日志查看 # 查看 master 端处于 mysqld 维护状态中的二进制日志文件mysql&gt; show binary logs;mysql&gt; show master logs;+-------------------+-----------+| Log_name | File_size |+-------------------+-----------+| mysqlm-bin.000001 | 125 || mysqlm-bin.000002 | 198 |+-------------------+-----------+2 rows in set (0.00 sec)# 显示指定的二进制文件中的相关事件SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]mysql&gt; show binlog events in 'mysqlm-bin.000002'\G;*************************** 1. row *************************** Log_name: mysqlm-bin.000002 Pos: 4 Event_type: Format_desc Server_id: 1End_log_pos: 106 Info: Server ver: 5.1.73-log, Binlog ver: 4*************************** 2. row *************************** Log_name: mysqlm-bin.000002 Pos: 106 Event_type: Query Server_id: 1End_log_pos: 198 Info: create database testdb2 rows in set (0.00 sec)mysql&gt; SHOW BINLOG EVENTS IN 'mysqlm-bin.000002' FROM 393 LIMIT 200;# 更多 show 情况mysql&gt; help show; 查看二进制日志格式 # mysqlbinlog mysql-bin.000001/*!40019 SET @@session.max_insert_delayed_threads=0*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;mysqlbinlog: File 'mysql-bin.000001' not found (Errcode: 2)DELIMITER ;# End of log fileROLLBACK /* added by mysqlbinlog */;/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;- 事件发生日期和时间- 时间发生的服务器标示（server-id）- 事件的结束位置（# End of log file）- 事件类型- 错误代码（error_code=2）- 事件内容- 事件发生时所在的服务器执行此事件的线程 ID 五、中继日志六、事务日志 事务：将随机 I/O 转换成顺序 I/O]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mysql日志</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 主从同步]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E6%80%BB%E7%BB%93.html</url>
    <content type="text"><![CDATA[这么一段时间连续在 5.6、5.5、5.1 三个 MySQL 版本之间切换，表示还是总结点什么好，脑子不太好用了，总记不住东西 MySQL 主从复制 之前写过一个 MySQL 5.6 主从复制，看了下 5.1 和 5.5 的复制，基本上大体步骤也类似 大体的配置步骤都是如下1.主 DB SERVER 上的配置 (1).安装数据库 (2).修改数据库配置文件,指明 server_id ,开启二进制日志 (log-bin) (3).启动数据库,查看当前是哪个日志, position 号是多少 (4).登陆数据库,授权用户 [ip地址为从机IP地址,如果是双向主从,这里的还需要授权本机的IP地址(此时自己的IP地址就是从IP地址)] (5).备份数据库 [记得加锁和解锁] mysql&gt; FLUSH TABLES WITH READ LOCK; (6).传送备份到从 DB server 上 (7).启动数据库 2.从 DB SERVER 上的配置 (1).安装数据库 (2).修改数据库配置文件,指明 server_id [如果是搭建双向主从的话,也要开启二进制日志 (log-bin)] (3).启动数据库,还原备份 (4).查看当前是哪个日志,position 号是多少 [单向主从此步不需要,双向主从需要] (5).指定主 DB server 的地址,用户,密码等信息 (6).开启同步,查看状态 更多阅读 InnoDB Troubleshooting Mysql数据库主从心得整理]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>MySQL 主从报错</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Percona Xtrabackup 备份 MySQL]]></title>
    <url>%2Fnote%2Fdb_Percona-Xtrabackup-%E5%A4%87%E4%BB%BD-MySQL.html</url>
    <content type="text"><![CDATA[之前用了 mysqldump 以及相关之类的工具进行 MySQL 备份，但是适用场景仅仅适合中小量的数据备份场景下，对于更大数据量，还是不太满足的，这时候就得需要备份神器 xtrabackup 简介 Percona XtraBackup 是开源免费的 MySQL 数据库热备份软件，它能对 InnoDB 和 XtraDB 存储引擎的数据库非阻塞地备份（对于 MyISAM 的备份同样需要加表锁）。XtraBackup 支持所有的 Percona Server、MySQL、MariaDB 和 Drizzle。 主页: http://www.percona.com/software/percona-xtrabackup 1、XtraBackup 优势 ： 备份过程快速、可靠 备份过程不会打断正在执行的事务 自动实现备份检验 无需停止数据库进行 InnoDB 热备 增量备份 MySQL 流压缩到传输到其它服务器 能比较容易地创建主从同步 备份 MySQL 时不会增大服务器负载 还原速度快 但是因为同样是 MySQL 客户端工具，不支持离线备份 2、安装：wget http://www.percona.com/downloads/percona-release/redhat/0.1-3/percona-release-0.1-3.noarch.rpmrpm -ivh percona-release-0.1-3.noarch.rpmyum install percona-xtrabackup -y 安装 XtraBackup 后，其实会有几个工具： innobackupex：这个是其实是下面三个工具的一个 perl 脚本封装，可以备份 MyISAM, InnoDB, XtraDB 引擎。但在处理 MyISAM 时需要加一个读锁。 xtrabackup：一个由C编译而来的二进制文件，只能备份 InnoDB 和 XtraDB 数据。 xbcrypt：用来加密或解密备份的数据。 xbstream：用来解压或压缩 xbstream 格式的压缩文件。 建议使用 perl 封装的 innobackupex 来作数据库备份，因为比较容易使用。所以下面只介绍innobackupex的使用。其它的使用参考: http://www.percona.com/doc/percona-xtrabackup/2.2/manual.html 3、备份与恢复3.1 完全备份# innobackupex --user=用户名 --password=密码 /backup/ 使用 innobakupex 备份时，其会调用 xtrabackup 备份所有的 InnoDB 表，复制所有关于表结构定义的相关文件(.frm)、以及 MyISAM、MERGE、CSV 和 ARCHIVE 表的相关文件，同时还会备份触发器和数据库配置信息相关的文件。这些文件会被保存至一个以时间命令的目录中。 在备份的同时，innobackupex 还会在备份目录中创建如下文件： xtrabackup_checkpoints —— 备份类型（如完全或增量）、备份状态（如是否已经为 prepared 状态）和 LSN(日志序列号)范围信息； 每个 InnoDB 页(通常为 16k 大小)都会包含一个日志序列号，即 LSN。LSN 是整个数据库系统的系统版本号，每个页面相关的 LSN 能够表明此页面最近是如何发生改变的。 xtrabackup_binlog_info —— mysql 服务器当前正在使用的二进制日志文件及至备份这一刻为止二进制日志事件的位置。 xtrabackup_binlog_pos_innodb —— 二进制日志文件及用于 InnoDB 或 XtraDB 表的二进制日志文件的当前 position。 xtrabackup_binary —— 备份中用到的 xtrabackup 的可执行文件； backup-my.cnf —— 备份命令用到的配置选项信息； 在使用 innobackupex 进行备份时，还可以使用 --no-timestamp 选项来阻止命令自动创建一个以时间命名的目录；如此一来，innobackupex 命令将会创建一个 BACKUP-DIR 目录来存储备份数据。 3.2 准备 (prepare) 一个完全备份一般情况下，在备份完成后，数据尚且不能用于恢复操作，因为备份的数据中可能会包含尚未提交的事务或已经提交但尚未同步至数据文件中的事务。因此，此时数据文件仍处理不一致状态。“准备”的主要作用正是通过回滚未提交的事务及同步已经提交的事务至数据文件也使得数据文件处于一致性状态。 innobakupex 命令的 --apply-log 选项可用于实现上述功能。如下面的命令： # innobackupex --apply-log /backup/BACKUP-DIRxtrabackup: starting shutdown with innodb_fast_shutdown = 1150319 7:55:52 InnoDB: Starting shutdown...150319 7:55:52 InnoDB: Shutdown completed; log sequence number 11452428150319 07:55:52 innobackupex: completed OK! 在实现“准备”的过程中，innobackupex 通常还可以使用 --use-memory 选项来指定其可以使用的内存的大小，默认通常为 100M。如果有足够的内存可用，可以多划分一些内存给 prepare 的过程，以提高其完成速度。 3.3 从一个完全备份中恢复数据 恢复不用启动 MySQL innobackupex 命令的 --copy-back 选项用于执行恢复操作，其通过复制所有数据相关的文件至 mysql 服务器 DATADIR 目录中来执行恢复过程。innobackupex 通过 backup-my.cnf 来获取 DATADIR 目录的相关信息。 # innobackupex --copy-back /backup/BACKUP-DIRinnobackupex: Starting to copy InnoDB log filesinnobackupex: in '/backup/2015-03-19_07-43-23'innobackupex: back to original InnoDB log directory '/data/mysql'innobackupex: Copying '/backup/2015-03-19_07-43-23/ib_logfile1' to '/data/mysql'innobackupex: Copying '/backup/2015-03-19_07-43-23/ib_logfile0' to '/data/mysql'innobackupex: Finished copying back files.150319 08:00:11 innobackupex: completed OK!# 后续工作# chown -R mysql.mysql /data/mysql 3.4 增量备份 每个 InnoDB 的页面都会包含一个 LSN 信息，每当相关的数据发生改变，相关的页面的 LSN 就会自动增长。这正是 InnoDB 表可以进行增量备份的基础，即 innobackupex 通过备份上次完全备份之后发生改变的页面来实现。 # innobackupex --incremental /backup --incremental-basedir=BASEDIR 其中，BASEDIR 指的是完全备份所在的目录，此命令执行结束后，innobackupex 命令会在 /backup 目录中创建一个新的以时间命名的目录以存放所有的增量备份数据。另外，在执行过增量备份之后再一次进行增量备份时，其 --incremental-basedir 应该指向上一次的增量备份所在的目录。 需要注意的是，增量备份仅能应用于 InnoDB 或 XtraDB 表，对于 MyISAM 表而言，执行增量备份时其实进行的是完全备份。 3.5 导入或导出单张表默认情况下，InnoDB 表不能通过直接复制表文件的方式在 mysql 服务器之间进行移植，即便使用了 innodb_file_per_table 选项。而使用 Xtrabackup 工具可以实现此种功能，不过，此时需要“导出”表的 mysql 服务器启用了 innodb_file_per_table 选项（严格来说，是要“导出”的表在其创建之前，mysql服务器就启用了 innodb_file_per_table 选项），并且“导入”表的服务器同时启用了 innodb_file_per_table 和 innodb_expand_import 选项。 (1)“导出”表导出表是在备份的 prepare 阶段进行的，因此，一旦完全备份完成，就可以在 prepare 过程中通过 --export 选项将某表导出了： # innobackupex --apply-log --export /backup/full_backup_dir 此命令会为每个 innodb 表的表空间创建一个以 .exp 结尾的文件，这些以 .exp 结尾的文件则可以用于导入至其它服务器。 (2)“导入”表要在 mysql 服务器上导入来自于其它服务器的某 innodb 表，需要先在当前服务器上创建一个跟原表表结构一致的表，而后才能实现将表导入： 最好之前查看想要导入的服务器是否支持 innodb 每表一空间选项mysql&gt; show global variables like 'innodb_file%';# 创建表，表结构必须一致，可以在原服务器上使用 &lt;show create table 表名&gt;mysql&gt; CREATE TABLE mytable (...) ENGINE=InnoDB;# 然后将此表的表空间删除：mysql&gt; ALTER TABLE 表名 DISCARD TABLESPACE;# 接下来，将来自于“导出”表的服务器的 mytable 表的 mytable.ibd 和 mytable.exp 文件复制到当前服务器的数据目录，然后使用如下命令将其“导入”：mysql&gt; ALTER TABLE 表名 IMPORT TABLESPACE; 3.6 压缩备份 3.7 部分备份Xtrabackup 也可以实现部分备份，即只备份某个或某些指定的数据库或某数据库中的某个或某些表。但要使用此功能，必须启用 innodb_file_per_table 选项，即每张表保存为一个独立的文件。同时，其也不支持 --stream 选项，即不支持将数据通过管道传输给其它程序进行处理。 此外，还原部分备份跟还原全部数据的备份也有所不同，即你不能通过简单地将 prepared 的部分备份使用 --copy-back 选项直接复制回数据目录，而是要通过导入表的方向来实现还原。当然，有些情况下，部分备份也可以直接通过 --copy-back 进行还原，但这种方式还原而来的数据多数会产生数据不一致的问题，因此，无论如何不推荐使用这种方式。 (1)创建部分备份 创建部分备份的方式有三种：正则表达式 --include, 枚举表文件 --tables-file 和列出要备份的数据库 --databases。 (a)使用 --include使用 --include 时，要求为其指定要备份的表的完整名称，即形如 databasename.tablename，如： # innobackupex --include='^mageedu[.]tb1' /path/to/backup (b)使用 --tables-file此选项的参数需要是一个文件名，此文件中每行包含一个要备份的表的完整名称；如： # echo -e 'mageedu.tb1\nmageedu.tb2' &gt; /tmp/tables.txt# innobackupex --tables-file=/tmp/tables.txt /backup (c)使用 --databases 此选项接受的参数为数据名，如果要指定多个数据库，彼此间需要以空格隔开；同时，在指定某数据库时，也可以只指定其中的某张表。此外，此选项也可以接受一个文件为参数，文件中每一行为一个要备份的对象。如： # innobackupex --databases="mageedu testdb" /backup (2)整理 preparing 部分备份 prepare 部分备份的过程类似于导出表的过程，要使用 --export 选项进行： # innobackupex --apply-log --export /pat/to/partial/backup 此命令执行过程中，innobackupex 会调用 xtrabackup 命令从数据字典中移除缺失的表，因此，会显示出许多关于“表不存在”类的警告信息。同时，也会显示出为备份文件中存在的表创建 .exp 文件的相关信息。 (3)还原部分备份 还原部分备份的过程跟导入表的过程相同。当然，也可以通过直接复制 prepared 状态的备份直接至数据目录中实现还原，不要此时要求数据目录处于一致状态。 3.7 备份恢复遵循的步骤1、停止 MySQL 服务器2、记录服务器配置和文件权限3、讲备份恢复到 MySQL 数据目录：此步骤依赖具体的备份工具4、改变配置和文件权限5、以限制方式启动 MySQL 服务器，比如通过网络访问 [mysqld]skip-networkingsocket=/path/mysql-recovery.sock 6、载入额外的逻辑备份，而检查和重放二进制文件7、检查已还原的数据8、以完全访问模式重启服务器 更多阅读 为 MySQL 选择合适的备份方式 Percona Xtrabackup备份mysql (完整备份与增量备份) MySQL 备份与恢复]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>percona xtrabackup</tag>
        <tag>MySQL 备份</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 备份与恢复]]></title>
    <url>%2Fnote%2Fdb_MySQL-%E5%A4%87%E4%BB%BD%E4%B8%8E%E6%81%A2%E5%A4%8D.html</url>
    <content type="text"><![CDATA[平时用的 MySQL 备份工具也就那一两种，最近恰好有不同的业务场景。使用了之前那的备份工具虽然可以做，但是明显感觉不合适了，所以就有了这篇文章，主体可能就是介绍一些备份方式和工具，至少以后提到不是一无所知 一、MySQL 备份 备份需要包含，数据、二进制日志、innodb 事务日志、代码（存储过程函数、触发器、事务调度器）、服务器配置文件 1、按照被分量大小分为 完全备份：全量备份 部分备份：仅备份一个库，多个库，一张表，多张表 增量备份：仅从上次完全备份或者增量备份之后的变化的数据部分 2、按照业务是否可持续分为 热备份：在线备份，读写操作不受影响 温备份：在线备份，读操作可继续进行，但写操作不允许 冷备份：离线备份，服务离线，备份期间不能为业务提供读写服务 MyISAM 只支持温备， InnoDB 支持热备 3、按照备份恢复方式分 逻辑备份：主要是备份 sql 语句，在恢复的时候执行备份的 sql 语句实现数据库数据的重现，且逻辑备份与存储引擎无关 物理备份：备份数据文件了，比较形象点就是 cp下数据文件，但真正备份的时候自然不是的 cp 这么简单 逻辑备份缺点： schema 和 data 存储在一起 巨大的 sql 语句 单个巨大的文件 性能成本高 所以总体上来讲，物理备份恢复速度比较快，占用空间比较大; 逻辑备份速度比较慢，占用空间比较小 二、备份工具 先从用过的以下几种工具开始说起，日后有其他工具接着补充 mysqldump mydumper mysqlhotcopy xtrabackup 更多… 1、mysqldump mysqldump 由于是 mysql 自带的备份工具，所以也是最常用的 mysql 数据库的备份工具。支持基于InnoDB 的热备份。但由于是逻辑备份，所以速度不是很快，适合备份数据量比较小的场景 官方页：http://dev.mysql.com/doc/refman/5.5/en/mysqldump.html mysqldump 主要特性： schema 和数据存储在一起，巨大的 SQL 语句，单个备份文件巨大 语法格式： Dumping structure and contents of MySQL databases and tables.Usage: mysqldump [OPTIONS] database [tables]OR mysqldump [OPTIONS] --databases [OPTIONS] DB1 [DB2 DB3...]OR mysqldump [OPTIONS] --all-databases [OPTIONS] 实例： 1、完全备份# mysqldump -A -u用户 -p密码 -hIP &gt; /tmp/all.sql-A, --all-databases：备份所有库2、指定备份一个库或多个库# mysqldump -B -u用户 -p密码 -hIP &gt; /tmp/all.sql-B, --databases：指定一个或多个库3、但是针对于 MyISAM 引擎，对于 InnoDB 也同样适用# mysqldump -A -u用户 -p密码 -hIP -x &gt; /tmp/all.sql-x, --lock-all-tables: 锁定所有表-l, --lock-tables：锁定备份表（不推荐，不利于时间点恢复）4、针对 InnoDB 引擎# mysqldump -A -u用户 -p密码 -hIP --single-transaction &gt; /tmp/all.sql--single-transaction：启动一个大的单一事务实现备份5、启用压缩# mysqldump -A -u用户 -p密码 -hIP -C &gt; /tmp/all.sql-C, --compress：启用压缩传输6、其他备份选项-E, --events：备份事件-R, --routines：备份存储过程和存储函数--triggers：备份触发器--master-data[=#]： 0: 表示不记录 1：增加了记录 `change master to` 语句，此语句未被注释 2：增加了记录 `change master to` 语句并注释，如果只是备份，选择 2 即可 案例： # 备份策略：每周完全备份，每日进行增量备份# 注意：二进制文件和数据文件不应该存放在同一磁盘1、完全备份：# mysqldump -A -u用户 -p密码 -hIP --lock-all-tables --master-data=2 &gt; /backup/full_backup_`date +%F`.sql如果本地备份，可以直接这么来mysqldump -A -uroot -p --lock-all-tables &gt; /backup/full_backup_`date +%F`.sql 备份脚本： 改进了网友的脚本，需要创建目录给予备份者权限即可 #!/usr/bin/env bash# description: MySQL buckup shell script# author: mingmings# url: http://mingmings.org/# mail: 369413651@qq.com# date: 2015-03-09# version: 1.0#----------------------------------------------------------USER=""PASSWORD=""# 多个库用空格隔开DATABASE="database1 database2..."#MAIL="test@test.com"BACKUP_DIR="/backup/"LOGFILE="data_backup.log"DATE=`date +%F`DUMPFILE=$&#123;DATE&#125;.sqlARCHIVE=$&#123;DATE&#125;.sql.gzOPTIONS="-u$&#123;USER&#125; -p$&#123;PASSWORD&#125; --lock-all-tables --database $&#123;DATABASE&#125;"#----------------------------------------------------------if [ ! -d $&#123;BACKUP_DIR&#125; ];then mkdir -p "$&#123;BACKUP_DIR&#125;" echo -e "$&#123;BACKUP_DIR&#125; create successful..."fi# write message head into logfileecho " "&gt;&gt; $&#123;BACKUP_DIR&#125;/$&#123;LOGFILE&#125;echo "--------------------" &gt;&gt; $&#123;BACKUP_DIR&#125;/$&#123;LOGFILE&#125;echo "BACKUP DATE:" $(date +"%F %H:%M:%S") &gt;&gt; $&#123;BACKUP_DIR&#125;/$&#123;LOGFILE&#125;echo "-------------------" &gt;&gt; $&#123;BACKUP_DIR&#125;/$&#123;LOGFILE&#125;# change directory and dump datacd $&#123;BACKUP_DIR&#125;mysqldump $&#123;OPTIONS&#125; | gzip -9 &gt; $&#123;BACKUP_DIR&#125;/$&#123;DUMPFILE&#125;.gz# 判断数据库备份是否成功if [ $? -eq 0 ];then echo "[$ARCHIVE] Backup Successful!!!" &gt;&gt; $&#123;LOGFILE&#125;else echo "---------- Database Backup Fail! ----------" &gt;&gt; $&#123;LOGFILE&#125;# mail alter when backup faild# mail -s "database:$DATABASE Daily Backup Fail!" $MAILfiecho "---------- Backup Process Done ----------"# Cleaning three days before...find $&#123;BACKUP_DIR&#125; -type f -mtime +2 -name "*.gz" -exec rm -f &#123;&#125; \; 2、mydumper Mydumper 是一个针对 MySQL 和 Drizzle 的高性能多线程备份和恢复工具。开发人员主要来自MySQL,Facebook,SkySQL 公司，同样也是逻辑备份工具 Mydumper主要特性： 轻量级C语言写的 执行速度比mysqldump快10倍 事务性和非事务性表一致的快照(适用于0.2.2以上版本) 快速的文件压缩 支持导出binlog 多线程恢复(适用于0.2.1以上版本) 以守护进程的工作方式，定时快照和连续二进制日志(适用于0.5.0以上版本) 开源 (GNU GPLv3) 主页：https://launchpad.net/mydumper 3、mysqlhotcopy4、mylvmbackup更多阅读 为 MySQL 选择合适的备份方式 MySQL Data Dumper MySQL 备份与恢复 MySQL 常见三种备份方法]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下的终端色彩显示]]></title>
    <url>%2Fnote%2FMac%E4%B8%8B%E7%9A%84%E7%BB%88%E7%AB%AF%E8%89%B2%E5%BD%A9%E6%98%BE%E7%A4%BA.html</url>
    <content type="text"><![CDATA[刚拿到手的 Mac 终端都是默认的黑白，用惯了其他色彩展示之后没有颜色真心很不方便，所以这也是基本上到手之后初始化的几个事情，过个年都没动静了，老家木有 WiFi ，所以今天看到之前的笔记，先来分享一篇 step1我们要在用户目录下(~)创建一个名为 .bash_profile export CLICOLOR=1export LSCOLORS=gxfxaxdxcxegedabagacad step2LSCOLORS 是用来设置当 CLICOLOR 被启用后，各种文件类型的颜色。LSCOLORS 的值中每两个字母为一组，分别设置某个文件类型的文字颜色和背景颜色。LSCOLORS 中一共11组颜色设置，按照先后顺序，分别对以下的文件类型进行设置： directory symbolic link socket pipe executable block special character special executable with setuid bit set executable with setgid bit set directory writable to others, with sticky bit directory writable to others, without sticky bit step3LSCOLORS 中，字母代表的颜色如下 a 黑色 b 红色 c 绿色 d 棕色 e 蓝色 f 洋红色 g 青色 h 浅灰色 A 黑色粗体 B 红色粗体 C 绿色粗体 D 棕色粗体 E 蓝色粗体 F 洋红色粗体 G 青色粗体 H 浅灰色粗体 x 系统默认颜色 所以，如果我们想把目录显示成红色，就可以把 LSCOLORS 设置为 bxfxaxdxcxegedabagacad 就可以了 目前自己用的 zsh ，所以这边直接讲配色设置直接写在 .zshrc 中 #shell envexport CLICOLOR=1#export LSCOLORS=cxfxaxdxcxegedabagacadexport LSCOLORS=gxfxcxdxbxegedabagacad]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>Mac下的终端色彩显示</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[argparse 实战]]></title>
    <url>%2Fnote%2Fargparse-%E5%AE%9E%E6%88%98.html</url>
    <content type="text"><![CDATA[上一篇关于 argparse 是转载别人翻译的官网的文章，最近开始脚本中需要涉及到参数处理，所以试过 sys.argv，也试过 getopt，最后再来看看 argparse，还是决定花点时间弄明白 argparse，所以一边写脚本一遍学习 argparse 了 关于 python 命令行参数解析的几个工具介绍 这篇孔令贤 的文章中有介绍，我就不多赘述，直接转过来 sys.argv 最简单最直观的手动解析 import sysdef TestSys(): for arg in sys.argv[1:]: print (arg) getopt getopt 模块是原来的命令行选项解析器，支持 UNIX 函数 getopt() 建立的约定。它会解析一个参数序列，如 sys.argv，并返回一个元祖序列和一个非选项参数序列。目前支持的选项语法包括短格式和长格式选项：-a, -bval, -b val, --noarg, --witharg=val, --witharg val。如果只是简单的命令行解析，getopt 还是不错的选择。一个例子如下： try: options, remainder = getopt.getopt(sys.argv[1:], 'o:v', ['output=', 'verbose', 'version=',])except getopt.GetoptError as err: print 'ERROR:', err sys.exit(1) argparse argparse是 python 标准库中的模块，以前的 optparse 已经废弃。利用 argparse，可以完成对命令行的参数定义、解析以及后续的处理。之前的一篇 argparse 中已经有介绍 这边直接利用脚本进行演示 创建对象 argparse.ArgumentParser(prog=None, usage=None, description=None, epilog=None, parents=, []formatter_class=argparse.HelpFormatter, prefix_chars='-', fromfile_prefix_chars=None, argument_default=None, conflict_handler='error', add_help=True) prog: 默认是sys.argv[ 0 ]，即程序名 usage: 默认是根据参数自动生成 description: 对程序的描述信息，在help选项信息之前打印 epilog: 对程序的补充信息，在help选项信息之后打印 parents=list(): 继承一个父argparse对象的属性，作为一个列表元素提供 conflict_handler: 解决选项冲突问题 add_help: 增加-h/–help选项，默认开启 选项 add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) name: 就是选项名称 action: store: 保存选项值 store_const: 保存的值由const决定 store_true，store_false：包含选择，则返回True或者False append：将值追加到一个列表，方便重复使用选项的情况 append_const count：记录选择的次数 version：取决于version关键字 docopt docopt 就比较强大了，它是根据你自己写的 help messages（文档描述），自动为你生成 parser。使用之前需要下载相应的库，这里有个界面可以试用一下 docopt 的强大，借用官方的一个例子 """Usage: arguments_example.py [-vqrh] [FILE] ... arguments_example.py (--left | --right) CORRECTION FILEProcess FILE and optionally apply correction to either left-hand side orright-hand side.Arguments: FILE optional input file CORRECTION correction angle, needs FILE, --left or --right to be presentOptions: -h --help -v verbose mode -q quiet mode -r make report --left use left-hand side --right use right-hand side"""from docopt import docoptif __name__ == '__main__': arguments = docopt(__doc__) print(arguments) 文档描述有两个部分：Usage 和 Option. Usage: 以一个空行结束，冒号后面的第一个单词作为程序的名称。名称后面就是参数的描述，可以包括：- 必选参数。是全大写的单词或尖括号括起来的的单词- 可选参数。需要注意的是，-oiv可以表示-o -i -v。可选参数的形式可以是--input=FILE or -i FILE or even -iFILE.- 子命令。[]表示可选参数，如my_program.py [-hvqo FILE]；( )表示必选参数，以及没有包含在[]中都作为必选参数。 |表示互斥参数... 表示接收多个参数值，如my_program.py FILE ...Options：可选参数的描述。每一行以 `- or --` 开头；同一行相同可选参数以空格隔开；两个或以上的空格分隔描述；可以定义默认值（[default: value]）；需要注意的是，docopt 不能完成 argparse 具有的参数值校验的功能。目前 docopt 已经被移植到了 Ruby, PHP 等语言更多的例子可以参考[这里](https://github.com/docopt/docopt/tree/master/examples) clize clize 也比较强大，利用装饰器将函数转换成命令行解析器。github地址：https://github.com/epsy/clize，一个例子： #!/usr/bin/env pythonfrom clize import runfrom sigtools.modifiers import autokwoargs@autokwoargsdef echo(word, prefix='', suffix=''): """Echoes text back word: One word or quoted string to echo back prefix: Prepend this to each line in word suffix: Append this to each line in word """ if prefix or suffix: return '\n'.join(prefix + line + suffix for line in word.split('\n')) return wordif __name__ == '__main__': run(echo) 生成的帮助文档如下: $ ./echo.py --helpUsage: ./echo.py [OPTIONS] wordEchoes text backPositional arguments: word One word or quoted string to echo backOptions: --prefix=STR Prepend this to each line in word(default: ) --suffix=STR Append this to each line in word(default: )Other actions: -h, --help Show the help 但个人感觉 clize 与 argparse 和 docopt 比起来，支持的功能相对还比较少，而且不容易上手（因为要熟悉相关的各种装饰器及其参数的使用），要支持高级解析功能，代码写起来比较费劲 argparse 实例脚本更多阅读 python library Argparse Tutorial stackoverflow]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>argparse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible plugin 之 callbacks 实现写文件，邮件，入库]]></title>
    <url>%2Fnote%2FAnsible-plugin-%E4%B9%8Bcallbacks-%E5%AE%9E%E7%8E%B0%E5%86%99%E6%96%87%E4%BB%B6%EF%BC%8C%E9%82%AE%E4%BB%B6%EF%BC%8C%E5%85%A5%E5%BA%93.html</url>
    <content type="text"><![CDATA[不管你有多么真诚，遇到怀疑你的人，你就是谎言；不管你有多么单纯，遇到复杂的人，你就是有心计；不管你有多么的天真，遇到现实的人，你就是笑话；不管你多么专业，遇到不懂的人，你就是空白。所以，不要太在乎别人对你的评价，你需要的只是，做最好的自己，独一无二的自己。 都知道 ansible 虽然执行完了可以写日志，但是是否可以做做其他事情，比如入库，发个邮件通告任务完成情况等，结果是有的，利用 plugin 的 callbacs 来完成，详情我也是看了灿哥和峰云两个大神的博客，顺带看看官方文档。允许 ansible 响应事件的时候调用额外的 callback 插件，完成一些额外的动作 1.1 写文件 所以这里模仿官方文档的形式，参照灿哥和风云的代码进行写文件，发送邮件，入库进行演示，首先是官方给出的 log.py def log(host, category, data): if type(data) == dict: # 这段把一些无用的信息替换 if 'verbose_override' in data: # avoid logging extraneous data from facts data = 'omitted' else: # 真正写入文件的内容 data = data.copy() invocation = data.pop('invocation', None) data = json.dumps(data) if invocation is not None: data = json.dumps(invocation) + " =&gt; %s " % data path = os.path.join("/var/log/ansible/hosts", host) now = time.strftime(TIME_FORMAT, time.localtime()) fd = open(path, "a") fd.write(MSG_FORMAT % dict(now=now, category=category, data=data)) fd.close()class CallbackModule(object): """ 下面针对每种不同的 callback 状态进行不同的操作 """ def on_any(self, *args, **kwargs): pass def runner_on_failed(self, host, res, ignore_errors=False): log(host, 'FAILED', res) def runner_on_ok(self, host, res): log(host, 'OK', res) def runner_on_skipped(self, host, item=None): log(host, 'SKIPPED', '...') def runner_on_unreachable(self, host, res): log(host, 'UNREACHABLE', res) 然后讲这个脚本扔到定义好的 callback plugin 目录里，给上可执行权限，具体设置参照 ansible.cfg callback_plugins = /path/ansible/callbacks 而后执行 playbook，之后查看之前定义好的写入文件的位置 /var/log/ansible/hosts/ ,就可以看到之前定义好的文件了 Feb 03 2015 18:34:27 - OK - omittedFeb 03 2015 18:34:30 - UNREACHABLE - &#123;"msg": "AnsibleError: unable to read /tmp/test.j2", "failed": true&#125; 1.2 发邮件 了解上面之后，整体发送邮件和写文件都大同小异，主要讲上面的动作换乘发送邮件就可以了，这里直接参照灿哥代码来 import smtplibimport osimport socketimport commandsfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextmsg = MIMEMultipart()def crab(subject, body): """ 补充相关发件人，收件人，登录账号密码，以及smtp信息等 """ sender = '' sender = sender mailto = '' mailto = mailto username = '' password = '' line = body TXT = MIMEText(line) msg.attach(TXT) msg['Subject'] = subject msg['to'] = mailto msg['From'] = sender smtp = smtplib.SMTP('smtp.qq.com') smtp.login(username, password) smtp.sendmail(sender, mailto, msg.as_string())class CallbackModule(object): """ 这里和上述一样，依旧是根据 callback 返回状态调用发邮件函数来 """ def runner_on_failed(self, host, res, ignore_errors=False): if ignore_errors: return sender = '"Ansible: %s" &lt;root&gt;' % host subject = 'Failed: %(module_name)s %(module_args)s' % res['invocation'] body = 'The following task failed for host ' + host + ':\n\n%(module_name)s %(module_args)s\n\n' \ % res['invocation'] if 'stdout' in res.keys() and res['stdout']: subject = res['stdout'].strip('\r\n').split('\n')[-1] body += 'with the following output in standard output:\n\n' + res['stdout'] + '\n\n' if 'stderr' in res.keys() and res['stderr']: subject = res['stderr'].strip('\r\n').split('\n')[-1] body += 'with the following output in standard error:\n\n' + res['stderr'] + '\n\n' if 'msg' in res.keys() and res['msg']: subject = res['msg'].strip('\r\n').split('\n')[0] body += 'with the following message:\n\n' + res['msg'] + '\n\n' body += 'A complete dump of the error:\n\n' + str(res) crab(subject=subject, body=body) def runner_on_unreachable(self, host, res): sender = '"Ansible: %s" &lt;root&gt;' % host if isinstance(res, basestring): subject = 'Unreachable: %s' % res.strip('\r\n').split('\n')[-1] body = 'An error occured for host ' + host + ' with the following message:\n\n' + res else: subject = 'Unreachable: %s' % res['msg'].strip('\r\n').split('\n')[0] body = 'An error occured for host ' + host + ' with the following message:\n\n' + \ res['msg'] + '\n\nA complete dump of the error:\n\n' + str(res) crab(subject=subject, body=body) def runner_on_error(self, host, res, jid): sender = '"Ansible: %s" &lt;root&gt;' % host if isinstance(res, basestring): subject = 'Async failure: %s' % res.strip('\r\n').split('\n')[-1] body = 'An error occured for host ' + host + ' with the following message:\n\n' + res else: subject = 'Async failure: %s' % res['msg'].strip('\r\n').split('\n')[0] body = 'An error occured for host ' + host + ' with the following message:\n\n' + \ res['msg'] + '\n\nA complete dump of the error:\n\n' + str(res) crab(subject=subject, body=body) 1.3 入库 原理相同，就不赘述，只是方法换成了写数据库 import osimport timeimport jsonimport datetimefrom pymongo import MongoClientdef InsertDB(values): global mongoinfo dbhost = mongoinfo['host'] dbport = mongoinfo['port'] dbuser = mongoinfo['user'] dbpwd = mongoinfo['password'] dbname = mongoinfo['dbname'] uri = 'mongodb://%s:%s@%s/%s'%(dbuser, dbpwd, dbhost, dbname) client = MongoClient(uri, safe=False) db = client.ansible_log db.callback.insert(values) class CallbackModule(object): def runner_on_failed(self, host, res, ignore_errors=False): now = datetime.datetime.now() result = res result['time'] = now.strftime(TIME_FORMAT) result['status'] = 'fail' InsertDB(result) 上面是写 mongodb，下面来写 sqlite，这里是个老外写的代码 Jan-Piet Mens import osimport timeimport sqlite3dbname = '/etc/ansible/setup.db'TIME_FORMAT='%Y-%m-%d %H:%M:%S'try: con = sqlite3.connect(dbname) cur = con.cursor()except: passdef log(host, data): if type(data) == dict: invocation = data.pop('invocation', None) if invocation.get('module_name', None) != 'setup': return facts = data.get('ansible_facts', None) now = time.strftime(TIME_FORMAT, time.localtime()) try: # `host` is a unique index cur.execute("REPLACE INTO inventory (now, host, arch, dist, distvers, sys,kernel) VALUES(?,?,?,?,?,?,?);", ( now, facts.get('ansible_hostname', None), facts.get('ansible_architecture', None), facts.get('ansible_distribution', None), facts.get('ansible_distribution_version', None), facts.get('ansible_system', None), facts.get('ansible_kernel', None) )) con.commit() except: passclass CallbackModule(object): def runner_on_ok(self, host, res): log(host, res) 写入 redis，这里是峰云的代码 class CallbackModule(object): def runner_on_ok(self, host, res): r = redis.Redis(host='127.0.0.1', port=6379, db=0) r.set(host,str(res)) f = open('/tmp/11','a') f.write(str(host)) f.write(str(res)) f.close() log(host, res) def runner_on_failed(self, host, res, ignore_errors=False): f = open('/tmp/11','a') f.write('\nbad\n') f.close() log(host, res) 不过因为本身 res 返回的就是一个字典的格式，所以数据的特殊结构，还是直接上 mongodb 比较合适，这里本地测试，sqlite 也是妥妥的，回头后面写个页面进行调用下库里的内容展示展示就更直观了 更多阅读 灿哥博客 峰云博客 钿钿的博客 callbacks 源码]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible callbacks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 执行原理(转)]]></title>
    <url>%2Fnote%2FAnsible-%E6%89%A7%E8%A1%8C%E5%8E%9F%E7%90%86-%E8%BD%AC.html</url>
    <content type="text"><![CDATA[转载自阳哥的文章 一、runner不得不说的这个 runner 接口，这是 ansible 下层用来执行远程命令的一个接口，无论是上一篇说的 Ad-Hoc 命令的执行: ansible -i ~/hosts all -m command -a &#39;who&#39;,还是最后一个执行playbook的命令: ansible-playbook playbook.yml ，下面掉得都是这个接口。 在 ansible 官网文档的 Python API 处也是介绍的这个接口：Python API 。比如要执行上面那个Ad-Hoc的命令，直接调用这个接口的话得这么写: import ansible.runnerrunner = ansible.runner.Runner( module_name='command', module_args='who', pattern='local', forks=10)datastructure = runner.run()print datastructure 打印出来的结果是这样的: &#123; 'dark': &#123; &#125;, 'contacted': &#123; '127.0.0.1': &#123; u'changed': True, u'end': u'2014-02-25 22:11:16.566084', u'stdout': u'Guest console Feb 1 16:29 \nthe5fire console Jan 20 19:50 \nthe5fire ttys023 Feb 25 22:11 \t(localhost)\nthe5fire ttys024 Feb 24 22:20 \t(localhost)', u'cmd': [ u'who' ], u'rc': 0, u'start': u'2014-02-25 22:11:16.556888', u'stderr': u'', u'delta': u'0:00:00.009196', 'invocation': &#123; 'module_name': 'command', 'module_args': 'who' &#125; &#125; &#125;&#125; 从这个地方我们可以了解到为什么对于受控制服务器需要安装 simplejson，因为控制服务器和受控服务器都需要通过json 格式进行数据传递的。 二、整体的流程图 图上是一个大概的流程，只是针对 playbook 来说( Ad-Hoc 的执行是直接掉得 runner)。 首先 ansbile-playbook 接受到参数： playbook.yml，然后读取这个 yml 文件，根据这个 yml 文件生成 Playbook 对象，代码: class Playbook 。 在这个 Playbook 中加载 yml 文件，在执行时生成 Play 对象，在 Play 对象中又包含了 Task 对象，一个 Task 对象可以算是一个最小的执行单元。 到了 Task 这一步之后就应该调用 runner 接口了，这个接口的调用还是在 Playbook 这个类中: Playbook._run_task_internal 。而这个 runner 接口，上面已经介绍了，到此也就大体了解上层的执行过程了。 三、再继续探索 runner 下层上面已经探索了 ansible-playbook 在执行时的流程，这里再继续深入了解一下，想看看 ansible 到底是如何执行的。 在 runner 这个类中，具体执行某一个 task 时是通过一个 Action Module 来完成的，这个 action module 是根据参数确定的，比如咱配置的是异步操作还是同步操作，这个不深究，默认是加载 normal 中的 Action Module，位置： normal 。在这个Action中对要执行的命令做了处理，对 shell 和 command 进行了处理，然后调用 runner 中的 self.runner._execute_module 来执行对应模块的操作，也就是 playbook 上写的 git 或者 shell 这样的模块。 到这整个过程其实还是挺无趣的，不过这个 _execute_module 里面的过程还是有点意思的。这个过程做了什么事呢？首先，根据对应模块加载了 library 下面的对应的模块代码比如 shell 加载的是: library/commands/command 这个代码，（这里要注意，上面加载的是 norma l的 action 模块，在那个模块里对 shell 进行了处理，变为 command，因此这里就是 command 了）。找到这个具体的模块文件之后，ansible 会加载一个 module_common.py，对其进行渲染（把咱们定义的命令，比如：virtualenv ~demo，渲染到这个文件中）。 渲染完毕之后，会把这个文件 copy 到远程服务器的用户家目录下的 .ansible/tmp/ansible-xxxxxx 这样的文件夹下（那个 ansible-xxxx 中 xxx 表示不知道是以什么方式生成的字符序列，可能是时间戳)。如果咱们定义的是一个shell，这里会多一个 command 的 py 文件，并且是可执行的。如果是 git，这个文件名就是 git。 传输完毕之后，就是执行了。ansible 默认是以兼容的 ssh 来进行远程命令执行的，执行的方法就是，通过subprocess，来执行 ssh 和已经传输到远程服务器的可执行的 python 文件，通过 PIPE 的方式把执行结果输出回来，输出的 CLI 上。 大概就是这么个过程，只是大致的看了下整个的执行过程，很多地方复杂的逻辑都忽略了，最后的通过 subprocess 的方式执行 ssh 远程操作，并把结果通过 PIPE 输出回来不是特别理解其原理。]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible 执行原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac 下一些小技巧]]></title>
    <url>%2Fnote%2FMac-%E4%B8%8B%E4%B8%80%E4%BA%9B%E5%B0%8F%E6%8A%80%E5%B7%A7.html</url>
    <content type="text"><![CDATA[这个篇幅是用来介绍一下 Mac 下一些 APP 的小技巧 0、快捷键以下是出现在 Mac OS X 菜单中的修饰键符号：Command 键图标（Command 键） – 在某些 Apple 键盘上，此键也可能带有 Apple 标志（apple 标志）Control 键图标（Control 键）Option 或 Alt 键图标（Option 键）-“Alt”可能也出现在此键上Shift 键图标（Shift 键）Caps lock 键图标（Caps Lock 键）- 切换 Caps Lock 开或关fn（功能键） 按键或组合键 功能 Option 显示所有可引导宗卷（启动管理程序） Shift 执行安全启动（以安全模式启动） C 从可引导磁盘启动（DVD、CD） T 以 FireWire 目标磁盘模式启动 N 从 NetBoot 服务器启动 X 强制 Mac OS X 启动（如果存在非 Mac OS X 启动宗卷） Command-V 以详细模式启动 Command-S 以单用户模式启动 1、Mac下截图基本用法 全屏截图：Command-Shift-3使用快捷键后会马上截取当前的全屏 指定区域截图：Command-Shift-4使用快捷键后会出来一个带有座标的瞄准器，用鼠标的拖放可以选择需要截图的区域。此方式有秘笈，后面详细说。 指定程序窗口截图：Commnad-Shift-4-Space使用快捷键后会出现一个照相机的图标，这时候你可以选择屏幕上能看到的任何程序窗口，把鼠标移到它上面后窗口会整个被高亮，只要单击一下就会把这个窗口截 图。 高级用法 “指定区域截图”有更高级一点的用法，使用快捷键 Command-Shift-4 并用鼠标选取需要截图的区域后，不要松开鼠标，然后你有几种选择： 按住鼠标的同时，按 空格 键，这时你能通过移动鼠标来移动整个已选择区域。 按住鼠标的同时，按 Shift 键，这时你能通过横向或竖向移动鼠标来改变已选择区域的长或高。 按住鼠标的同时，按 Option 键，这时你通过移动鼠标可以改变已选择区域的半径大小。 当你使用快捷键后发现想停止截图，在按住鼠标的同时只要按 Esc 就会中止截图的过程，不会保存任何文件。 如果不改变设置, 所有截图会默认保存到桌面，也就是 Desktop 文件夹。 2、安装 sshpass 默认的安装 sshpass 会失败 # 强制使用 homebrewbrew install https://raw.github.com/eugeneoden/homebrew/eca9de1/Library/Formula/sshpass.rb]]></content>
      <categories>
        <category>mac</category>
      </categories>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 多item 不同写法的时间差异]]></title>
    <url>%2Fnote%2FAnsible-%E5%A4%9Aitem-%E4%B8%8D%E5%90%8C%E5%86%99%E6%B3%95%E7%9A%84%E6%97%B6%E9%97%B4%E5%B7%AE%E5%BC%82.html</url>
    <content type="text"><![CDATA[之前群里和灿哥，京奥，爽爷等讨论了下 ansible 多 item 的写法的时候关于时间快慢的问题后期做了这个测试，测试如下 测试环境 通过 ansible 对本地的一台虚机进行安装 RPM 包的测试，快照了基本状态，每次测试完回到最初的状态 yml写法 ansible 版本 yum源 task 安装包 shell模块 1.7.1 公网epel 相同的tag控制 @Desktop、@Development tools with_items 1.7.1 公网epel 相同的tag控制 @Desktop、@Development tools with_flattened 1.7.1 公网epel 相同的tag控制 @Desktop、@Development tools 上面还有个问题就是采用公网的 yum 源，这里是造成测试可能产生最大的不准确的地方，如果是内网的 yum 源则会减少很多误差，所以这里测试仅作参考 playbook 下面是我要测试的 playbook 中即将运行的部分 - name: dependency package yum: name="&#123;&#123; item &#125;&#125;" state=present with_flattened: - ['@Desktop','@Development tools'] ignore_errors: yes tags: - cc执行结果ansible-playbook -i hosts site.yml --tags "cc" -k 0.28s user 0.15s system 0% cpu 2:42.45 total - name: dependency package yum: name="&#123;&#123; item &#125;&#125;" state=present with_items: - "@Development tools" - "@Desktop" ignore_errors: yes tags: - cc执行结果ansible-playbook -i hosts site.yml --tags "cc" -k 0.26s user 0.13s system 0% cpu 2:22.08 total - name: dependency package shell: yum groupinstall -y Desktop Development tools ignore_errors: yes tags: - cc执行结果ansible-playbook -i hosts site.yml --tags "cc" -k 0.25s user 0.13s system 0% cpu 3:01.10 total 以上的结果连续测试了两边以上，得到的结果大致如下，但是仍旧不表示个中快慢，稍后会针对将环境影响较大的部分尽量修改以获得更加贴近的数据]]></content>
      <categories>
        <category>ansible</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github push 代理设置]]></title>
    <url>%2Fnote%2Fgit_Github-push%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE.html</url>
    <content type="text"><![CDATA[说实话出这步都是被逼的，尼玛 github 又被强了，真心不知道说啥了，push 代码都不行，所以只能寻找代理的方式 一、配置1.1 需求首先需求就是能自由 push / pull github 仓库里的代码，所以直接设置代理可以正常拉去代码即可，参考文章 这里 1.2 准备 首先准备好 socket5 的代理，有很多种实现 socket5 的方式，因为我本地是 Mac 平台，就直接用了默认的终端 ssh 来实现 socket5 的代理 ssh -D 1080 -N -f root@X.X.X.X 这里的要求就是你这台远端的机器是墙外的机器，最终通过他来访问 github ，这台机器只要开启了 ssh server，有账户密码即可 可以利用 netstat -an | grep 1080 查看本地是否启动了这个端口，如果成功启用，那么本地的 socket5 代理就设置好了，那么下面开始使用 1.3 使用 因为 git 本身就可以使用的协议就有： http、ssh、git，所以使用代理的方式各有不同，下面分别列举 1.3.1 HTTP 协议# 使用 http.confgit config http.config socks5://127.0.0.1:1080# 也可以使用环境变量export HTTPS_PROXY=socks5://127.0.0.1:1080# git 的配置可以是全局的，也可以根据不同的仓库进行配置，环境变量只能全局使用，否则就需要在每次使用 git 的时候用 env env HTTPS_PROXY=socks5://127.0.0.1:1080 git pull 如果需要根据不同的 remote 使用不同的代理，可以使用 remote.&lt;name&gt;.proxy 1.3.2 SSH 协议 修改 ssh 的 client 配置文件 .ssh/config Host github.com Port 22 ProxyCommand nc -X 5 -x 127.0.0.1:1080 %h %p ServerAliveInterval 10 这样连接 github 的 ssh 都会使用 socket 代理，ssh 的配置可以参考 man ssh_config ，nc 命令的使用可以参考 man nc 。 SSH 协议的代理可以是全局的（去掉 Host 那行就行了），也可以针对某个网站，但不能针对某个仓库配置 1.3.3 GIT 协议1.给 GIT 协议配置代理需要写一个脚本，比如脚本的名字叫： git_proxy #!/bin/shnc -X 5 -x 127.0.0.1:1080 "$@" 2.然后使用 core.gitproxy 进行配置： git config core.gitproxy /path/to/git_proxy 3.它可以配成全局的，也可以配成各个仓库自己的，还可以使用： git config core.gitproxy '/path/to/git_proxy for github.com' 到了这里就可以正常 push / pull 了，下面单独就 Mac 环境下另一工具说明 二、MacOS 终端代理 除了上面的 ssh -D 实现 socket5 代理以外，可以使用 tsocks 为任意程序使用 socks 代理，参考文章 codelife 三、tsocks 代理1.安装 tsocks, 该项目主页 $ brew tap adamv/alt$ brew install tsocks 2.配置 tsocks打开配置文件/usr/local/etc/tsocks.conf local = 192.168.0.0/255.255.255.0server = 127.0.0.1server_type = 5server_port = 8080 3.开始使用 和上面一样，http 代理和 https 代理配置方法也相同 # http 和 https 代理$ export http_proxy='http://YOUR_USERNAME:YOUR_PASSWORD@PROXY_IP:PROXY_PORT/'$ export https_proxy='http://YOUR_USERNAME:YOUR_PASSWORD@PROXY_IP:PROXY_PORT/'# 取消代理$ unset http_proxy$ unset https_proxy 这边用一个实例进行，配置方式也基本如同上面，让 Mac 下的终端里的 http 走 tsock 提供的 socket5 代理 $ export http_proxy='http://localhost:1080'$ export https_proxy='http://localhost:1080'$ tsocks /Applications/Textual.app/Contents/MacOS/Textual 更多阅读 如何设置 Git 代理 利用 SSH 代理爬墙 SSH via HTTP proxy in OSX]]></content>
      <categories>
        <category>github</category>
      </categories>
      <tags>
        <tag>git push代理设置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix监控nginx站点]]></title>
    <url>%2Fnote%2Fzabbix%E7%9B%91%E6%8E%A7nginx%E7%AB%99%E7%82%B9.html</url>
    <content type="text"><![CDATA[目前来说，zabbix 监控监控 nginx 肯定是有的，松爷的书里也说明的，另外呢，这个哥们 的这篇统一监控 nginx 写的监控多个URL也挺好的，所以总结这些就有了这篇文章，我只是搬运工 监控 nginx 这部分主要分为两种情况，第一种就是监控 nginx server 的状态；另一种就是监控网站的 URL 存活，所以就分为这两块 一、监控 nginx server nginx 被监控端配置 nginx 所在的被监控端必须启用了 stub_status 模块 在 server section 中增加如下字段，具体每个字段含义，qing请参考http://nginx.org/en/docs/http/ngx_http_stub_status_module.html location /nginxstatus &#123; stub_status on; access_log off; allow 127.0.0.1; allow 10.80.140.12; allow 10.80.100.52; deny all; 重载配置后，请求 http://x.x.x.x/nginxstatus 应该能看到如下结果 Active connections: 1server accepts handled requests 192033 192033 194627Reading: 0 Writing: 1 Waiting: 0 2.配置脚本和 UserParameter 这部分还是和上面一样在 nginx 被监控端配置，下面直接用了松爷书里的脚本 #!/bin/bash# function:monitor nginx from zabbix# License: GPL# mail:admin@itnihao.com# version 1.0 date:2012-12-09# version 1.0 date:2013-01-15# version 1.1 date:2014-09-05#nginx.conf####################################################################### server &#123;# listen 127.0.0.1:80;# server_name 127.0.0.1;# location /nginxstatus &#123;# stub_status on;# access_log off;# allow 127.0.0.1;# allow 192.168.11.0/24;# deny all;# &#125;# location ~ ^/(phpfpmstatus)$ &#123;# include fastcgi_params;# fastcgi_pass unix:/tmp/fpm.sock;# fastcgi_param SCRIPT_FILENAME $fastcgi_script_name;# &#125;# &#125;######################################################################source /etc/bashrc &gt;/dev/null 2&gt;&amp;1source /etc/profile &gt;/dev/null 2&gt;&amp;1nginxstatus=http://127.0.0.1/nginxstatus #注意这里修改的status 访问路径# Functions to return nginx statsfunction checkavailable &#123; code=$(curl -o /dev/null -s -w %&#123;http_code&#125; $&#123;nginxstatus&#125;) if [ "$&#123;code&#125;" == "200" ] then return 1 else echo 0 fi&#125;function active &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Active' | awk '&#123;print $3&#125;'&#125;function reading &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Reading' | awk '&#123;print $2&#125;'&#125;function writing &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Writing' | awk '&#123;print $4&#125;'&#125;function waiting &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | grep 'Waiting' | awk '&#123;print $6&#125;'&#125;function accepts &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $1&#125;'&#125;function handled &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $2&#125;'&#125;function requests &#123; checkavailable|| curl -s "$&#123;nginxstatus&#125;" | awk NR==3 | awk '&#123;print $3&#125;'&#125;case "$1" in nginx_site_dicovery) nginx_site_dicovery ;; active) active ;; reading) reading ;; writing) writing ;; waiting) waiting ;; accepts) accepts ;; handled) handled ;; requests) requests ;; *) echo "Usage: $0 &#123;active |reading |writing |waiting |accepts |handled |requests &#125;"esac 脚本存放 /etc/zabbix/scripts 了，名称无所谓，后面调用即可，下面增加 userparameter # cat zabbix_agentd.d/userparameter_nginx.confUserParameter=nginx.accepts,/etc/zabbix/scripts/nginx_status.sh acceptsUserParameter=nginx.handled,/etc/zabbix/scripts/nginx_status.sh handledUserParameter=nginx.requests,/etc/zabbix/scripts/nginx_status.sh requestsUserParameter=nginx.connections.active,/etc/zabbix/scripts/nginx_status.sh activeUserParameter=nginx.connections.reading,/etc/zabbix/scripts/nginx_status.sh readingUserParameter=nginx.connections.writing,/etc/zabbix/scripts/nginx_status.sh writingUserParameter=nginx.connections.waiting,/etc/zabbix/scripts/nginx_status.sh waiting 3.zabbix server 上的配置 这里可以导入模板即可 然后创建 graph 这样，对 nginx server 基本监控就起来了，设置 trigger，action 就可以了 二、监控多站点 URL 参照 这个哥们 的这篇监控 nginx 多 site 监控所有的站点的话，可以在每个 nginx server 上跑第一部分的程序，然后汇总到 server 即可，也可以单独拿一台机器出来集中监控所有的 nginx 状态，我们称这台机器叫做“nginx 监控服务器”，这台机器可以是安装有 zabbix agent 的 zabbix server，也可以是其他 agent，但是这里我们更倾向于用第一种，当然机器负载较大的情况下，也可以单独分配一台机器来完成 思路：把所有 nginx 站点的URL写入到“ nginx 监控服务器”上的一个配置文件中。增加或删除 nginx 监控站点只需要修改这个配置文件，利用 zabbix 的 low-level discovery 动态监控这些站点。“ nginx 监控服务器”的 zabbix-agent 调用 nginx 监控脚本，获取 nginx_status 后，利用 zabbix-sender 把监控数据发送到 zabbix 服务器端。 1.nginx 被监控端配置 nginx 所在的被监控端必须启用了 stub_status 模块 在 server section 中增加如下字段，具体每个字段含义，qing请参考http://nginx.org/en/docs/http/ngx_http_stub_status_module.html location /nginxstatus &#123; stub_status on; access_log off; allow 127.0.0.1; allow 10.80.140.12; allow 10.80.100.52; deny all; 重载配置后，请求 http://x.x.x.x/nginxstatus 应该能看到如下结果 Active connections: 1server accepts handled requests 192033 192033 194627Reading: 0 Writing: 1 Waiting: 0 2.nginx 监控服务器上配置 这里我们用 zabbix server 当做 nginx 集中监控服务器，所以需要安装 zabbix-agent 和 zabbix-sender；另外为了保证脚本执行不会超时，可以设置 zabbix_agentd.conf 里的 Timeout=30，这样就不会因为执行超时，agent 拿不到数据的情况了 创建脚本存放目录，名称无所谓mkdir -p /etc/zabbix/scripts 创建如下脚本，这里直接引用了这个哥们的脚本，稍稍修改 #!/bin/bash## Filename: nginx_monitor.sh# Revision: 1.0# Date: 2014/09/24# Author: Qicheng# Email:# Website: http://qicheng0211.blog.51cto.com# Description: nginx统一监控脚本# Notes:## 修改AGENT_CONF的值为本地zabbix agent的配置文件路径AGENT_CONF="/etc/zabbix/zabbix_agentd.conf "# nginx站点的配置文件路径，注意和你本地是相对应的NGINX_SITE_CONF="/etc/zabbix/scripts/nginx_site.conf"# zabbix_sender的路径ZBX_SENDER="/usr/bin/zabbix_sender"FUNCTION=$1HOST_NAME=$2NGINX_SITE=$3CURL="/usr/bin/curl"TIMEOUT=30# nginx site low-level discoveryfunction nginxSiteDiscovery()&#123; nginx_site=($(grep '^[^#]' $&#123;NGINX_SITE_CONF&#125;)) max_index=$[$&#123;#nginx_site[@]&#125;-1] printf '&#123;\n' printf '\t"data":[' for key in `seq -s' ' 0 $max_index` do printf '\n\t\t&#123;' printf "\"&#123;#NGINX_SITE&#125;\":\"$&#123;nginx_site[$&#123;key&#125;]&#125;\"&#125;" if [ $key -ne $max_index ];then printf "," fi done printf '\n\t]\n' printf '&#125;\n'&#125;# 获取nginx status，把数据发送到zabbix serverfunction getNginxStatus()&#123; nginx_status_url="$&#123;NGINX_SITE&#125;/nginxstatus" # 获取nginx_status后，保存到下面的文件里 nginx_status_file="/tmp/nginx_status_$(echo $&#123;NGINX_SITE&#125; | sed 's#^http.*://##; s#/#_#g').log" :&gt;"$nginx_status_file" # curl获取nginx_status $&#123;CURL&#125; -s --connect-timeout $&#123;TIMEOUT&#125; "$nginx_status_url" 2&gt;&amp;1 | tee "$nginx_status_file" line_num=$(cat "$nginx_status_file" | wc -l) # 判断是否正确获取nginx_status [ $line_num -ne 4 ] &amp;&amp; &#123; echo "ERROR: $nginx_status_file is not correct."; exit 1;&#125; active=$(cat "$nginx_status_file" | grep 'Active' | awk '&#123;print $NF&#125;') reading=$(cat "$nginx_status_file" | grep 'Reading' | awk '&#123;print $2&#125;') writing=$(cat "$nginx_status_file" | grep 'Writing' | awk '&#123;print $4&#125;') waiting=$(cat "$nginx_status_file" | grep 'Waiting' | awk '&#123;print $6&#125;') accepts=$(cat "$nginx_status_file" | awk NR==3 | awk '&#123;print $1&#125;') handled=$(cat "$nginx_status_file" | awk NR==3 | awk '&#123;print $2&#125;') requests=$(cat "$nginx_status_file" | awk NR==3 | awk '&#123;print $3&#125;') echo "Sending the data to zabbix server..." # 将特定格式的数据发送到zabbix server，每行的格式为：&lt;hostname&gt; &lt;key&gt; &lt;value&gt; cat &lt;&lt; EOF | $&#123;ZBX_SENDER&#125; -c $&#123;AGENT_CONF&#125; -i -"$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,active]" "$&#123;active&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,reading]" "$&#123;reading&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,writing]" "$&#123;writing&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,waiting]" "$&#123;waiting&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,accepts]" "$&#123;accepts&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,handled]" "$&#123;handled&#125;""$&#123;HOST_NAME&#125;" "nginx_status[$NGINX_SITE,requests]" "$&#123;requests&#125;"EOF&#125;[ $# -eq 0 ] &amp;&amp; &#123; echo "ERROR: The script needs at least one parameter."; exit 1;&#125;case $FUNCTION in nginxSiteDiscovery|getNginxStatus) $FUNCTION ;; *) echo "ERROR: Bad parameters." exit 1 ;;esac 3.创建站点配置文件 这部分依旧在 nginx 监控服务器上的配置，在刚才创建的 scripts下新建一个配置文件，我这里只用一个站点作为演示，多个URL就每一行一个 # cat /etc/zabbix/scripts/nginx_site.confhttp://10.80.100.52 4.添加 UserParameter 这部分的确是在 agent 上的配置，只不过这里是在 zabbix server 上的 agent 上，添加完成了之后重启 agent UserParameter=nginxSiteDiscovery,bash /etc/zabbix/scripts/nginx_monitor.sh nginxSiteDiscoveryUserParameter=getNginxStatus[*],bash /etc/zabbix/scripts/nginx_monitor.sh getNginxStatus "$1" "$2" 5.命令行测试 这部分为了验证前面的操作 # 首先确定是否可以获取到该URL statuscurl -s --connect-timeout 30 'http://10.80.100.52/nginxstatus'Active connections: 2server accepts handled requests 193851 193851 196445Reading: 0 Writing: 1 Waiting: 1# 通过 zabbix_get 获取数据# curl -s --connect-timeout 30 'http://10.80.100.52/nginxstatus'# bash /etc/zabbix/scripts/nginx_monitor.sh nginxSiteDiscovery# zabbix_get -s 127.0.0.1 -k getNginxStatus[10.80.100.52, http://10.80.100.52] 如果上述都能正确返回结果，那么表明数据能正确传输了，可以进行下一步了 6.配置 web 这部门可以直接导入模板，或者直接新建模板都可以 新建 host ，这里既然 nginx 集中监控机是 zabbix server 本身，那么新建 Host 时候就要注意 host 就是 server 本身，然后 link 模板即可，这里模板也是文章作者分享，下载模板Template App Nginx 这里，就可以针对全网的 URL 进行监控了，或者根据自己需要适当修改模板，满足自身需求也可，在结合上面的对 nginx server 的监控，就可以达到最所有 web 的监控，当然了，可能有更复杂的需求，这里只是基本上满足了基本的对 web 的监控需求，后面如果有更多监控，也会继续跟进]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 分配只读用户]]></title>
    <url>%2Fnote%2Fzabbix-%E5%88%86%E9%85%8D%E5%8F%AA%E8%AF%BB%E7%94%A8%E6%88%B7.html</url>
    <content type="text"><![CDATA[如果你半夜醒来发现自己已经好长时间没读书，而且没有任何负罪感的时候，你就必须知道，你已经堕落了。不是说书本本身特了不起，而是读书这个行为意味着你没有完全认同于这个现世和现实，你还有追求，还在奋斗，你还有不满，你还在寻找另一种可能性，另一种生活方式。 最近一直在研究 zabbix ，这次重新学和以前不同，之前是看书，这次是结合实际需求看书再看文档，恰好有个需求就是其他项目组的人需要查看自己项目的设备状况，所以我这边得分配一个只读用户，只能查看自己设备的权限 一、zabbix 用户1.1 需求 zabbix 的用户管理也做到了权限细化，定位到某个组，定义组的权限，所以根据这个需求，我得给这个项目组创建一个用户组，并且只能查看他们项目组的相关的信息 1.2 创建相关用户并分配权限1.创建 user group 2.创建 user 划分权限 登录测试 这样就完成了之前给每个项目组划分一个只能查看的账号，方便他们查看项目机器的需求，还是很方便的 参考阅读 zabbix user]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监控中性能指标]]></title>
    <url>%2Fnote%2F%E7%9B%91%E6%8E%A7%E4%B8%AD%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87.html</url>
    <content type="text"><![CDATA[监控是个麻烦事情，做得好，绝对是个大型工程，当然了也可以将就凑或用，所以问题就是需要监控哪些指标可能每个公司都有自己独立的见解，从网上看到一份监控指标写的我觉得已经算的上详细了，遂转载过来，后期加上自己的不断补充 Apache 监控指标： Apache吞吐率 Apache并发连接数 Apache并发连接数详细统计，包括读取请求、持久连接、发送响应内容、关闭连接、等待连接 Lighttpd 监控指标： Lighttpd吞吐率 Lighttpd并发连接数 Lighttpd并发连接数详细统计，包括建立连接、读取请求、读取POST数据、处理请求、发送响应内容、关闭连接 Nginx 监控指标： Nginx吞吐率 Nginx并发连接数 Nginx并发连接数详细统计，包括读取请求、处理请求和发送响应、持久连接 Nginx持久连接利用率 MySQL 监控指标： MySQL查询吞吐率，包括Change DB、Select、Insert、Update、Delete MySQL持久连接利用率 MySQL查询缓存空间使用率 MySQL查询缓存命中率 MySQL缓存查询数 MySQL索引缓存命中率 MySQL索引读取统计 MySQL连接吞吐率 MySQL连接缓存命中率 MySQL并发连接数，包括最大允许连接数、实际最大连接数、当前连接数、活跃连接数、缓存连接数 MySQL流量统计 MySQL表统计锁定 MongoDB 监控指标： MongoDB全局锁时间比例。此指标反映MongoDB进入锁状态的时间比例。 MongoDB当前等待锁总数。是读锁数和写锁数的总和。 MongoDB当前等待读锁数。因读请求过高时触发的锁数。 MongoDB当前等待写锁数。因写请求过高时触发的锁数。 MongoDB查询吞吐率。也就是MongoDB每秒处理的请求数，根据请求类别的不一样细分有query，update，delete，getmore吞吐率。 MongoDB使用内存，使用磁盘空间。此指标能反映MongoDB使用内存，磁盘空间的状况。 MongoDB分页次数，此指标反映内存分页的次数，有助于对MongoDB的性能分析。 MongoDB索引命中率，即单位总命中次数除以总命中次数与未命中次数之和。 MongoDB索引访问次数每秒，此指标反映索引的使用频率。 MongoDB当前链接数，可用链接数。 Memcache 监控指标： Memcache缓存命中率，即单位总命中次数除以总命中次数与未命中次数之和； Memcache当前链接数，即当前已经建立的链接数量； Memcache链接数每秒，即单位时间内新建立的链接数量； Memcache使用内存，即当前存储的items所占用的字节数； Memcache当前条目数量，即当前存储的items数量； Memcache读写每秒，分为读每秒和写每秒，读每秒是指单位时间内新增的读的次数，写每秒是指单位时间内新增的写的次数； Memcache空间使用率，当前存储的items所占用的字节数除以系统分配给Memcache的内存大小 Redis 监控指标： Redis链接客户数。 Redis链接从库数。此指标反映Redis的从库链接数。 Redis链接数每分钟。此指标反映Redis的请求频率。 Redis阻塞客户数。当并发请求数过高时触发阻塞。此指标反映Redis的并发请求状况。 Redis Pub/Sub通道数。 Redis Pub/Sub模式数。 Redis命中率。即单位总命中次数除以总命中次数与未命中次数之和。 Redis使用内存。此指标反映Redis当前占用内存量。 Redis执行命令数每分钟。此指标反映Redis执行命令频率。 Tomcat 监控指标： JVM内存，包括JVM可使用内存、JVM所使用内存、JVM最大可使用内存； Tomcat请求数，包括每秒请求数，每秒出错数； Tomcat网络流量统计，包括进流量统计，出流量统计； Tomcat线程，包括最大线程数，当前线程数，当前繁忙线程数； Tomcat处理时间，包括最大处理时间，平均处理时间； Web 监控指标 网站返回值 请求时长]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控性能指标</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix 报错集锦]]></title>
    <url>%2Fnote%2Fzabbix%20%E6%8A%A5%E9%94%99%E9%9B%86%E9%94%A6.html</url>
    <content type="text"><![CDATA[要相信：梦里能到达的地方，总有一天，脚步也能到达！ 研究 zabbix 中碰到了各种各样的问题，所以一路踩过来，分享出来，保持更新 一、安装错误1.1、zabbix gui install problem故障现象：这里的问题就是我除了可以选择 sqlite 以外无法选择任何其他数据库 解决办法： 思路来自：https://www.zabbix.com/forum/showthread.php?t=26871 提示我可能 php 没有安装 mysqli 的扩展，导致无法查找到 mysqld 的类，所以前端使用 php 就无法查询到 mysqld 的选项，只要安装好 php 的这个扩展即可 # 进入源码包tar xf php-5.3.25.tar.gzcd php-5.3.25/ext/mysqli/$&#123;PHP_INSTALL_PATH&#125;/bin/phpize./configure --with-php-config=$&#123;PHP_INSTALL_PATH&#125;/bin/php-configmakemake installvim $&#123;PHP_INSTALL_PATH&#125;/etc/php.ini添加extension = mysqli.so重启 php 即可 二、网络传输错误2.1、latest data 没有数据 故障现象 首次测试，欲配置 client 主动发送数据至 server，监控网卡流量，但是配置完成 item 监控 enable，但是 latest data 没有数据，也没法出图，查询日志发觉多数都是些如下错误 server:24211:20150113:124147.686 cannot send list of active checks to [10.80.140.12]: host [zabbix] not foundagent:11877:20150113:124147.686 no active checks on server [10.80.140.12:10051]: host [zabbix] not found 解决方法： 经过日志查看，agent 配置文件中 Hostname 和 创建 host 的页面中填写的第一行 Host name 不同，所以无法识别，修改回一致，重启 agent ，问题解决 2.2、connection unreachable 故障现象： 在创建完 host 之后的页面中，Availablility 中显示红色，并报错 “Get value from agent failed: cannot connect to [[192.168.1.1]:10050]: [111] Connection refused” 解决方法： agent 可能并没有开启，开启之后即可 2.3、timeout (转载自http://fengzhige.blog.51cto.com/3691377/1034485) 故障现象： 有时候用户自定义的脚本运行的时间可能比较长，如超过 10 秒的 20 秒的。这时在执行 zabbix_agentd -p 或者 zabbix_agentd -t 时就可能出现 “Alarm clock”，从而得不到想要的结果。这是因为 zabbix agentd 配置文件中定义 Timeout 时间默认为 3 秒，脚本运行取结果的时间超过了 3秒就会出现这种情况。 解决方法： 编辑配置文件 /etc/zabbix/zabbix_agentd.conf，找到 Timeout 把它定义为 30 秒或小于 30 秒 特殊情况： 对上述中的情况还需要注意对 zabbix 服务器端的配置，如我自己定义的脚本 UserParameter=ping.avgtime,ping 192.168.30.2 -c 10 -w 29 |grep 'avg' |awk -F "/" '&#123;print $5&#125;' 对192.168.30.2 ping 10 取平均值，-w 参数是对 ping 限定时间为 29 秒 这个脚本运行的大概时间为 10 秒左右，此时在 agent 端虽然可以用 zabbix_agentd -t 得到结果，但是在 zabbix 服务器端日志会不断的出现 1762:20121023:191941.360 resuming Zabbix agent checks on host [Zabbix server]: connection restored1761:20121023:191952.149 Zabbix agent item [ping.avgtime] on host [CentOS-3] failed: first network error, wait for 15 seconds1762:20121023:192010.610 Zabbix agent item [ping.avgtime] on host [CentOS-3] failed: another network error, wait for 15 seconds1762:20121023:192028.628 Zabbix agent item [ping.avgtime] on host [CentOS-3] failed: another network error, wait for 15 seconds 这样的错误日志，并且在 web 端也没有画出图来。 解决办法： 编辑zabbix服务器端的配置文件 /etc/zabbix/zabbix_server.conf 找到 Timeout 把它定义为30秒或小于30秒。 如果还有类似提示则应该是 zabbix 服务器的内存设置得太小了，加大服务器内存便可。 2.4、dropped connection配置完成之后 server 的 web 界面里，监控状态图标显示红色异常，并提示如下错误： Received empty response from Zabbix Agent at [10.1.68.105]. Assuming that agent dropped connection because of access permissions 查看 agent 日志报错提示： 1750:20150615:110722.100 no active checks on server [x.x.x.x:10051]: host [xxxx.xxxxx] not found 这里 agent 配置的 ZABBIX_SERVER 变量是 zabbix server 的公网口地址，结果在 zabbix server 的配置里配置的是 agent 的内网地址口，导致两者的 ZABBIX_SERVER 变量值不匹配，出现了这个问题，直接统一用内网地址即可解决 三、权限问题3.1、客户端脚本权限问题 ZBX_NOTSUPPORTED: Unsupported item key. 查看目标权限，属主属组的确是 zabbix ，但是忘了给脚本加上 x 可执行权限，故报错，加上权限即可 3.2 zabbix server 端对脚本调用权限问题 zabbix server 执行 zabbix_get 结果输出不正确，日志里查看发现sh: /xxx/xxx/zabbix/bin/raid.sh: Permission denied server 端用 zabbix 用户执行脚本，但是执行的脚本中有需要 root 权限执行的命令，所以 zabbix 用户权限不够，就会提示这个问题，此时可以给与 zabbix 用户进行 sudo 提权即可 3.3 agentd 执行 root 命令问题 Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all zabbix agent 是 yum 安装，该服务以 zabbix 用户启动的。验证后发现， 原来是 netstat -lantup 里的 -p 参数或者 ss 需要 root 用户才能使用。 解决方法： # visudo# 注释掉此行Defaults requiretty# 在最后加入如下行：zabbix ALL=(ALL) NOPASSWD: /bin/netstat,/usr/sbin/ss# “NOPASSWD”表示zabbix用户在执行命令时，无需输入密码；# “/bin/netstat”，是 zabbix 用户可以 root 身份执行的命令，如果有多个，请用逗号分隔，这样的好处是做到权限的精细控制 四、配置错误4.1 not support key 转载自 运维生存时间 zabbix 定义好 key 之后，总是会出现 Not supported，看到这个问题，大家不用着急，问题其实很容易解决，首先鼠标点击当前 key 的大红叉上，会显示出报错内容。常见的有： 1、zabbix_server 取不到值，或者取到空值，在 server 上使用命令zabbix_get 获取当前 key 2、取到的值和 key 的类型不一样，例如我定义的是 float，但是取到的是字符串，那肯定不会。 3、脚本执行超时，默认情况下 zabbix 3 秒就超时，所以要确认下脚本到底要执行多久 这些都是一些常见的问题，但是有一个很奇怪的问题 zabbix_get 能获取到值，但是 item 依旧为 Not Supported。如果你的值类型设置没错的话，那有如下解决方法： 1、等 10 分钟，zabbix 会去重新 check 一次当前 item 的 Supported 状态。 2、删掉当前 item，重新创建 3、修改 zabbix 重新 check 的时间，例如改成 10 分钟，点击administration —&gt; General —&gt; 右侧下拉条选择 other —&gt; Refresh unsupported items (in sec)改为 60（单位为秒）—-&gt; update。如下图： 更多阅读]]></content>
      <categories>
        <category>zabbix</category>
      </categories>
      <tags>
        <tag>zabbix 错误集锦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让人耳目一新的python库（转）]]></title>
    <url>%2Fnote%2Fpython-%E8%AE%A9%E4%BA%BA%E8%80%B3%E7%9B%AE%E4%B8%80%E6%96%B0%E7%9A%84python%E5%BA%93.html</url>
    <content type="text"><![CDATA[工欲善其事，必先利其器。Python 社区高产富饶，有大量的美丽，实用的库, 这里挑选出来一些接口设计简洁的库。文章转载自 hit9 1、docopt Pythonic的命令行参数解析库，github 地址 """Usage: quick_example.py tcp &lt;host&gt; &lt;port&gt; [--timeout=&lt;seconds&gt;] quick_example.py serial &lt;port&gt; [--baud=9600] [--timeout=&lt;seconds&gt;] quick_example.py -h | --help | --version"""from docopt import docoptif __name__ == '__main__': arguments = docopt(__doc__, version='0.1.1rc') print(arguments) 2、requests 大神kennethreitz的作品，简易明了的HTTP请求操作库, 是urllib2的理想替代品，API简洁明了，这才是Python开发者喜欢的 &gt;&gt;&gt; r = requests.get('https://api.github.com/user', auth=('user', 'pass'))&gt;&gt;&gt; r.status_code200&gt;&gt;&gt; r.headers['content-type']'application/json; charset=utf8'&gt;&gt;&gt; r.encoding'utf-8'&gt;&gt;&gt; r.textu'&#123;"type":"User"...'&gt;&gt;&gt; r.json()&#123;u'private_gists': 419, u'total_private_repos': 77, ...&#125; 3、sh 如其名，子进程接口。github 地址 from sh import ifconfigprint(ifconfig("wlan0")) 4、purl 拥有简洁接口的URL处理器，github 地址 &gt;&gt;&gt; from purl import URL&gt;&gt;&gt; from_str = URL('https://www.google.com/search?q=testing')&gt;&gt;&gt; u.query_param('q')u'testing'&gt;&gt;&gt; u.host()u'www.google.com' 5、when.py 友好时间的日期库，github 地址 &gt;&gt;&gt; import when&gt;&gt;&gt; when.timezone()'Asia/Shanghai'&gt;&gt;&gt; when.today()datetime.date(2013, 5, 14)&gt;&gt;&gt; when.tomorrow()datetime.date(2013, 5, 15)&gt;&gt;&gt; when.now()datetime.datetime(2013, 5, 14, 21, 2, 23, 78838) 6、clize clize是一个类似 getopt 的库。可以用程序的函数名字来作为使用方法，github 地址 #!/usr/bin/env pythonfrom clize import clize@clizedef echo(text, reverse=false): if reverse: text = text[::-1] print(text)if __name__ == '__main__': import sys echo(*sys.argv) 而这个小程序就可以这么使用: $ ./echo.py --helpUsage: ./echo.py [OPTIONS] textPositional arguments: textOptions: --reverse -h, --help Show this help Pocoo小组 pocoo出的库，必属精品。它的库很出名: flask, jinja2, pygments,sphinx… github 地址 &emsp;&emsp; 参考阅读 看下这个gist HN]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多线程的基本概念]]></title>
    <url>%2Fnote%2F%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html</url>
    <content type="text"><![CDATA[之前对于多线程总是一知半解，最近用到了之后才想认真的学习，所以一边用一边学，顺带分享出来 首先从基本概念开始恶补，转载自 心内求法 并发式编程 不同的编程范式对软件有不同的视角。 并发式编程将软件看做任务和资源的组合——任务之间竞争和共享资源，当资源满足时执行任务，否则等待资源。 并发式编程使得软件易于理解和重用，在某些场景能够极大提高性能。 多任务操作系统 要实现并发，首先需要操作系统的支持。现在的操作系统大部分都是多任务操作系统，可以“同时”执行多个任务。 多任务可以在进程或线程的层面执行。 进程是指一个内存中运行的应用程序，每个进程都有自己独立的一块内存空间。多任务操作系统可以“并发”执行这些进程。 线程是指进程中乱序、多次执行的代码块，多个线程可以“同时”运行，所以认为多个线程是“并发”的。多线程的目的是为了最大限度的利用CPU资源。比如一个JVM进程中，所有的程序代码都以线程的方式运行。 这里面的“同时”、“并发”只是一种宏观上的感受，实际上从微观层面看只是进程/线程的轮换执行，只不过切换的时间非常短，所以产生了“并行”的感觉。 多线程 vs 多进程 操作系统会为每个进程分配不同的内存块，而多个线程共享进程的内存块。这带来最直接的不同就是创建线程的开销远小于创建进程的开销。 同时，由于内存块不同，所以进程之间的通信相对困难。需要采用 pipe/named pipe, signal, message queue, shared memory, socket 等手段；而线程间的通信简单快速，就是共享进程内的全局变量。 但是，进程的调度由操作系统负责，线程的调度就需要我们自己来考虑，避免死锁，饥饿，活锁，资源枯竭等情况的发生，这会增加一定的复杂度。而且，由于线程之间共享内存，我们还需要考虑线程安全性的问题。 线程安全 以为线程间共享进程中的全局变量，所以当其他线程改变了共享的变量时，可能会对本线程产生影响。 所谓线程安全的约束是指一个函数被多个并发线程反复调用时，要一直产生正确的结果。要保证线程安全，主要是通过加锁的方式保证共享变量的正确访问。 比线程安全更严格的约束是”可重入性”，即函数在一个线程内执行的过程中被暂停，接下来又在另一个线程内被调用，之后在返回原线程继续执行。在整个过程中都能保证正确执行。保证可重入性，通常通过制作全局变量的本地拷贝来实现。 线程的生命周期所谓的 xx 生命周期，其实就是某对象的包含产生和销毁的一张状态图。线程的生命周期如下图所示：各状态的说明如下： New新建。新创建的线程经过初始化后，进入Runnable状态。 Runnable就绪。等待线程调度。调度后进入运行状态。 Running运行。 Blocked阻塞。暂停运行，解除阻塞后进入Runnable状态重新等待调度。 Dead消亡。线程方法执行完毕返回或者异常终止。 可能有3种情况从Running进入Blocked： 同步：线程中获取同步锁，但是资源已经被其他线程锁定时，进入Locked状态，直到该资源可获取（获取的顺序由Lock队列控制） 睡眠：线程运行sleep()或join()方法后，线程进入Sleeping状态。区别在于sleep等待固定的时间，而join是等待子线程执行完。当然join也可以指定一个“超时时间”。从语义上来说，如果两个线程a,b, 在a中- - 调用b.join()，相当于合并(join)成一个线程。最常见的情况是在主线程中join所有的子线程。 等待：线程中执行wait()方法后，线程进入Waiting状态，等待其他线程的通知(notify）。 线程的类型 主线程：当一个程序启动时，就有一个进程被操作系统（OS）创建，与此同时一个线程也立刻运行，该线程通常叫做程序的主线程（Main Thread）。每个进程至少都有一个主线程，主线程通常最后关闭。 子线程：在程序中创建的其他线程，相对于主线程来说就是这个主线程的子线程。 守护线程：daemon thread，对线程的一种标识。守护线程为其他线程提供服务，如JVM的垃圾回收线程。当剩下的全是守护线程时，进程退出。 前台线程：相对于守护线程的其他线程称为前台线程。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Argparse简易教程]]></title>
    <url>%2Fnote%2FArgparse%E7%AE%80%E6%98%93%E6%95%99%E7%A8%8B.html</url>
    <content type="text"><![CDATA[写 python 中碰到了需求，所以查询看到这个哥们翻译的挺好的，就直接转载过来的，原文地址见这里 本教程是对于Python标准库中推荐使用的命令行解析模块argparse的简单介绍。 PS：还有其他两个模块实现这一功能，getopt(等同于C语言中的getopt())和弃用的optparse。因为argparse是基于optparse，所以用法很类似。 概念让我们先用 ls 来展示这篇教程将要介绍的相关特性： $ lscpython devguide prog.py pypy rm-unused-function.patch$ ls pypyctypes_configure demo dotviewer include lib_pypy lib-python ...$ ls -ltotal 20drwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpythondrwxr-xr-x 4 wena wena 4096 Feb 8 12:04 devguide-rwxr-xr-x 1 wena wena 535 Feb 19 00:05 prog.pydrwxr-xr-x 14 wena wena 4096 Feb 7 00:59 pypy-rw-r--r-- 1 wena wena 741 Feb 18 01:01 rm-unused-function.patch$ ls --helpUsage: ls [OPTION]... [FILE]...List information about the FILEs (the current directory by default).Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.... 从上面的四个命令，我们可以了解一些概念： ls 命令在没有参数的情况下也是可以使用的。默认显示当前目录的内容。 如果想让它展示不同，需要给它更多的参数。这个例子中,我们想让它显示目录 pypy ,需要指定必要的参数。因为程序需要基于这些参数确定做些什么。这个概念类似 cp, 比如最常见的 cp SRC DST。第一个参数表示你要复制什么，第二个参数表示复制到哪里去。 现在，我想要改变程序的行为。在示例中，我们让它显示更多的信息，不仅仅是文件名，这里的 -l 就是一个可选参数。 最后是一个帮助文档的片段。这些帮助对于没有使用过这个程序的人很有帮助，他们可以通过简单的阅读，就可以了解程序的用法。 基础让我们从一个简单的例子开始，它(几乎)什么都不 import argparseparser = argparse.ArgumentParser()parser.parse_args() 运行： $ python prog.py$ python prog.py --helpusage: prog.py [-h]optional arguments: -h, --help show this help message and exit$ python prog.py --verboseusage: prog.py [-h]prog.py: error: unrecognized arguments: --verbose$ python prog.py foousage: prog.py [-h]prog.py: error: unrecognized arguments: foo 结果分析： 不加任何参数运行，什么也不显示，没有什么用。 第二条展示了 argparse 模块的好处，几乎什么都不做，却得到了一个很有用的帮助信息。 --help 参数可简写成-h,是唯一预设的(不需要指定)。 定位参数例子： import argparseparser = argparse.ArgumentParser()parser.add_argument("echo")args = parser.parse_args()print args.echo 运行： $ python prog.pyusage: prog.py [-h] echoprog.py: error: the following arguments are required: echo$ python prog.py --helpusage: prog.py [-h] echopositional arguments: echooptional arguments: -h, --help show this help message and exit$ python prog.py foofoo 结果分析： 我们用到了方法 add_argument()，用来指定程序需要接受的命令参数，本例中的 echo。 现在运行程序必须指定一个参数。 方法 parse_args() 通过分析指定的参数返回一些数据，如本例中的 echo。 像魔法一样，argparse 自动生成这些变量，你可能已经注意到变量 echo 和我们指定的参数相同。 虽然现在帮助信息已经很美观了，但是还不够好。例如我们知道 echo 是个定位参数，但是却不知道该参数的意思，只能通过猜或者读源码。下面，我们可以让它更有帮助： import argparseparser = argparse.ArgumentParser()parser.add_argument("echo", help="echo the string you use here")args = parser.parse_args()print args.echo 运行： $ python prog.py -husage: prog.py [-h] echopositional arguments: echo echo the string you use hereoptional arguments: -h, --help show this help message and exit 再修改下： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", help="display a square of a given number")args = parser.parse_args()print args.square**2 运行如下： $ python prog.py 4Traceback (most recent call last): File "prog.py", line 5, in &lt;module&gt; print args.square**2TypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int' 运行有点问题，因为如果不指定参数类型，argparse 默认它是字符串。因此我们需要告诉 argparse 该参数是整型。 import argparseparser = argparse.ArgumentParser()parser.add_argument("square", help="display a square of a given number", type=int)args = parser.parse_args()print args.square**2 运行： $ python prog.py 416$ python prog.py fourusage: prog.py [-h] squareprog.py: error: argument square: invalid int value: 'four' 可以运行了，程序能够在执行前过滤一些错误的参数输入。 可选参数以上，展示了定位参数的用法。下面让我们来看看如何添加可选参数： import argparseparser = argparse.ArgumentParser()parser.add_argument("--verbosity", help="increase output verbosity")args = parser.parse_args()if args.verbosity: print "verbosity turned on" 输出： $ python prog.py --verbosity 1verbosity turned on$ python prog.py$ python prog.py --helpusage: prog.py [-h] [--verbosity VERBOSITY]optional arguments: -h, --help show this help message and exit --verbosity VERBOSITY increase output verbosity$ python prog.py --verbosityusage: prog.py [-h] [--verbosity VERBOSITY]prog.py: error: argument --verbosity: expected one argument 结果分析： 当指定 --verbosity 时程序就显示一些东西，没指定的时候就不显示。 这个参数事实上是可选的，不指定它也不会出错。如果不指定可选的参数，对应的变量就被设置为 None，比如本例中的 args.verbosity, 这就是为什么示例中的 if 没有执行的原因。 帮助信息发生了点变化 当我们使用可选参数 --verbosity 时，也必须指定一些值。 上面的示例中可选参数 --verbosity 后面接受任意的整型值，但是对于简单的程序，实际上只需要两种值，True 或者 False。因此可以修改上面的代码 import argparseparser = argparse.ArgumentParser()parser.add_argument("--verbose", help="increase output verbosity", action="store_true")args = parser.parse_args()if args.verbose: print "verbosity turned on" 运行： $ python prog.py --verboseverbosity turned on$ python prog.py --verbose 1usage: prog.py [-h] [--verbose]prog.py: error: unrecognized arguments: 1$ python prog.py --helpusage: prog.py [-h] [--verbose]optional arguments: -h, --help show this help message and exit --verbose increase output verbosity 结果分析： 现在多加一个标志来替代必须给出一些值，并修改了名称来表达我们的意思。注意现在指定了一个新的关键词 action，并且赋值为 store_ture。如果指定了这个可选参数，args.verbose 就赋值为 True ,否则就为False。 多指定了值，它就会发出错误提示。 注意帮助文档有什么不同 简写如果你很熟悉命令行，你可能已经注意到我在上面已经提到了参数的简写，非常的简单： import argparseparser = argparse.ArgumentParser()parser.add_argument("-v", "--verbose", help="increase output verbosity", action="store_true")args = parser.parse_args()if args.verbose: print "verbosity turned on" 运行如下： $ python prog.py -vverbosity turned on$ python prog.py --helpusage: prog.py [-h] [-v]optional arguments: -h, --help show this help message and exit -v, --verbose increase output verbosity 注意帮助信息也有相应的变化。 混合使用定位参数和可选参数再复杂一点： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display a square of a given number")parser.add_argument("-v", "--verbose", action="store_true", help="increase output verbosity")args = parser.parse_args()answer = args.square**2if args.verbose: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)else: print answer 运行： $ python prog.pyusage: prog.py [-h] [-v] squareprog.py: error: the following arguments are required: square$ python prog.py 416$ python prog.py 4 --verbosethe square of 4 equals 16$ python prog.py --verbose 4the square of 4 equals 16 为了让程序复杂点，我们重新加上了定位参数。 注意到参数的顺序是没有影响的。 来看看为程序加上处理重复参数的能力会怎么样： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display a square of a given number")parser.add_argument("-v", "--verbosity", type=int, help="increase output verbosity")args = parser.parse_args()answer = args.square**2if args.verbosity == 2: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)elif args.verbosity == 1: print "&#123;&#125;^2 == &#123;&#125;".format(args.square, answer)else: print answer 运行： $ python prog.py 416$ python prog.py 4 -vusage: prog.py [-h] [-v VERBOSITY] squareprog.py: error: argument -v/--verbosity: expected one argument$ python prog.py 4 -v 14^2 == 16$ python prog.py 4 -v 2the square of 4 equals 16$ python prog.py 4 -v 316 除了最后一个暴露了一个bug，其他的看起都来运行良好。让我们通过限制–verbosity后面跟的值来修正： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display a square of a given number")parser.add_argument("-v", "--verbosity", type=int, choices=[0, 1, 2], help="increase output verbosity")args = parser.parse_args()answer = args.square**2if args.verbosity == 2: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)elif args.verbosity == 1: print "&#123;&#125;^2 == &#123;&#125;".format(args.square, answer)else: print answer 运行： $ python prog.py 4 -v 3usage: prog.py [-h] [-v &#123;0,1,2&#125;] squareprog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)$ python prog.py 4 -husage: prog.py [-h] [-v &#123;0,1,2&#125;] squarepositional arguments: square display a square of a given numberoptional arguments: -h, --help show this help message and exit -v &#123;0,1,2&#125;, --verbosity &#123;0,1,2&#125; increase output verbosity 注意帮助信息和错误信息都发生了变化。 现在让我们用一种更常用的方法来处理，类似 CPython 处理自己的参数(参考 python --help)： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display the square of a given number")parser.add_argument("-v", "--verbosity", action="count", help="increase output verbosity")args = parser.parse_args()answer = args.square**2if args.verbosity == 2: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)elif args.verbosity == 1: print "&#123;&#125;^2 == &#123;&#125;".format(args.square, answer)else: print answer 我们引入了另一个关键词 count 来统计可选参数出现的次数： $ python prog.py 416$ python prog.py 4 -v4^2 == 16$ python prog.py 4 -vvthe square of 4 equals 16$ python prog.py 4 --verbosity --verbositythe square of 4 equals 16$ python prog.py 4 -v 1usage: prog.py [-h] [-v] squareprog.py: error: unrecognized arguments: 1$ python prog.py 4 -husage: prog.py [-h] [-v] squarepositional arguments: square display a square of a given numberoptional arguments: -h, --help show this help message and exit -v, --verbosity increase output verbosity$ python prog.py 4 -vvv16 和前面的版本相比这里多了一个关键词(类似 action=&quot;store_true”)。 行为上也类似 store_true。 count 关键词的示范，大家可能在其他地方已经看过了。 就像 store_ture，如果不指定 -v，响应变量就会被设置为 None。 指定完整的名称和简写效果是一样的。 但是不爽的是，帮助信息并没有做出有用的提示，不过可以通过修改 help 来改善这个问题。 最后那个输出又暴露了程序的 bug 修改一下： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display a square of a given number")parser.add_argument("-v", "--verbosity", action="count", help="increase output verbosity")args = parser.parse_args()answer = args.square**2# bugfix: replace == with &gt;=if args.verbosity &gt;= 2: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)elif args.verbosity &gt;= 1: print "&#123;&#125;^2 == &#123;&#125;".format(args.square, answer)else: print answer 运行如下： $ python prog.py 4 -vvvthe square of 4 equals 16$ python prog.py 4 -vvvvthe square of 4 equals 16$ python prog.py 4Traceback (most recent call last): File "prog.py", line 11, in &lt;module&gt; if args.verbosity &gt;= 2:TypeError: unorderable types: NoneType() &gt;= int() 第一个输出是正确的，修正了上个版本的问题，参数出现次数 &gt;=2 时都能显示详细的信息。 第三个输出还是有问题 再来修改下： import argparseparser = argparse.ArgumentParser()parser.add_argument("square", type=int, help="display a square of a given number")parser.add_argument("-v", "--verbosity", action="count", default=0, help="increase output verbosity")args = parser.parse_args()answer = args.square**2if args.verbosity &gt;= 2: print "the square of &#123;&#125; equals &#123;&#125;".format(args.square, answer)elif args.verbosity &gt;= 1: print "&#123;&#125;^2 == &#123;&#125;".format(args.square, answer)else: print answer 我们又加入了一个关键词 default。设置它的默认值为 0，这样可以让它兼容其他整型。注意，如果一个可选参数没有指定，它就会被设置成 None，None 是不能和整型比较的(触发 [TypeError][5] 异常)。运行结果： $ python prog.py 416 你可以使用我们所学来做很多事情，但是这仅仅是皮毛而已。argparse 模块非常强大，下面来看看更多的用法。 高级用法如果我们想扩展程序的功能，而不仅仅是求平方： import argparseparser = argparse.ArgumentParser()parser.add_argument("x", type=int, help="the base")parser.add_argument("y", type=int, help="the exponent")parser.add_argument("-v", "--verbosity", action="count", default=0)args = parser.parse_args()answer = args.x**args.yif args.verbosity &gt;= 2: print "&#123;&#125; to the power &#123;&#125; equals &#123;&#125;".format(args.x, args.y, answer)elif args.verbosity &gt;= 1: print "&#123;&#125;^&#123;&#125; == &#123;&#125;".format(args.x, args.y, answer)else: print answer 输出： $ python prog.pyusage: prog.py [-h] [-v] x yprog.py: error: the following arguments are required: x, y$ python prog.py -husage: prog.py [-h] [-v] x ypositional arguments: x the base y the exponentoptional arguments: -h, --help show this help message and exit -v, --verbosity$ python prog.py 4 2 -v4^2 == 16 截止到目前，我们都在利用详细的级别来改变输出，下面的示例演示了利用详细的级别来显示更多输出： import argparseparser = argparse.ArgumentParser()parser.add_argument("x", type=int, help="the base")parser.add_argument("y", type=int, help="the exponent")parser.add_argument("-v", "--verbosity", action="count", default=0)args = parser.parse_args()answer = args.x**args.yif args.verbosity &gt;= 2: print "Running '&#123;&#125;'".format(__file__)if args.verbosity &gt;= 1: print "&#123;&#125;^&#123;&#125; ==".format(args.x, args.y),print answer 输出： $ python prog.py 4 216$ python prog.py 4 2 -v4^2 == 16$ python prog.py 4 2 -vvRunning 'prog.py'4^2 == 16 参数冲突: 迄今为止，我们已经使用到了 [argparse.ArgumentParser][6] 的两个方法，来看看他的另一个方法 add_mutually_exclusive_group()。它可以让我们指定某个参数和其他参数冲突。下面来修改下程序以对这个新方法有更多的了解：我们将加入参数 --quiet，它和参数 --verbose 冲突，不能同时指定： import argparseparser = argparse.ArgumentParser()group = parser.add_mutually_exclusive_group()group.add_argument("-v", "--verbose", action="store_true")group.add_argument("-q", "--quiet", action="store_true")parser.add_argument("x", type=int, help="the base")parser.add_argument("y", type=int, help="the exponent")args = parser.parse_args()answer = args.x**args.yif args.quiet: print answerelif args.verbose: print "&#123;&#125; to the power &#123;&#125; equals &#123;&#125;".format(args.x, args.y, answer)else: print "&#123;&#125;^&#123;&#125; == &#123;&#125;".format(args.x, args.y, answer) 程序很简单，为了演示冲突，去掉了其他功能特性展示，运行结果： $ python prog.py 4 24^2 == 16$ python prog.py 4 2 -q16$ python prog.py 4 2 -v4 to the power 2 equals 16$ python prog.py 4 2 -vqusage: prog.py [-h] [-v | -q] x yprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose$ python prog.py 4 2 -v --quietusage: prog.py [-h] [-v | -q] x yprog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose 很好理解，我们添加最后那个输出是为了展示灵活性，比如，指定参数时可以同时混用参数全称和简写。通过前面的学习，为了以防万一，你可能想通过帮助信息来告诉用户如何使用你的程序： import argparseparser = argparse.ArgumentParser(description="calculate X to the power of Y")group = parser.add_mutually_exclusive_group()group.add_argument("-v", "--verbose", action="store_true")group.add_argument("-q", "--quiet", action="store_true")parser.add_argument("x", type=int, help="the base")parser.add_argument("y", type=int, help="the exponent")args = parser.parse_args()answer = args.x**args.yif args.quiet: print answerelif args.verbose: print "&#123;&#125; to the power &#123;&#125; equals &#123;&#125;".format(args.x, args.y, answer)else: print "&#123;&#125;^&#123;&#125; == &#123;&#125;".format(args.x, args.y, answer) 注意下面的帮助信息，[-v | -q] 表明了可以使用 -v 或者 -q，但是不能同时使用。 $ python prog.py --helpusage: prog.py [-h] [-v | -q] x ycalculate X to the power of Ypositional arguments: x the base y the exponentoptional arguments: -h, --help show this help message and exit -v, --verbose -q, --quiet 总结argparse 模块提供了比我们展示的多得多的功能。它的文档更加详尽和深入，并且配了大量的示例。自己去深入阅读下，文档很容易理解。 参考链接 原文地址：Argparse Tutorial 官方文档：argparse 另外一篇：argparse]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>Argparse Tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NoSQL类型以及适用场景]]></title>
    <url>%2Fnote%2Fdb_NoSQL%E7%B1%BB%E5%9E%8B%E4%BB%A5%E5%8F%8A%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF.html</url>
    <content type="text"><![CDATA[最近有一直关注 Redis 和 MongoDB，因为环境一直有用，然后也看到一篇不错的文章，转载自网络 关系型数据库存在的问题对比传统关系型数据库，NoSQL有着更为复杂的分类——键值、面向文档、列存储以及图数据库。这里就带你一览NoSQL各种类型的适用场景及一些知名公司的方案选择。 在过去几年，关系型数据库一直是数据持久化的唯一选择，数据工作者考虑的也只是在这些传统数据库中做筛选，比如SQL Server、Oracle或者是MySQL。甚至是做一些默认的选择，比如使用.NET的一般会选择SQL Server；使用Java的可能会偏向Oracle，Ruby是MySQL，Python则是PostgreSQL或MySQL等等。 原因很简单：过去很长一段时间内，关系数据库的健壮性已经在多数应用程序中得到证实。我们可以使用这些传统数据库良好的控制并发操作、事务等等。然而如果传统的关系型数据库一直这么可靠，那么还有NoSQL什么事？NoSQL之所以生存并得到发展，是因为它做到了传统关系型数据库做不到的事！ Impedance Mismatch 应用程序规模的变大网络应用程序的规模日渐变大，我们需要储存更多的数据、服务更多的用户以及需求更多的计算能力。为了应对这种情形，我们需要不停的扩展。 扩展分为两类： 一种是纵向扩展，即购买更好的机器，更多的磁盘、更多的内存等等； 另一种是横向扩展，即购买更多的机器组成集群。 在巨大的规模下，纵向扩展发挥的作用并不是很大。首先单机器性能提升需要巨额的开销并且有着性能的上限，在 Google 和 Facebook 这种规模下，永远不可能使用一台机器支撑所有的负载。鉴于这种情况，我们需要新的数据库，因为关系数据库并不能很好的运行在集群上。不错你也可能会去搭建关系数据库集群，但是他们使用的是共享存储，这并不是我们想要的类型。于是就有了以 Google、 Facebook、Amazon 这些试图处理更多传输所引领的 NoSQL 纪元。 NoSQL纪元当下已经存在很多的 NoSQL 数据库，比如 MongoDB、Redis、Riak、HBase、Cassandra 等等。每一个都拥有以下几个特性中的一个： 不再使用 SQL 语言，比如 MongoDB、Cassandra 就有自己的查询语言 通常是开源项目 为集群运行而生 弱结构化——不会严格的限制数据结构类型 NoSQL数据库的类型NoSQL可以大体上分为4个种类：Key-value、Document-Oriented、Column-Family Databases 以及 Graph-Oriented Databases。下面就一览这些类型的特性： 一、 键值（Key-Value）数据库键值数据库就像在传统语言中使用的哈希表。你可以通过 key 来添加、查询或者删除数据，鉴于使用主键访问，所以会获得不错的性能及扩展性。 产品：Riak、Redis、Memcached、Amazon’s Dynamo、Project Voldemort 有谁在使用：GitHub （Riak）、BestBuy （Riak）、Twitter （Redis和Memcached）、StackOverFlow （Redis）、 Instagram （Redis）、Youtube （Memcached）、Wikipedia（Memcached） 适用的场景储存用户信息，比如会话、配置文件、参数、购物车等等。这些信息一般都和ID（键）挂钩，这种情景下键值数据库是个很好的选择。 不适用场景取代通过键查询，而是通过值来查询。Key-Value 数据库中根本没有通过值查询的途径。需要储存数据之间的关系。在 Key-Value 数据库中不能通过两个或以上的键来关联数据。事务的支持。在 Key-Value 数据库中故障产生时不可以进行回滚。 二、 面向文档（Document-Oriented）数据库面向文档数据库会将数据以文档的形式储存。每个文档都是自包含的数据单元，是一系列数据项的集合。每个数据项都有一个名称与对应的值，值既可以是简单的数据类型，如字符串、数字和日期等；也可以是复杂的类型，如有序列表和关联对象。数据存储的最小单位是文档，同一个表中存储的文档属性可以是不同的，数据可以使用 XML、JSON 或者 JSONB 等多种形式存储。 产品：MongoDB、CouchDB、RavenDB 有谁在使用：SAP （MongoDB）、Codecademy （MongoDB）、Foursquare （MongoDB）、NBC News （RavenDB） 适用的场景 日志。企业环境下，每个应用程序都有不同的日志信息。Document-Oriented数据库并没有固定的模式，所以我们可以使用它储存不同的信息。 分析。鉴于它的弱模式结构，不改变模式下就可以储存不同的度量方法及添加新的度量。 不适用场景在不同的文档上添加事务。Document-Oriented数据库并不支持文档间的事务，如果对这方面有需求则不应该选用这个解决方案。 三、 列存储（Wide Column Store/Column-Family）数据库列存储数据库将数据储存在列族（column family）中，一个列族存储经常被一起查询的相关数据。举个例子，如果我们有一个Person类，我们通常会一起查询他们的姓名和年龄而不是薪资。这种情况下，姓名和年龄就会被放入一个列族中，而薪资则在另一个列族中。 产品：Cassandra、HBase 有谁在使用：Ebay （Cassandra）、Instagram （Cassandra）、NASA （Cassandra）、Twitter （Cassandra and HBase）、Facebook （HBase）、Yahoo!（HBase） 适用的场景 日志。因为我们可以将数据储存在不同的列中，每个应用程序可以将信息写入自己的列族中。 博客平台。我们储存每个信息到不同的列族中。举个例子，标签可以储存在一个，类别可以在一个，而文章则在另一个。 不适用场景 ACID事务。Vassandra就不支持事务。 原型设计。如果我们分析Cassandra的数据结构，我们就会发现结构是基于我们期望的数据查询方式而定。在模型设计之初，我们根本不可能去预测它的查询方式，而一旦查询方式改变，我们就必须重新设计列族。 四、 图（Graph-Oriented）数据库图数据库允许我们将数据以图的方式储存。实体会被作为顶点，而实体之间的关系则会被作为边。比如我们有三个实体，Steve Jobs、Apple和Next，则会有两个“Founded by”的边将Apple和Next连接到Steve Jobs。 产品：Neo4J、Infinite Graph、OrientDB 有谁在使用：Adobe （Neo4J）、Cisco （Neo4J）、T-Mobile （Neo4J） 适用的场景在一些关系性强的数据中推荐引擎。如果我们将数据以图的形式表现，那么将会非常有益于推荐的制定 不适用场景不适合的数据模型。图数据库的适用范围很小，因为很少有操作涉及到整个图]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>NoSQL类型及适用场景</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elastic IP 和 Public IP 的区别]]></title>
    <url>%2Fnote%2F%E4%BA%91_Elastic-%E5%92%8C-Public-IP%E7%9A%84%E5%8C%BA%E5%88%AB.html</url>
    <content type="text"><![CDATA[之前对两者有一点模糊，后来看看文档之后也慢慢熟悉了一部分，也知道了这两者区别，后来看到下面这个哥们的文章，貌似总结的比我更全面，就直接转载了 转载自这个哥们的文章最早的疑问就是同样都是公网地址，同样都是可变动的IP，两者差别在哪里，后来看过不少国外作者的书也介绍了一部分，主要差别如下 1.隶属对象EIP 是属于某个特定的账号，可以关联到账号的任意实例上，也可卸载下来重新关联到其他实例上，而且实例被删除之后，EIP 依然单独存在。(分配 EIP 时注意 VPC 和 EC2 的 EIP 的区别，不同类型的 EIP 时能关联到自己类型的实例上，即 VPC 中的 EIP 只能用于 VPC 中的实例，Classic EC2 只能关联非 VPC 的 EIP ） 2.作用范围而普通的 Public IP 是属于具体的某台实例，不能卸载重新关联到别的实例，实例创建时，如果勾选自动分配 Public IP，则会随实例一起被创建，实例删除时，跟着被删除，无法被重复利用和保留； 3.重启变动还有一个非常重要的特性：Public IP 在实例关机后再开机，可能会改变，重启不影响（这跟 Classic EC2 实例的 Public DNS 一样，可能会改变）。而 EIP 怎么都不会变。 4.冲突生效如果实例创建之初，有 PublicIP ,然后再关联了 Elastic IP 的话，二者都会变成 Elastic IP 的样子（被覆盖），当 EIP 被解除关联之后，Public IP 才会被显露，但此时会重新分配 Public IP，所以 Public IP 会变。 所以，如果在EC2实例的生命周期内，有停机再开机的可能，还是使用EIP比较保险]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>aws elastic ip</tag>
        <tag>aws public ip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS API boto采坑]]></title>
    <url>%2Fnote%2F%E4%BA%91_AWS-API-boto%E9%87%87%E5%9D%91.html</url>
    <content type="text"><![CDATA[想打你一顿，也想抱抱你，想问你怎么还不来找我。愿你爱的人，最后住进你的人生。 从零开始接触AWS，走过不少弯路，进步缓慢，仅将吃过的亏写出来，以供后面的朋友避开弯路，快速上手。通过 aws 提供的 api 可以很方面的弄出我们自己的平台出来，所以这几天一直看这方面的东西，在此期间感谢灿哥的帮助，忍受了我很低级的问题，回头请你吃鱼，哈哈，话不多说，走了很多弯路，所以记录下，供有相关方面的朋友参考下 我只会一点点 python，所以需要一个开发环境封装好了 aws 的 api，即 sdk ，官方也写明了 boto，关于 boto，请看 https://boto.readthedocs.org/en/stable/) 1.1 连接1.创建连接 &gt;&gt;&gt; import boto&gt;&gt;&gt; ec2_conn = boto.connect_ec2(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)&gt;&gt;&gt; conn = boto.ec2.connect_to_region("us-west-2") 起初我并没理解 conn 是啥，后来仔细看官方给出的解释，就是 conn 是 EC2Connection 类的实例化，关于 EC2Connection 中的方法，可以通过 dir(conn) 或者 文档 来进行查看。通过其中提供的方法，可以获得 ec2 的各个信息，下面开始 2.获取 instance_id、security_group等 &gt;&gt;&gt; import boto&gt;&gt;&gt; ec2_conn = boto.connect_ec2(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)&gt;&gt;&gt; conn = boto.ec2.connect_to_region("us-west-2")&gt;&gt;&gt; reservation = conn.get_all_instances()&gt;&gt;&gt; print reservation返回类似如下[Reservation:r-fee7019f，Reservation: ....]&gt;&gt;&gt; print reservation[0].instances[0]Instance:i-19dxxxxx&gt;&gt;&gt; print reservation[0].instances[0].idi-19dxxxxx 最开始最糊涂的就是这个 reservation 了，返回给我的是一个 Reservation 对象，开始死活没明白，为什么返回给我这个，而后才知道，reservation 其实类似与一个容器，里面包含了返回来的所有的 ec2 这个主机的信息，非常全面，个人理解如果是直接返回，会导致整个屏幕都无法显示，也不利于查看和进行正则，所以 boto 对这些信息进行了一层封装成一个对象，需要取出数据直接从该对象中取出即可 # 返回 reservation 中所有的 instances id 列表instances = []for r in reservations: instances.extend(r.instances)# 简洁写法[i for r in reservation for i in r.instances]# 以此类推如果是取得 reservation 中的所有 security group 或者其他信息，那么可以使用[i for r in reservation for i in r.groups] 如果想查看 instance 里的各种属性，请自行 dir(reservation[0].instances[0]) 或者是 help(reservation[0].instances[0]) 3.获取主机状态 这里只是暂且展现三列，reservation id、instance id、instance state，其余信息相同In [85]: for r in reservation: ....: for i in r.instances: ....: print r.id, i.id, i.state 1.2 条件过滤 上面的过滤方式也是一种，但是 boto 提供了从 get_all_instances 直接进行过滤的写法，即 filters，文档详细见 这里 ，关注其中的 filters 部分 &gt;&gt;&gt; reservation = conn.get_all_instances(filters=&#123;‘’ : ‘’&#125;) 这里尤为注意，filters 只接受字典的过滤方式，字典的形式，可以提供多个 key:value 形式的过滤条件 1.过滤instance id &gt;&gt;&gt; reservation = conn.get_all_instances(filters=&#123;‘instance_id’ : ‘i-xxxxxx’&#125;) 2.过滤状态 &gt;&gt;&gt; reservation = conn.get_all_instances(filters=&#123;‘instance-state-code’ : 16&#125;)&gt;&gt;&gt; reservation = conn.get_all_instances_state(filters=&#123;‘instance-state-name’ : ‘running’&#125;)... 关与 state code，aws 在后台判断一个实例的状态是通过 state code，而不是 state name，具体每个 code 对应的 value ，官方规定如下：The valid values are: 0 (pending), 16 (running), 32 (shutting-down), 48 (terminated), 64 (stopping), 80 (stopped) 关于状态， ec2 总共有以下几种状态 1.3 创建实例手里有 《python and aws cookbook》，看完了其中的部分内容，按照里面进行的内容走不通了，豁然找到官方文档对比，发觉很多接口参数已经变化了，所以被坑了很久，最终还是读读官方文档或者是 help() 里的内容 创建实例 conn = boto.ec2.connect_to_region(region, aws_access_key_id=aws_id, aws_secret_access_key=aws_key)help(conn.run_instances)run_instances(image_id, min_count=1, max_count=1, key_name=None, security_groups=None, user_data=None, addressing_type=None, instance_type='m1.small', placement=None, kernel_id=None, ed=False, subnet_id=None, block_device_map=None, disable_api_termination=False, instance_initiated_shutdown_behavior=None, private_ip_address=None, placemensecurity_group_ids=None, additional_info=None, instance_profile_name=None, instance_profile_arn=None, tenancy=None, ebs_optimized=False, network_interfaces= 目前不需要知道所有参数，只需要基本使用的 image_id：AMI ID，这个好理解 min_count：最小创建实例数量 max_count：最大创建实例数量，说实话，真没理解为什么是两个，而不是一个 security_groups：安全组，至于每种类型啥意思，哪种特点，得去看文档 instance_type：实例类型，各种类型详细参数请看帮助* t1.micro * m1.small * m1.medium * m1.large * m1.xlarge * m3.medium * m3.large * m3.xlarge * m3.2xlarge * c1.medium * c1.xlarge * m2.xlarge * m2.2xlarge * m2.4xlarge * cr1.8xlarge * hi1.4xlarge * hs1.8xlarge * cc1.4xlarge * cg1.4xlarge * cc2.8xlarge * g2.2xlarge * c3.large * c3.xlarge * c3.2xlarge * c3.4xlarge * c3.8xlarge * i2.xlarge * i2.2xlarge * i2.4xlarge * i2.8xlarge * t2.micro * t2.small * t2.medium private_ip_address：内网地址，可以指定 dry_run：如果操作不实际运行，那么就设置为真，一般情况下，此项都是设置 False 所以，创建一个实例，直接通过最小化参数 run.instances(AMI)仅此一项即可，当然了，如果是实际投入使用，一项是肯定不够的一般我的创建都是run_instances( AMI, instance_type=INSTANCES_TYPE, security_groups=['default’]) 1.4 给实例打标签 这里后来看了帮助之后才发觉增添标签也有两种方式 add_tag 和 add_tags, 还是一直没明白 aws 提供了两种方法来进行打 tag，不过两种方法我最直观的用处就是为后面的 filters 直接上代码conn = boto.ec2.connect_to_region(region, aws_access_key_id=aws_id, aws_secret_access_key=aws_key)reservation = conn.get_all_instances()instance = reservation[0].instances[0]# 第一种增加 tag 方法# 传参格式： add_tag(self, key, value='', dry_run=False)instance.add_tag(key='Name', value='test') //key 和 value 都必须是字符串instance.add_tag('test') //仅增加 key# 第二种增加 tags 方法传参格式： add_tags(self, tags, dry_run=False)instance.add_tags(&#123;'name' : 'test'&#125;) //传参必须是一个 dict# 移除 tag，格式同增加相同remove_tag(self, key, value=None, dry_run=False)remove_tags(self, tags, dry_run=False)# filtersreservations = conn.get_all_instances(filters=&#123;'tag-key': 'name', 'tag-value': 'test'&#125;)print reservations[0].instances[0] 最终就得到了我们创建的 tag 的 instances 的信息了，这里吃了不少坑，书里写的可能因为时间关系已经不对了，Google 上找少有直接说明这个问题的，最后只有 stackoverflow 上有一个哥们提到了 tag 格式的问题，没有注意到，希望后面的需要的朋友注意]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>aws</tag>
        <tag>api</tag>
        <tag>boto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis 的复制]]></title>
    <url>%2Fnote%2Fdb_redis%E7%9A%84%E5%A4%8D%E5%88%B6.html</url>
    <content type="text"><![CDATA[最近碰了的一个线上问题，让我重新开始看看 redis 的复制，也算是重新认识下 redis 以及仔细了解下，话不多说，直接开始，部分内容摘抄 罗峰 的博客的这篇 redis 复制 一、什么是复制主从复制，当用户往 Master 端写入数据时，通过 Redis Sync 机制将数据文件发送至 Slave，Slave 也会执行相同的操作确保数据一致；且实现 Redis 的主从复制非常简单。 二、redis 复制的特点 1、同一个 Master 可以拥有多个 Slaves。 2、Master 下的 Slave 还可以接受同一架构中其它 slave 的链接与同步请求，实现数据的级联复制，即 Master-&gt;Slave-&gt;Slave 模式； 3、Master 以非阻塞的方式同步数据至 slave，这将意味着 Master 会继续处理一个或多个 slave 的读写请求； 4、Slave 端同步数据也可以修改为非阻塞是的方式，当 slave 在执行新的同步时，它仍可以用旧的数据信息来提供查询；否则，当 slave 与 master 失去联系时，slave 会返回一个错误给客户端； 5、主从复制具有可扩展性，即多个 slave 专门提供只读查询与数据的冗余，Master 端专门提供写操作； 6、通过配置禁用 Master 数据持久化机制，将其数据持久化操作交给 Slaves 完成，避免在 Master 中要有独立的进程来完成此操作。 三、redis 复制原理3.1 主从复制原理允许我可耻的把大峰哥的图也扒下来了，大致的复制过程入上图。 当启动一个 Slave 进程后，它会向 Master 发送一个 SYNC Command，请求同步连接。无论是第一次连接还是重新连接，Master 都会启动一个后台进程，将数据快照保存到数据文件中，同时 Master 会记录所有修改数据的命令并缓存在数据文件中。具体处理函数如下图 后台进程完成缓存操作后，Master 就发送数据文件给 Slave，Slave 端将数据文件保存到硬盘上，然后将其在加载到内存中，接着 Master 就会所有修改数据的操作，将其发送给 Slave 端。若 Slave 出现故障导致宕机，恢复正常后会自动重新连接，Master 收到 Slave 的连接后，将其完整的数据文件发送给 Slave，如果 Mater 同时收到多个 Slave 发来的同步请求，Master 只会在后台启动一个进程保存数据文件，然后将其发送给所有的 Slave，确保Slave 正常。下面来个详细版的全图 3.2 补充 redis 2.8 版本之后，主从同步机制发生了一些变化，参考阅读《redis 设计与实现》第二版 redis 复制功能分为同步（sync）和命令传播（command propagate）两个操作 同步将从 slave 数据库状态更新至和 master 当前的数据库状态 命令传播则用于在 master 状态被修改，导致主从不一致时候，让主从重新回到一直的状态的作用 旧版本复制功能的缺陷 初次复制slave 之前没有复制过任何 master，或者当 slave 当前要复制的 master 和上次复制的 master 不同 断线后重新复制：处于命令传播阶段的 master 因为一些原因中断了复制，但是 slave 通过自动重连连接上了 master，并继续复制 master。虽然断线后重连，但是 master 会向 slave 从头发送一份包含所有 key 的 rdb 文件给 slave，而往往 slave 中已经包含了部分 key。为了弥补断线产生的丢失的数据，重新连线上来的 slave， master 重新又做一次完整的 sync 无疑是非常低效的 先来看看 fsync 做了什么 每次执行 fsync 命令，redis 得做如下事情 master 需要执行 BGSAVE 命令来生成 RDB 文件，这个生成操作会耗费 master 大量的 CPU、内存和磁盘 I/O 资源 master 要讲自己生成的 RDB 文件发送给 slave ，这个发送会耗费大量的网络带宽和流量，并且对 master 服务响应产生一定的影响 slave 接受到了这个 RDB，需要重载，载入期间会阻塞没法处理请求 所以综上 fsync 是一个相当耗费资源的操作 redis 2.8 + 新版本的复制功能 所以新版本处理断线重连那个机制上用 psync 命令替换了原有的 fsync 3.2 psync psync 具备 完整同步 和 部分同步 两种模式 完整同步：用于 slave 第一次进行复制的时候，这个时候和 fsync 效果是一样的，一次完整的 fsync ，发送完整的 RDB 文件，以及发送缓冲区的命令等 部分同步：部分同步用于处理断线后重连的情况，当 slave 断线重连后，如果条件合适，master 只发送断线期间的写操作命令给 slave，下面用一个图简单解释下 psync 工作过程 psync 部分模式有下面几个部分组成 master 复制偏移量（replication offset）： master 复制积压缓冲区（replication backlog） 服务器运行 ID（run id） 就是这个部分同步解决了 2.8 版本之前旧复制模式的缺陷，具体的 pysnc 实现过程，可以阅读《redis 设计与实现》中有更为详细的说明 3.3 主从同步的过程根据 2.8 之后的改进完整的列出 2.8 版本之后的主从同步概况 1、设置 master 地址和端口 当 slave 接受到从客户端设置 slaveof 之后，或者启动配置文件里指定之后，将会把 IP 和端口保存在服务器状态的 master host 属性和 masterport 属性里，并且向客户端返回 ok 2、建立套接字连接 slaveof 命令执行之后，slave 根据命令所设置，创建连向 master 的套接字连接。一旦套接字成功连接，slave 会为复制分配一个文件事件处理器处理后续复制相关工作，master 则会把 slave 看做是自己的客户端对待，具体流程如下图 3、发送 PING 命令 当套接字建立后，第一件事 slave 机会向 master 发送一个 PING 命令，这个命令有如下作用 检测套接字读写是否正常 检测 master 是否能正常处理请求 如果 master 响应并返回命令回复，但是 slave 没法在规定时间读取命令回复内容，表示主从网络状态不佳，出现这种情况，slave 会断开并重新创建连向 master 的套接字 如果 master 响应并返回一个错误，表示 master 暂且没法处理 slave 的命令请求，不能继续执行复制工作的后续，当出现这种情况，slave 断开并重新创建连向 master 的套接字。 如果 slave 接受到 PONG 回复，表示主从网络状态正常，可以正常处理 slave 的请求，复制可以继续 4、身份验证 收到 PONG 之后，就进入身份验证阶段 如果 slave 设置了 masterauth 则进行身份验证 如果 slave 没设置，那么不进行验证 需要身份验证的情况下，slave 向 master 发送一条 AUTH 命令，命令参数为 slave 设置的 masterauth 选项的值，验证阶段可能碰到一下情况 如果 master 没有配置 requirepass 选项，并且 slave 上也没有设置 masterauth 那么就没有验证，复制工作继续执行 如果 slave 发送了 AUTH 命令发送的密码和 master 上配置的相同，通过验证，复制继续，如果密码错误，返回 invalid password 如果 master 设置了 requirepass 选项，slave 没有设置 masterauth 选项，那么 master 会返回一个 NOAUTH 错误 如果 master 没设置 requirepass 选项，但是 slave 却设置了 masterauth 选项，那么 master 又会返回 no password is set 错误，一旦出现错误，主从复制不执行 5、发送端口信息 身份验证通过之后，slave 将执行命令 REPLCONF listening-port * 向 master 发送自己的监听端口号 master 接受到这个命令后，会将端口号记录在 slave 对应的客户端状态的 slave_listening-port 属性里，该属性可以通过客户端命令查看 127.0.0.1:7000&gt; INFO replication# Replicationrole:slavemaster_host:127.0.0.1master_port:6000master_link_status:upmaster_last_io_seconds_ago:0master_sync_in_progress:0slave_repl_offset:29slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 6、同步 这一步，slave 将向 master 发送 PSYNC 命令，执行同步操作，将自己的状态更新至和 master 当前所处的状态，这里有两种状态的变化 如果 psync 命令执行的是完整同步操作，那么 master 需要成为 slave 的客户端，才能将保存在缓冲区里面的写命令发送给 slave 如果 psync 命令执行的是部分同步操作，那么 master 必须成为 slave 的客户端，才能向 slave 发送复制积压缓冲区的写命令 这里可以用下图表明两者状态的变化 7、命令传播 完成同步之后，master 就会进入命令传播阶段，这时候 master 只要一直将自己执行的写命令发送给 slave，slave 只要一直接受并执行 master 发送来的写命令，就可以保证主从服务器保持一致了 四、主从复制4.1、slave 下面用两台 redis 来验证上面的理论，这里采用 redis 2.8.20 作为演示版本 主从配置比较简单，一种直接写配置文件，一种直接命令行配置 1、命令行127.0.0.1:6379&gt; SLAVEOF 172.16.178.128 6379OK2、配置文件# slaveof &lt;masterip&gt;&lt;masterport&gt;slaveof 192.168.8.8 6379 这样一个主从复制就配置完成了，当然了这个肯定不行，刚才前台输出信息，可以看到一旦配置了 slaveof 之后就会出现如下信息 [4161] 30 May 19:11:01.341 * SLAVE OF 172.16.178.128:6379 enabled (user request)[4161] 30 May 19:11:02.309 * Connecting to MASTER 172.16.178.128:6379[4161] 30 May 19:11:02.309 * MASTER &lt;-&gt; SLAVE sync started[4161] 30 May 19:11:02.310 * Non blocking connect for SYNC fired the event.[4161] 30 May 19:11:02.311 * Master replied to PING, replication can continue...[4161] 30 May 19:11:02.311 * Partial resynchronization not possible (no cached master)[4161] 30 May 19:11:02.312 * Full resync from master: 0d7eef5f1941e4d09e10caa02d27094ff785ca42:1[4161] 30 May 19:11:02.411 * MASTER &lt;-&gt; SLAVE sync: receiving 18 bytes from master[4161] 30 May 19:11:02.412 * MASTER &lt;-&gt; SLAVE sync: Flushing old data[4161] 30 May 19:11:02.412 * MASTER &lt;-&gt; SLAVE sync: Loading DB in memory[4161] 30 May 19:11:02.412 * MASTER &lt;-&gt; SLAVE sync: Finished with success 4.2、master 上 刚才的 slave 配置之后就可以看到 master 也输出了信息，我们看到互相对应 [4025] 30 May 19:11:02.308 * Slave 172.16.178.129:6379 asks for synchronization[4025] 30 May 19:11:02.308 * Full resync requested by slave 172.16.178.129:6379[4025] 30 May 19:11:02.309 * Starting BGSAVE for SYNC with target: disk[4025] 30 May 19:11:02.309 * Background saving started by pid 4065[4065] 30 May 19:11:02.320 * DB saved on disk[4065] 30 May 19:11:02.321 * RDB: 0 MB of memory used by copy-on-write[4025] 30 May 19:11:02.408 * Background saving terminated with success[4025] 30 May 19:11:02.408 * Synchronization with slave 172.16.178.129:6379 succeeded 4.3、数据同步 这里演示的库是空，master 上增加 key 操作，查看输出日志 master 上会出现如下输出[4025] 30 May 20:46:48.454 * 1 changes in 3600 seconds. Saving...[4025] 30 May 20:46:48.455 * Background saving started by pid 4122[4122] 30 May 20:46:48.457 * DB saved on disk[4122] 30 May 20:46:48.458 * RDB: 0 MB of memory used by copy-on-write[4025] 30 May 20:46:48.556 * Background saving terminated with success slave 上的信息[4161] 30 May 20:46:48.465 * 1 changes in 3600 seconds. Saving...[4161] 30 May 20:46:48.467 * Background saving started by pid 4240[4240] 30 May 20:46:48.477 * DB saved on disk[4240] 30 May 20:46:48.477 * RDB: 0 MB of memory used by copy-on-write[4161] 30 May 20:46:48.568 * Background saving terminated with success 上面这两段信息即可验证了上面的理论，也同时看到数据同步到 slave 上，完成了一次复制操作 五、读写分离和安全5.1 读写分离 通过复制可以实现读写分离提高服务器负载能力，master 只负责写，多个 slave 可以负责读 并且 master 上禁用持久化，slave 上开启持久化 5.2 安全1、绑定信任地址 redis 是设计是在 “redis 运行在可信环境” 前提下做出的，所以默认 redis 会接受来自任何地址发送过来的请求，可以通过 bind 实现绑定地址 bind 127.0.0.1 X.X.X.X 2.8 之前的版本只能绑定一个地址，2.8 之后的版本可以绑定多个地址 2、为 redis 设置一个密码 requirepass *************** 这样客户端每次连接都需要输入 &gt; AUTH *********** 才可以正常连接使用 如果上面的配置是在主从环境下的 master 上，那么 slave 也必须在配置里写明才能正常的复制 master masterauth ************ 3、特殊命令设置别名 有些特殊的命令，如 FLUSHALL 这类命令相当危险，可以设置一个复杂的别名，可以将此别名写入程序调用，这样手动输出命中的概率很低 rename-command FLUSHALL kafhksdhfkhsakfhasdklhfklsa 参考链接 redis主从复制 redis replication 中文 redis replication doc 《redis 设计与实现》第二版]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>redis的复制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AWS Command Line Interface]]></title>
    <url>%2Fnote%2F%E4%BA%91_AWS-Command-Line-Interface.html</url>
    <content type="text"><![CDATA[自从来到新单位之后开始接触 AWS， 遂开始研究下这东西，目前从 Web interface 可以完成了日常的一些功能，就是通过命令行，或者 API 来完成，一开始看 API 有点晕，还是先从简单的命令行工具开始 根据文档 AWS CLI User Guide 上介绍，cli 是管理服务和云主机的统一工具，是对 api 进行了封装之后，可以在自动化以及脚本中使用的命令行工具，关于 cli 的源码在 这里 一、准备1.注册注册网址 这里 ，注册的过程中会有电话过来，英文的，不过不用理会，其实就是让你输入 pin码，注册完之后会收到一封亚马逊的确认邮件 2.获取 access key ID 和 secret access key 这两部分都是 access key 的组成部分，那么 access key 就是用来确保程序请求的，这里官方补充了一句，推荐使用 IAM 的 access key 来替代 root 账户的 access key，IAM 用来确保安全的来访问 AWS 服务资源，关于具体啥是 IAM，请直接点击查看官方文档 打开 IAM console 选择 Users，在用户选择指定的用户 单击 User Actions, 选择 Manage Access Keys. 选择 Create Access Key. Your keys will look something like this: Access key ID 类似于: AKIAIOSFODNN7EXAMPLESecret access key 类似于: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY 而后就可以下载，保存好即可 相关主题：What Is IAM?AWS Security Credentials 二、安装我这里是 os x 的平台，所以安装方式也可以有很多种，pip 、bundled等，为了方便，我用了 pip 进行安装 $ sudo pip install awscli$ aws help 自动补全的功能# 在我这里安装的脚本中附带一个自动补全的脚本，针对用户不同的shell环境进行补全$ source /usr/local/bin/aws_zsh_completer.sh 1.快速开始 $ aws configureAWS Access Key ID [None]: AWS Secret Access Key [None]: Default region name [None]: us-west-1Default output format [None]: json 注意：有个注意的地方就是 地区（region）一定要指出，如果不写，默认的地区是 us-east-1 ，更多的确请参考 Regions and Endpoints，output format 也是必选项，如果不指，则默认使用 json 2.多配置文件登录 /etc/boto.cfg - 全局配置文件，针对所有用户 ~/.boto - 用户的配置文件 ~/.aws/credentials - 认证配置文件 $ aws configure --profile user2~/.aws/credentials[default]aws_access_key_id= xxxaws_secret_access_key=xxx[user2]aws_access_key_id=xxxaws_secret_access_key=xxx~/.aws/config[default]region=us-west-1output=json[profile user2]region=us-east-1output=text 到此基本设置算是结束了，就可以开始使用 CLI 进行命令行操作了]]></content>
      <categories>
        <category>AWS</category>
      </categories>
      <tags>
        <tag>aws cli</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb sharding]]></title>
    <url>%2Fnote%2Fdb_mongodb-sharding.html</url>
    <content type="text"><![CDATA[依旧来自于 Lanceyan, 进行摘抄，加工，再次感谢这个哥们，连同图片我都可耻的粘下来了 在系统早期，数据量还小的时候不会引起太大的问题，但是随着数据量持续增多，后续迟早会出现一台机器硬件瓶颈问题的。而mongodb主打的就是海量数据架构,“分片”就用这个来解决这个问题 shading 是一种将海量数据水平扩展的集群系统，数据分区表存储在各个节点上，通过 shading 可以增加更多的机器来应对不断增加的数据和负载 mongodb的数分块称为chunk，每个chunk 都是 collection 中的一段连续的记录，通常尺寸是200M，超出则生成新的数据块 上图中有个TDDL，是taobao的一个数据访问层组件，他主要的作用是SQL解析、路由处理。根据应用的请求的功能解析当前访问的sql判断是在哪个业务数据库、哪个表访问查询并返回数据结果。具体如图： 说了这么多传统数据库的架构，那Nosql怎么去做到了这些呢？mysql要做到自动扩展需要加一个数据访问层用程序去扩展，数据库的增加、删除、备份还需要程序去控制。一但数据库的节点一多，要维护起来也是非常头疼的。不过mongodb所有的这一切通过他自己的内部机制就可以搞定！顿时石化了，这么牛X！还是上图看看mongodb通过哪些机制实现路由、分片： 从图中可以看到有四个组件：mongos、config server、shard、replica set。 mongos ：数据库集群请求的入口，所有的请求都通过mongos进行协调，不需要在应用程序添加一个路由选择器，mongos自己就是一个请求分发中心，它负责把对应的数据请求请求转发到对应的shard服务器上。在生产环境通常有多mongos作为请求的入口，防止其中一个挂掉所有的mongodb请求都没有办法操作。 config server，顾名思义为配置服务器，存储所有数据库元信息（路由、分片）的配置。mongos本身没有物理存储分片服务器和数据路由信息，只是缓存在内存里，配置服务器则实际存储这些数据。mongos第一次启动或者关掉重启就会从 config server 加载配置信息，以后如果配置服务器信息变化会通知到所有的 mongos 更新自己的状态，这样 mongos 就能继续准确路由。在生产环境通常有多个 config server 配置服务器，因为它存储了分片路由的元数据，这个可不能丢失！就算挂掉其中一台，只要还有存货， mongodb集群就不会挂掉。 shard，这就是传说中的分片了。上面提到一个机器就算能力再大也有天花板，就像军队打仗一样，一个人再厉害喝血瓶也拼不过对方的一个师。俗话说三个臭皮匠顶个诸葛亮，这个时候团队的力量就凸显出来了。在互联网也是这样，一台普通的机器做不了的多台机器来做，如下图： 一台机器的一个数据表 Collection1 存储了 1T 数据，压力太大了！在分给4个机器后，每个机器都是256G，则分摊了集中在一台机器的压力。也许有人问一台机器硬盘加大一点不就可以了，为什么要分给四台机器呢？不要光想到存储空间，实际运行的数据库还有硬盘的读写、网络的IO、CPU和内存的瓶颈。在mongodb集群只要设置好了分片规则，通过mongos操作数据库就能自动把对应的数据操作请求转发到对应的分片机器上。在生产环境中分片的片键可要好好设置，这个影响到了怎么把数据均匀分到多个分片机器上，不要出现其中一台机器分了1T，其他机器没有分到的情况，这样还不如不分片！ replica set，上两节已经详细讲过了这个东东，怎么这里又来凑热闹！其实上图4个分片如果没有 replica set 是个不完整架构，假设其中的一个分片挂掉那四分之一的数据就丢失了，所以在高可用性的分片架构还需要对于每一个分片构建 replica set 副本集保证分片的可靠性。生产环境通常是 2个副本 + 1个仲裁。 Lab首先通过单台机器上的 sharing 对分片有个直观的印象，然后对这种分片架构进行合理性讨论 规划如下: mongos config server shard server 40000 30000 20000,20001 1.首先启动sharding server./mongodb/bin/mongod --shardsvr --port 20000 --dbpath /data/shard/s0 --fork --logpath /data/shard/log/so.log./mongodb/bin/mongod --shardsvr --port 20001 --dbpath /data/shard/s1 --fork --logpath /data/shard/log/s1.log2.启动config server./mongodb/bin/mongod --shardsvr --port 30000 --dbpath /data/shard/config/ --fork --logpath /data/shard/log/config.log3.最后启动mongos路由进程,这里使用chunkSize 指定1M也是为了测试使用./mongodb/bin/mongos --port 40000 --configdb 127.0.0.1:30000 --fork --logpath /data/shard/log/route.log --chunkSize 14.开始设置sharding，连接mongos[root@node128 ~]# ./mongodb/bin/mongo admin --port 40000MongoDB shell version: 2.6.4connecting to: 127.0.0.1:40000/adminWelcome to the MongoDB shell.For interactive help, type "help".For more comprehensive documentation, see http://docs.mongodb.org/Questions? Try the support group http://groups.google.com/group/mongodb-user 增加sharding server mongos&gt; db.runCommand(&#123;addshard:'127.0.0.1:20000'&#125;)&#123; "shardAdded" : "shard0000", "ok" : 1 &#125;mongos&gt; db.runCommand(&#123;addshard:'127.0.0.1:20001'&#125;)&#123; "shardAdded" : "shard0001", "ok" : 1 &#125; 对test 库进行分片 mongos&gt; db.runCommand(&#123;enablesharding:'test'&#125;)&#123; "ok" : 1 &#125; 设置片键 mongos&gt; db.runCommand(&#123;shardcollection:'test.users',key:&#123;_id:1&#125;&#125;)&#123; "collectionsharded" : "test.users", "ok" : 1 &#125; 测试，插入数据 mongos&gt; use testswitched to db testmongos&gt; for (var i=1;i&lt;50000;i++) db.users.insert(&#123;age:1,name:'testname',addr:'bj',country:'china'&#125;)WriteResult(&#123; "nInserted" : 1 &#125;) 查看分片状态 mongos&gt; db.users.stats()&#123; "sharded" : true, //开启分片 "systemFlags" : 1, "userFlags" : 1, "ns" : "test.users", "count" : 49999, "numExtents" : 11, "size" : 5599888, "storageSize" : 13975552, "totalIndexSize" : 1643376, "indexSizes" : &#123; "_id_" : 1643376 //shard key &#125;, "avgObjSize" : 112, "nindexes" : 1, "nchunks" : 7, "shards" : &#123; //具片信息 "shard0000" : &#123; "ns" : "test.users", "count" : 33927, "size" : 3799824, "avgObjSize" : 112, "storageSize" : 11182080, "numExtents" : 6, "nindexes" : 1, "lastExtentSize" : 8388608, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 1111936, "indexSizes" : &#123; "_id_" : 1111936 &#125;, "ok" : 1 &#125;, "shard0001" : &#123; "ns" : "test.users", "count" : 16072, "size" : 1800064, "avgObjSize" : 112, "storageSize" : 2793472, "numExtents" : 5, "nindexes" : 1, "lastExtentSize" : 2097152, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 531440, "indexSizes" : &#123; "_id_" : 531440 &#125;, "ok" : 1 &#125; &#125;, "ok" : 1&#125; 物理文件分布状态 [root@node128 ~]# ll /data/shard/s0total 163872drwxr-xr-x 2 root root 4096 Dec 1 16:33 journal-rw------- 1 root root 67108864 Dec 1 16:21 local.0-rw------- 1 root root 16777216 Dec 1 16:21 local.ns-rwxr-xr-x 1 root root 5 Dec 1 16:21 mongod.lockdrwxr-xr-x 3 root root 4096 Dec 1 16:44 moveChunk-rw------- 1 root root 67108864 Dec 1 16:44 test.0-rw------- 1 rootroot 16777216 Dec 1 16:44 test.nsdrwxr-xr-x 2 root root 4096 Dec 1 16:33 _tmp[root@node128 ~]# ll /data/shard/s1total 163868drwxr-xr-x 2 root root 4096 Dec 1 16:44 journal-rw------- 1 root root 67108864 Dec 1 16:24 local.0-rw------- 1 root root 16777216 Dec 1 16:24 local.ns-rwxr-xr-x 1 root root 5 Dec 1 16:24 mongod.lock-rw------- 1 root root 67108864 Dec 1 16:44 test.0-rw------- 1 root root 16777216 Dec 1 16:44 test.nsdrwxr-xr-x 2 root root 4096 Dec 1 16:44 _tmp 显示分片信息概况 mongos&gt; db.runCommand(&#123;listshards:1&#125;)&#123; "shards" : [ &#123; "_id" : "shard0000", "host" : "127.0.0.1:20000" &#125;, &#123; "_id" : "shard0001", "host" : "127.0.0.1:20001" &#125; ], "ok" : 1&#125; 输出分片状态详细信息 mongos&gt; printShardingStatus()--- Sharding Status --- sharding version: &#123; "_id" : 1, "version" : 4, "minCompatibleVersion" : 4, "currentVersion" : 5, "clusterId" : ObjectId("547c275a439f21faea455c07")&#125; shards: &#123; "_id" : "shard0000", "host" : "127.0.0.1:20000" &#125; &#123; "_id" : "shard0001", "host" : "127.0.0.1:20001" &#125; databases: &#123; "_id" : "admin", "partitioned" : false, "primary" : "config" &#125; &#123; "_id" : "test", "partitioned" : true, "primary" : "shard0000" &#125; test.users shard key: &#123; "_id" : 1 &#125; chunks: shard0001 3 shard0000 4 &#123; "_id" : &#123; "$minKey" : 1 &#125; &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a66208bba868e9c35dd") &#125; on : shard0001 Timestamp(2, 0) &#123; "_id" : ObjectId("547c2a66208bba868e9c35dd") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a6e208bba868e9c4a6e") &#125; on : shard0001 Timestamp(3, 0) &#123; "_id" : ObjectId("547c2a6e208bba868e9c4a6e") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a74208bba868e9c74a5") &#125; on : shard0001 Timestamp(4, 0) &#123; "_id" : ObjectId("547c2a74208bba868e9c74a5") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a7c208bba868e9ca17d") &#125; on : shard0000 Timestamp(4, 1) &#123; "_id" : ObjectId("547c2a7c208bba868e9ca17d") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a82208bba868e9cca09") &#125; on : shard0000 Timestamp(3, 4) &#123; "_id" : ObjectId("547c2a82208bba868e9cca09") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547c2a8a208bba868e9cf613") &#125; on : shard0000 Timestamp(4, 2) &#123; "_id" : ObjectId("547c2a8a208bba868e9cf613") &#125; --&gt;&gt; &#123; "_id" : &#123; "$maxKey" : 1 &#125; &#125; on : shard0000 Timestamp(4, 3) 判断是否分片 mongos&gt; db.runCommand(&#123;isdbgrid:1&#125;)&#123; "isdbgrid" : 1, "hostname" : "node128", "ok" : 1 &#125; 对已有库进行分片 mongos&gt; db.runCommand({shardcollection:&apos;test.user_2&apos;,key:{_id:1}}) 查看当前库的状态 mongos&gt; db.user_2.stats()&#123; "sharded" : false, "primary" : "config", "ok" : 0, "errmsg" : "Collection [admin.user_2] not found."&#125; 上面的使用中，对sharding 已经算是有了直观的了解，但是通过上面的我们可以看到每个sharding server 为单一节点单一实例，没有备份，一旦一个节点 down， 数据就会丢失一半，所以这是个不完善的架构，所以真正投入生产环境使用肯定要结合复制集进行数据的多份，下面就是进行 复制集 + 分片集 更为完善的的mongodb sharing 架构首先确定各个组件的数量，mongos 3个， config server 3个，数据分片 shard server 2个，每个shard 为一个复制集，。这些实例可以部署在独立机器也可以部署在一台机器，我们这里测试资源有限，只准备了 3台机器，在同一台机器只要端口不同就可以，看一下物理部署图，这里部署的时候我省略了仲裁节点 主机 IP 实例 node128 172.16.105.128 mongod shard1_1:27017, mongod shard2_1:27018, mongod config1:20000, mongos1:30000 node129 172.16.105.129 mongod shard1_2:27017, mongod shard2_2:27018, mongod config2:20000, mongos2:30000 node130 172.16.105.130 mongod shard1_3:27017, mongod shard2_3:27018, mongod config3:20000, mongos3:30000 [root@node128 ~]# mkdir -p /data/shard1_1[root@node128 ~]# mkdir -p /data/shard2_1[root@node128 ~]# mkdir -p /data/config[root@node129 ~]# mkdir -p /data/shard1_2[root@node129 ~]# mkdir -p /data/shard2_2[root@node129 ~]# mkdir -p /data/config[root@node130 ~]# mkdir -p /data/shard1_3[root@node130 ~]# mkdir -p /data/shard2_3[root@node130 ~]# mkdir -p /data/config start shard1启动sharding server [root@node128 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard1 --port 27017 --dbpath /data/shard1_1/ --logpath /data/shard1_1/shard1_1.log --logappend --fork[root@node129 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard1 --port 27017 --dbpath /data/shard1_2/ --logpath /data/shard1_2/shard1_2.log --logappend --fork[root@node130 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard1 --port 27017 --dbpath /data/shard1_3/ --logpath /data/shard1_3/shard1_3.log --logappend --fork 初始化复制集 [root@node128 ~]# ./mongodb/bin/mongo admin --port 27017&gt; config = &#123;_id: 'shard1', members:[&#123;_id:0, host:'172.16.105.128:27017'&#125;,&#123;_id:1, host:'172.16.105.129:27017'&#125;,&#123;_id:2, host:'172.16.105.130:27017'&#125;]&#125;&#123; "_id" : "shard1", "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27017" &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27017" &#125;, &#123; "_id" : 2, "host" : "172.16.105.130:27017" &#125; ]&#125;&gt; rs.initiate(config)&#123; "info" : "Config now saved locally. Should come online in about a minute.", "ok" : 1&#125; start shard2启动sharding server [root@node128 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard2 --port 27018 --dbpath /data/shard2_1/ --logpath /data/shard2_1/shard2_1.log --logappend --fork[root@node129 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard2 --port 27018 --dbpath /data/shard2_2/ --logpath /data/shard2_2/shard2_2.log --logappend --fork[root@node130 ~]# ./mongodb/bin/mongod --shardsvr --replSet shard2 --port 27018 --dbpath /data/shard2_3/ --logpath /data/shard2_3/shard2_3.log --logappend --fork 初始化复制集 [root@node129 ~]# ./mongodb/bin/mongo admin --port 27018&gt; config = &#123;_id: 'shard2', members:[&#123;_id:0, host:'172.16.105.128:27018'&#125;,&#123;_id:1, host:'172.16.105.129:27018'&#125;,&#123;_id:2, host:'172.16.105.130:27018'&#125;]&#125;&#123; "_id" : "shard2", "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27018" &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27018" &#125;, &#123; "_id" : 2, "host" : "172.16.105.130:27018" &#125; ]&#125;&gt; rs.initiate(config)&#123; "info" : "Config now saved locally. Should come online in about a minute.", "ok" : 1&#125; start config server启动config server [root@node128 ~]# ./mongodb/bin/mongod --configsvr --dbpath /data/config/ --port 20000 --logpath /data/config/config.log --logappend --fork[root@node129 ~]# ./mongodb/bin/mongod --configsvr --dbpath /data/config/ --port 20000 --logpath /data/config/config.log --logappend --fork[root@node130 ~]# ./mongodb/bin/mongod --configsvr --dbpath /data/config/ --port 20000 --logpath /data/config/config.log --logappend --fork start mongos[root@node128 ~]# ./mongodb/bin/mongos --configdb 172.16.105.128:20000,172.16.105.129:20000,172.16.105.130:20000 --port 30000 --chunkSize 1 --logpath /data/mongos.log --logappend --fork[root@node129 ~]# ./mongodb/bin/mongos --configdb 172.16.105.128:20000,172.16.105.129:20000,172.16.105.130:20000 --port 30000 --chunkSize 1 --logpath /data/mongos.log --logappend --fork[root@node130 ~]# ./mongodb/bin/mongos --configdb 172.16.105.128:20000,172.16.105.129:20000,172.16.105.130:20000 --port 30000 --chunkSize 1 --logpath /data/mongos.log --logappend --fork 加入sharding server [root@node130 ~]# ./mongodb/bin/mongo admin --port 30000mongos&gt; db.runCommand(&#123;addshard:"shard1/172.16.105.128:27017,172.16.105.129:27017,172.16.105.130:27017"&#125;)&#123; "shardAdded" : "shard1", "ok" : 1 &#125;mongos&gt; db.runCommand(&#123;addshard:"shard2/172.16.105.128:27018,172.16.105.129:27018,172.16.105.130:27018"&#125;)&#123; "shardAdded" : "shard2", "ok" : 1 &#125;# 开启分片的库mongos&gt; db.runCommand(&#123;enablesharding:"test"&#125;)&#123; "ok" : 1 &#125;# 设定片键mongos&gt; db.runCommand(&#123;shardcollection: "test.users", key:&#123;_id:1&#125;&#125;)&#123; "collectionsharded" : "test.users", "ok" : 1 &#125; testing sharding连接 mongos [root@node130 ~]# ./mongodb/bin/mongo --port 30000MongoDB shell version: 2.6.4connecting to: 127.0.0.1:30000/testmongos&gt; for (var i=1;i&lt;100000;i++) db.users.insert(&#123;id:1,addr_1:"beijing",addr_2:"shanghai"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;) 查看user表状态 mongos&gt; db.users.stats()&#123; "sharded" : true, "systemFlags" : 1, "userFlags" : 1, "ns" : "test.users", "count" : 99999, "numExtents" : 12, "size" : 11199888, "storageSize" : 22364160, "totalIndexSize" : 3532032, "indexSizes" : &#123; "_id_" : 3532032 &#125;, "avgObjSize" : 112, "nindexes" : 1, "nchunks" : 10, "shards" : &#123; "shard1" : &#123; "ns" : "test.users", "count" : 62595, "size" : 7010640, "avgObjSize" : 112, "storageSize" : 11182080, "numExtents" : 6, "nindexes" : 1, "lastExtentSize" : 8388608, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 2060352, "indexSizes" : &#123; "_id_" : 2060352 &#125;, "ok" : 1 &#125;, "shard2" : &#123; "ns" : "test.users", "count" : 37404, "size" : 4189248, "avgObjSize" : 112, "storageSize" : 11182080, "numExtents" : 6, "nindexes" : 1, "lastExtentSize" : 8388608, "paddingFactor" : 1, "systemFlags" : 1, "userFlags" : 1, "totalIndexSize" : 1471680, "indexSizes" : &#123; "_id_" : 1471680 &#125;, "ok" : 1 &#125; &#125;, "ok" : 1&#125; 列出分片信息 mongos&gt; db.runCommand(&#123; listshards:1&#125;)&#123; "shards" : [ &#123; "_id" : "shard1", "host" : "shard1/172.16.105.128:27017,172.16.105.129:27017,172.16.105.130:27017" &#125;, &#123; "_id" : "shard2", "host" : "shard2/172.16.105.128:27018,172.16.105.129:27018,172.16.105.130:27018" &#125; ], "ok" : 1&#125; 查询自身是否分片 mongos&gt; db.runCommand(&#123; isdbgrid:1 &#125;)&#123; "isdbgrid" : 1, "hostname" : "node130", "ok" : 1 &#125; 打印分片信息 mongos&gt; printShardingStatus()--- Sharding Status --- sharding version: &#123; "_id" : 1, "version" : 4, "minCompatibleVersion" : 4, "currentVersion" : 5, "clusterId" : ObjectId("547e9ac589c82a0fa41dec99")&#125; shards: &#123; "_id" : "shard1", "host" : "shard1/172.16.105.128:27017,172.16.105.129:27017,172.16.105.130:27017" &#125; &#123; "_id" : "shard2", "host" : "shard2/172.16.105.128:27018,172.16.105.129:27018,172.16.105.130:27018" &#125; databases: &#123; "_id" : "admin", "partitioned" : false, "primary" : "config" &#125; &#123; "_id" : "test", "partitioned" : true, "primary" : "shard1" &#125; test.users shard key: &#123; "_id" : 1 &#125; chunks: shard2 5 shard1 5 &#123; "_id" : &#123; "$minKey" : 1 &#125; &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb208e3c770f4eebe6031") &#125; on : shard2 Timestamp(2, 0) &#123; "_id" : ObjectId("547eb208e3c770f4eebe6031") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb211e3c770f4eebe73be") &#125; on : shard2 Timestamp(3, 0) &#123; "_id" : ObjectId("547eb211e3c770f4eebe73be") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb220e3c770f4eebe9961") &#125; on : shard2 Timestamp(4, 0) &#123; "_id" : ObjectId("547eb220e3c770f4eebe9961") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb235e3c770f4eebec6a9") &#125; on : shard2 Timestamp(5, 0) &#123; "_id" : ObjectId("547eb235e3c770f4eebec6a9") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb246e3c770f4eebef24d") &#125; on : shard2 Timestamp(6, 0) &#123; "_id" : ObjectId("547eb246e3c770f4eebef24d") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb264e3c770f4eebf2b38") &#125; on : shard1 Timestamp(6, 1) &#123; "_id" : ObjectId("547eb264e3c770f4eebf2b38") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb273e3c770f4eebf54b7") &#125; on : shard1 Timestamp(4, 4) &#123; "_id" : ObjectId("547eb273e3c770f4eebf54b7") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb298e3c770f4eebf9920") &#125; on : shard1 Timestamp(5, 2) &#123; "_id" : ObjectId("547eb298e3c770f4eebf9920") &#125; --&gt;&gt; &#123; "_id" : ObjectId("547eb2a8e3c770f4eebfc186") &#125; on : shard1 Timestamp(5, 4) &#123; "_id" : ObjectId("547eb2a8e3c770f4eebfc186") &#125; --&gt;&gt; &#123; "_id" : &#123; "$maxKey" : 1 &#125; &#125; on : shard1 Timestamp(5, 5) 打印分片信息 mongos&gt; sh.status() 输出状态如上 实际物理文件分布 [root@node128 ~]# tree /data/ -L 2/data/├── config│ ├── config.0│ ├── config.log│ ├── config.ns│ ├── journal│ ├── local.0│ ├── local.ns│ ├── mongod.lock│ └── _tmp├── mongos.log├── shard1_1│ ├── journal│ ├── local.0│ ├── local.1│ ├── local.ns│ ├── mongod.lock│ ├── moveChunk│ ├── shard1_1.log│ ├── test.0│ ├── test.ns│ └── _tmp└── shard2_1 ├── journal ├── local.0 ├── local.1 ├── local.ns ├── mongod.lock ├── shard2_1.log ├── test.0 ├── test.ns └── _tmp10 directories, 21 files其余节点就不一一列出 到这里一个可以投入使用的的mongodb 复制集 + sharding 基本完成，当然这上面的部分仍旧有缺陷，需要完善，后面继续进行 sharding 的日常管理以及更加深入的使用]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb</tag>
        <tag>sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb复制集的管理]]></title>
    <url>%2Fnote%2Fdb_mongodb%E5%A4%8D%E5%88%B6%E9%9B%86%E7%9A%84%E7%AE%A1%E7%90%86.html</url>
    <content type="text"><![CDATA[复制集部署是仅仅不够的，还需要深入了解以及管理，所以接着开始复制集的管理 认真的读完了这个哥们的文章 Lanceyan,基本思路也是按照这篇文章思路来写的，对这篇文章进行了转载 Bully 算法关于该算法，这里有个中文的介绍 Bully算法是一种协调者（主节点）竞选算法，主要思想是集群的每个成员都可以声明它是主节点并通知其他节点。别的节点可以选择接受这个声称或是拒绝并进入主节点竞争。被其他所有节点接受的节点才能成为主节点。节点按照一些属性来判断谁应该胜出。这个属性可以是一个静态ID，也可以是更新的度量像最近一次事务ID（最新的节点会胜出）。 We use a consensus protocol to pick a primary. Exact details will be spared here but that basic process is: get maxLocalOpOrdinal from each server. if a majority of servers are not up (from this server’s POV), remain in Secondary mode and stop. if the last op time seems very old, stop and await human intervention. else, using a consensus protocol, pick the server with the highest maxLocalOpOrdinal as the Primary. 得到每个服务器节点的最后操作时间戳。每个mongodb都有oplog机制会记录本机的操作，方便和主服务器进行对比数据是否同步还可以用于错误恢复。 如果集群中大部分服务器down机了，保留活着的节点都为 secondary状态并停止，不选举了。 如果集群中选举出来的主节点或者所有从节点最后一次同步时间看起来很旧了，停止选举等待人来操作。 如果上面都没有问题就选择最后操作时间戳最新（保证数据是最新的）的服务器节点作为主节点。 选举触发条件 只有特定的情况选举才能进行 初始化一个副本集时。 副本集和主节点断开连接，可能是网络问题。 主节点down 选举还有个前提条件，参与选举的节点数量必须大于副本集总节点数量的一半，如果已经小于一半了所有节点保持只读状态，日志里将会出现 can&#39;t see a majority of the set, relinquishing primary 复制集管理1.手动下架主节点 db.adminCommand({replSetStepDown : 1})db.adminCommand({replSetStepDown : 1, force : true}) 强制 repset:PRIMARY&gt; db.adminCommand(&#123;replSetStepDown : 1&#125;) node128上的控制台 2014-11-19T00:36:59.633+0800 [rsHealthPoll] replSet member 172.16.105.129:27017 is now in state SECONDARY2014-11-19T00:36:59.634+0800 [rsMgr] replSet info electSelf 02014-11-19T00:37:02.924+0800 [rsMgr] replSet PRIMARY node129上的控制台 2014-11-19T15:07:23.684+0800 [rsHealthPoll] replSet member 172.16.105.128:27017 is now in state PRIMARY2014-11-19T15:07:24.084+0800 [rsBackgroundSync] replSet syncing to: 172.16.105.128:270172014-11-19T15:07:24.094+0800 [rsBackgroundSync] replset setting syncSourceFeedback to 172.16.105.128:27017 2.设置优先级 优先级为0不能成为 primary， 优先级由大到小，优先级i范围 0~1000（包含1000） 查看优先级，默认的优先级都为1，不显示repset:PRIMARY&gt; rs.conf()&#123; "_id" : "repset", "version" : 1, "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27017" &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27017" &#125; ]&#125;repset:PRIMARY&gt; cfg = rs.conf()repset:PRIMARY&gt; cfg.members[0].priority = 2repset:PRIMARY&gt; cfg.members[1].priority = 3repset:PRIMARY&gt; rs.reconfig(cfg)repset:SECONDARY&gt; rs.conf()&#123; "_id" : "repset", "version" : 2, "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27017", "priority" : 2 &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27017", "priority" : 3 &#125; ]&#125; 根据优先级，所以不让一个节点成为主节点，那么就有这三种操作了 使用rs.freeze(120)冻结指定的秒数不能选举成为主节点 设置成为仲裁节点 优先级低于所有副本集成员 3.oplog 信息 repset:PRIMARY&gt; db.printReplicationInfo()configured oplog size: 990MB //日志大小log length start to end: 0secs (0hrs) //oplog启用时间段oplog first event time: Thu Nov 20 2014 10:17:06 GMT+0800 (CST) //第一个事务日志产生的时间oplog last event time: Thu Nov 20 2014 10:17:06 GMT+0800 (CST) //最后一个事务日志产生的时间now: Thu Nov 20 2014 10:33:34 GMT+0800 (CST) //现在时间 oplog 只记录改变数据库现状的操作，查询操作不存储在 oplog 中 成员数量 摘抄文章里的这段话 官方推荐副本集的成员数量为奇数，最多12个副本集节点，最多7个节点参与选举。 最多12个副本集节点是因为没必要一份数据复制那么多份，备份太多反而增加了网络负载和拖慢了集群性能； 而最多7个节点参与选举是因为内部选举机制节点数量太多就会导致1分钟内还选不出主节点 哪些限制参考官方文挡MongoDB Limits and Thresholds。参考这个文章 这里。后来突然看了一篇 stackoverflow 的文章终于顿悟了，mongodb 本身设计的就是一个可以跨 IDC 的分布式数据库，所以我们应该把它放到大的环境来看。 心跳心跳 综上所述，整个集群需要保持一定的通信才能知道哪些节点活着哪些节点挂掉。mongodb节点会向副本集中的其他节点每两秒就会发送一次pings包，如果其他节点在10秒钟之内没有返回就标示为不能访问。每个节点内部都会维护一个状态映射表，表明当前每个节点是什么角色、日志时间戳等关键信息。如果是主节点，除了维护映射表外还需要检查自己能否和集群中内大部分节点通讯，如果不能则把自己降级为secondary只读节点。 同步副本集同步分为 初始化同步 和 keep复制。初始化同步指全量从主节点同步数据，如果主节点数据量比较大同步时间会比较长。而 keep 复制指初始化同步过后，节点之间的实时同步一般是增量同步。初始化同步不只是在第一次才会被处罚，有以下两种情况会触发： secondary 第一次加入，这个是肯定的。 secondary 落后的数据量超过了 oplog 的大小，这样也会被全量复制。 oplog 保存了数据的操作记录，secondary 复制 oplog 并把里面的操作在 secondary 执行一遍。但是 oplog 也是 mongodb 的一个集合，保存在 local.oplog.rs 里，但是这个 oplog 是一个 capped collection 也就是固定大小的集合，新数据加入超过集合的大小会覆盖。一旦 oplog 被覆盖，那么复制就会停止，所以这里需要注意，跨IDC的复制要设置合适的 oplogSize，避免在生产环境经常产生全量复制。 oplogSize 可以通过 –oplogSize 设置大小，对于 linux 和windows 64位，oplog size 默认为剩余磁盘空间的5%。 { “resync” : 1} 命令进行手动执行同步，也可以启动时候用 --autoresync 进行重新同步 同步也并非只能从主节点同步，假设集群中3个节点，节点1是主节点在 IDC1，节点2、节点3在 IDC2，初始化节点2、节点3会从节点1同步数据。后面节点2、节点3会使用就近原则从当前IDC的副本集中进行复制，只要有一个节点从 IDC1的节点1复制数据。 设置同步还要注意以下几点： secondary 不会从 delayed 和 hidden 成员上复制数据。 只要是需要同步，两个成员的 buildindexes 必须要相同无论是否是 true 和 false。buildindexes 主要用来设置是否这个节点的数据用于查询，默认为 true。 如果同步操作30秒都没有反应，则会重新选择一个节点进行同步 状态复制集状态都保存在各自的 local 库里，并且不会被复制，确保每个节点只有一个本地库 primary 上的复制状态还包括 secondary 节点列表，可以如下方式查看 repset:PRIMARY&gt; use localswitched to db localrepset:PRIMARY&gt; db.slaves.find()&#123; "_id" : ObjectId("546d4f22e3d8c20a0aefbfa2"), "config" : &#123; "_id" : 1, "host" : "172.16.105.129:27017" &#125;, "ns" : "local.oplog.rs", "syncedTo" : Timestamp(1416449826, 1) &#125;]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb复制集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发环境部署(四)]]></title>
    <url>%2Fnote%2Fdjango%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2-%E5%9B%9B.html</url>
    <content type="text"><![CDATA[善，总是以蜗牛的速度前进。然而无论多么艰难，我们始终不该放弃内心深处对善良的追求。 python 自带的轻量级的 web 服务器只能是用来本地测试，到了生产环境必须使用更为强大的 web 服务器，这里我使用的是 nginx，那么 python 应用要和 nginx 进行交互就必须利用一个桥梁和 nginx 通信，这里截取 51CTO 开发频道 python 应用部署部分内容，python 的应用部署比php略显麻烦，常见的部署方法有： fcgi：用spawn-fcgi或者框架自带的工具对各个project分别生成监听进程，然后和http服务通信 wsgi：利用http服务的mod_wsgi模块来跑各个project。 无论哪种都很麻烦，apache的mod_wsgi配置起来很麻烦，内存占用还大，如果要加上nginx作为静态页面的服务器那就更麻烦了；我的应用基本上到后来都是是各个project各自为战，且不说管理上的混乱，这样对负载也是不利的，空闲的project和繁忙的project同样需要占用内存。 一、uwsgi 这里开始真的混乱了好久，一直没分清uwsgi，uWSGI WSGI is the Web Server Gateway Interface. It is a specification for web servers and application servers to communicate with web applications (though it can also be used for more than that)，翻译过来大致是：WSGI是一种Web服务器网关接口。它是一个Web服务器与应用服务器通信的一种规范 关于WSGI看这里：WSGI 关于uwsgi看这里：uwsgi uWSGI：是一个Web服务器，它实现了WSGI协议、uwsgi、http等协议。Nginx中HttpUwsgiModule的作用是与uWSGI服务器进行交换 uwsgi：于WSGI一样是一种通信协议，而uWSGI是实现了uwsgi和WSGI两种协议的Web服务器。 uwsgi协议是一个uWSGI服务器自有的协议，它用于定义传输信息的类型，每一个uwsgi packet前4byte为传输信息类型描述，它与WSGI相比是两样东西。 2.uwsgi据说改进性能之后大约是fcgi协议的10倍那么快，有个比较见下图： #django的安装前几篇文章也有，这里再centos下安装pip也很简单，uwsgi也可以通过pip来安装 yum -y install libevent-devel python-devel yum -y install python-pip pip install uwsgi #测试uwsgi是否能独立启动 #本地创建一个test.py文件，内容如下 def application(env, start_response): start_response(&apos;200 OK&apos;, [(&apos;Content-Type&apos;,&apos;text/html&apos;)]) return &quot;Hello World&quot; #独立启动uwsgi，测试是否可以成功 uwsgi --http :8001 --wsgi-file test.py \\这条命令打开了本地8001端口进行监听，http访问即可看到Hello World，表明独立启动uwsgi成功 2.uWSGI的主要特点如下： 超快的性能 低内存占用（实测为apache2的mod_wsgi的一半左右） 多app管理 详尽的日志功能（可以用来分析app性能和瓶颈） 高度可定制（内存大小限制，服务一定次数后重启等） 部署环境中nginx作为前端响应web请求和处理静态请求，其余非静态请求通过uwsgi传递给django。安装参考了Django中国社区的这篇文章 二、uwsgi + nginx + django2.1 系统环境Distribution : CentOS 6.5 minimal uwsgi version : 2.0.4 Python version : 2.7Web Server : Nginx 1.6 Init system : sysvinit 2.2 安装uwsgi，测试uwsgi django 的安装前几篇文章也有，这里再 centos 下安装 pip 也很简单，uwsgi 也可以通过 pip 来安装 yum -y install libevent-devel python-devel libxml2-develyum -y install python-pip pip install uwsgi #测试uwsgi是否能独立启动 #本地创建一个test.py文件，内容如下 def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "Hello World" #独立启动uwsgi，测试是否可以成功 uwsgi --http :8001 --wsgi-file test.py \\这条命令打开了本地8001端口进行监听，http访问即可看到Hello World，表明独立启动uwsgi成功 2.3 配置 django 连接 uwsgi1.新建一个 django project，runserver 测试正常启动即可，然后确定关闭django程序关闭 # tree testpro/ -L 1 #注意这里的层级结构testpro/├── django_socket.xml ├── django_wsgi.py├── manage.py└── testpro #目录1 directory, 3 files 2.新建 uwsgi 配置文件 这里要注意，python 2.7版本，如果是 python 2.6，则会报错 #!/usr/bin/env python # coding: utf-8 import os import sys # 将系统的编码设置为UTF8 reload(sys) sys.setdefaultencoding('utf8') os.environ.setdefault("DJANGO_SETTINGS_MODULE", "tryfirst.settings") from django.core.handlers.wsgi import WSGIHandler application = WSGIHandler() #os.environ.setdefault("DJANGO_SETTINGS_MODULE", "testpro.settings")#import django.core.handlers.wsgi#application = django.core.handlers.wsgi.WSGIHandler() 2.这时候利用 uwsgi 启动服务，访问 8000 端口是否能看到 django 应用的界面 uwsgi --http :8000 --chdir /home/src/sites/mysite --module django_wsgi.py注意 chdir 路径是我本地的 django 项目测试地址 到了这里成功的话利用 uwsgi 单独启动 django 应用就没有问题了，下一步让uwsgi 和 nginx 实现通信，作为桥梁，就可以实现我们的目的了 2.4 uwsgi 的一些参数和调优建议 详细介绍请查看参考阅读 uwsgi #并发四个线程 uwsgi -s :9090 -w mysite -p 4 #主控线程+4个线程 uwsgi -s :9090 -w mysite -M -p 4 #执行超过30s的client直接放弃 uwsgi -s :9090 -w mysite -M -p 4 -t 30 #限制内存空间 uwsgi -s :9090 -w mysite -M -p 4 -t 30 --limit-as 128 #服务超过10000个request自动respawn uwsgi -s :9090 -w mysite -M -p 4 -t 30 --limit-as 128 -R 10000 #后台运行 uwsgi -s :9090 -w mysite -M -p 4 -t 30 --limit-as 128 -R 10000 -d uwsgi.log 2.5 配置 uwsgi 连接 nginx 安装 nginx，这里略，上面是通过命令行启动 uwsgi，线上肯定是使用配置文件。我们让 nginx 和 uwsgi 通信使用 socket 来进行通讯，所以注意使用的通信端口没有被其他程序占用即可 1、新建 django_socket.xml，内容如下&lt;uwsgi&gt; &lt;socket&gt;:8000&lt;/socket&gt; &lt;chdir&gt;/home/src/sites/mysite/&lt;/chdir&gt; &lt;module&gt;django_wsgi&lt;/module&gt; &lt;processes&gt;4&lt;/processes&gt; &lt;!-- 进程数 --&gt; &lt;daemonize&gt;uwsgi.log&lt;/daemonize&gt; &lt;/uwsgi&gt; 2、nginx核心配置如下 server &#123; listen 80; server_name 192.168.122.136; access_log /home/ms/mysite/access.log; error_log /home/ms/mysite/error.log; location / &#123; include uwsgi_params; #这个模块编译好 uwsgi_pass 127.0.0.1:8000; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125;# location /static/ &#123;# alias /home/work/src/sites/testdjango1/testdjango/collectedstatic/;# index index.html index.htm;# &#125;# location /media/ &#123;# alias /home/work/src/sites/testdjango1/testdjango/public/media/;# &#125;&#125; 3、启动 nginx，以配置文件方式启动 uwsgi，检查端口和进程是否能正常 nginx -s reload uwsgi -x /home/src/sites/mysite/django_socket.xml 全部正常之后就可以尝试访问 nginx 的域名 80 端口进行访问，看是否能看到django 运行的页面了，查看日志，也能看到 uwsgi 接受到了请求 三、uwsgi 的启动关闭脚本 这部分是可选的，但是一旦投入线上使用，每次都使用命令行很显然是不切实际的，所以编写成类似于独立启动的服务脚本，方便启动和关闭 uwsgi，稍后补上 稍后补上 参考阅读 uWSGI projext uwsgi github uWSGI Options]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发环境部署(三)]]></title>
    <url>%2Fnote%2Fdjango%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2-%E4%B8%89.html</url>
    <content type="text"><![CDATA[有时候心头会翻滚一些止不住的欲望，想住更大的房子，开更好的车。可是只要读到一本好书，看了一部好电影，认识了一个有趣的人，去了一个风景美好的地方，就又觉得，其实把那些拼命赚钱的时间用来读更多的书，看更多的电影，认识更多有趣的人，走更远的路，看更多的好风景，这样的人生，才是真的美满 这篇是在django环境部署（一）、python版本控制器pyenv之后的第三篇，日常使用python的不同版本控制和虚拟环境完成环境部署 一、新建python版本$ pyenv install --list //列出可用的安装 $ pyenv install 2.7.6 //这里安装我需要的2.7.6版本测试，现在阶段下使用这个版本就够了 $ pyenv install 3.4.0 //这里安装测试的另一个python版本 二、新建虚拟环境$ pyenv virtualenv 2.7.6 dj16-276 //基于python2.7.6的django1.6的虚拟环境 $ pyenv virtualenv 3.4.0 django1.6-3.4 //基于python3.4的django1.6虚拟环境 $ pyenv versions //系统的安装环境 * system (set by /Users/mingmings/.pyenv/version) 2.7.6 3.4.0 dj16-276 django16-3.4 三、虚拟环境中安装django$ pyenv activate dj16-276 //激活虚拟环境 (dj16-276)$ pip install django //安装django框架 (dj16-276)$ pip install yolk yolk -l #查看安装的django是否安装成功 $ ll ~/.pyenv/versions/dj16-276/lib/python2.7/site-packages/ (dj16-276)$ python -V //虚拟环境中的python版本 Python 2.7.6 $ python -V //系统环境中的python版本 Python 2.7.5 四、开始django#验证django版本 $ python -c &quot;import django; print(django.get_version())&quot; #新建一个project $ django-admin.py startproject tryfirst-django #开启测试 $ cd tryfirst $ python manage.py runserver 到底利用虚拟环境中的python和django构建了两个和系统环境无关的django虚拟环境，到此完成，后面就是django的内容了]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>pyenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongodb复制集]]></title>
    <url>%2Fnote%2Fdb_mongodb%E5%A4%8D%E5%88%B6%E9%9B%86.html</url>
    <content type="text"><![CDATA[简介官方站点在大数据的时代，传统的关系型数据库要能更高的服务必须要解决高并发读写、海量数据高效存储、高可扩展性和高可用性这些难题。不过就是因为这些问题Nosql诞生了。 NOSQL有这些优势： 大数据量，可以通过廉价服务器存储大量的数据，轻松摆脱传统mysql单表存储量级限制。 高扩展性，Nosql去掉了关系数据库的关系型特性，很容易横向扩展，摆脱了以往老是纵向扩展的诟病。 高性能，Nosql通过简单的key-value方式获取数据，非常快速。还有NoSQL的Cache是记录级的，是一种细粒度的Cache，所以NoSQL在这个层面上来说就要性能高很多。 灵活的数据模型，NoSQL无需事先为要存储的数据建立字段，随时可以存储自定义的数据格式。而在关系数据库里，增删字段是一件非常麻烦的事情。如果是非常大数据量的表，增加字段简直就是一个噩梦。 高可用，NoSQL在不太影响性能的情况，就可以方便的实现高可用的架构。比如mongodb通过mongos、mongo分片就可以快速配置出高可用配置。 在nosql数据库里，大部分的查询都是键值对（key、value）的方式。MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中最像关系数据库的。支持类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。所以这个非常方便，我们可以用sql操作MongoDB，从关系型数据库迁移过来，开发人员学习成本会大大减少。如果再对底层的sql API做一层封装，开发基本可以感觉不到mongodb和关系型数据库的区别。 安装1.yum 源安装 cat &gt;&gt; /etc/yum.repos.d/mongodb-enterprise.repo &lt;&lt; EOF[mongodb-enterprise]name=MongoDB Enterprise Repositorybaseurl=https://repo.mongodb.com/yum/redhat/$releasever/mongodb-enterprise/stable/$basearch/gpgcheck=0enabled=1EOF# 官方源中提供了如下的 RPM 包- mongodb-enterprise.x86_64 基础包- mongodb-enterprise-mongos.x86_64 包含daemon程序和一些相关配置文件和脚本- mongodb-enterprise-server.x86_64 只包含daemon程序- mongodb-enterprise-shell.x86_64 mongo shell- mongodb-enterprise-tools.x86_64 相关的一些工具# yum 安装即可yum install -y --enablerepo=mongodb-enterprise mongodb-enterprise-2.6.5# 启动service mongod startchkconfig mongod on# 配置通过RPM安装的包，默认的存储 - /var/lib/mongo 存储instance的数据- /var/log/mongodb 日志存放位置- /etc/mongodb.conf 配置文件- /etc/init.d/mongod 启动脚本 2.源码包安装 curl -O http://downloads.mongodb.org/linux/mongodb-linux-x86_64-2.6.4.tgz | tar zxf -mkdir -p mongodbcp -R -n mongodb-linux-x86_64-2.6.4/ mongodbexport PATH=&lt;mongodb-install-directory&gt;/bin:$PATHmongod --dbpath &lt;path to data directory&gt; 客户端连接1.syntax: mongo host:port/dbname mongo 默认连接本地test库mongo 127.0.0.1:27017/admin 2.停止服务 service mongod stop&gt; use admin&gt; db.shutdownServer() 复制集副本集 也或者叫 复制集 是主从模式的一种形式，但是 NoSQL 的产生就是为了解决大数据量、高扩展性、高性能、灵活数据模型、高可用性。但是光通过主从模式的架构远远达不到上面几点，由此 MongoDB 设计了 副本集 和 分片 的功能。 mongoDB官方已经 不建议使用主从模式了，替代方案是采用副本集的模式，详细情况查看 官方的话 原理：mongodb复制集主节点负责处理客户端的请求，其他的都是从节点，负责映射主节点的数据。主节点记录所有的操作。从节点定期轮训主节点获得这些操作，而后对自己的数据副本执行这些操作。从节点执行了主节点的相同的操作，所以从节点就可以保持与主节点的数据同步。 主从之间是通过一个日志来存储写操作的，这个日志就是oplog。它是一个固定长度的 capped collection，位于 local 数据库中，用于记录复制集(replica set)操作日志，对于64位 mongodb ，默认的占用了 5% 磁盘空间，oplog 大小可以启动 mongodb 时指定 mongod –plogSize 指定 repset:PRIMARY&gt; use localswitched to db localrepset:PRIMARY&gt; show collectionsmeoplog.rsreplset.minvalidstartup_logsystem.indexessystem.replsetrepset:PRIMARY&gt; db.oplog.rs.find()&#123; "ts" : Timestamp(1416312406, 1), "h" : NumberLong(0), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "initiating set" &#125; &#125;&#123; "ts" : Timestamp(1416315116, 1), "h" : NumberLong("-7269003673399721967"), "v" : 2, "op" : "i", "ns" : "test.testdb", "o" : &#123; "_id" : ObjectId("546b40eba1f9ba55ca18ecb7"), "test1" : "testval1" &#125; &#125;&#123; "ts" : Timestamp(1416329687, 1), "h" : NumberLong("902176275869766644"), "v" : 2, "op" : "n", "ns" : "", "o" : &#123; "msg" : "Reconfig set", "version" : 2 &#125; &#125; ts: 某个时间的时间戳 op: 操作类型，i：insert；d：delete；u：update ns: 命名空间，操作的collection name o: document 内容 LAB节点: 172.16.105.128 [root@node128 bin]# ./mongod --dbpath /data/mongodbtest/repset/data/ --replSet repset[root@node129 bin]# ./mongod --dbpath /data/mongodbtest/replset/data/ --replSet repset[root@node130 bin]# ./mongod --dbpath /data/mongodbtest/replset/data/ --replSet repset初始化部分信息如下：2014-11-07T11:26:47.283+0800 [initandlisten] MongoDB starting : pid=1383 port=27017 dbpath=/data/mongodbtest/rep/data/ 64-bit host=node1282014-11-07T11:26:47.283+0800 [initandlisten] db version v2.6.4...2014-11-07T11:26:47.283+0800 [initandlisten] allocator: tcmalloc2014-11-07T11:26:47.283+0800 [initandlisten] options: &#123; replication: &#123; replSet: "repset" &#125;, storage: &#123; dbPath: "/data/mongodbtest/rep/data/" &#125; &#125;...2014-11-07T11:26:47.434+0800 [rsStart] replSet can't get local.system.replset config from self or any seed (EMPTYCONFIG)2014-11-07T11:26:47.434+0800 [rsStart] replSet info you may need to run replSetInitiate -- rs.initiate() in the shell -- if that is not already done... 此时三台机器并没有角色之分，副本及也没有初始化，根据规划，128作为主节点，129，130作为副本及的从节点 [root@node128 ~]# ./mongo 127.0.0.1MongoDB shell version: 2.6.5connecting to: test&gt; use adminswitched to db admin&gt; show dbsadmin (empty)local 0.078GB&gt; config = &#123;_id:"repset", members:[&#123;_id:0,host:"172.16.105.128:27017"&#125;,&#123;_id:1,host:"172.16.105.129:27017"&#125;,&#123;_id:2,host:"172.16.105.130:27017"&#125;]&#125;&#123; "_id" : "repset", "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27017" &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27017" &#125;, &#123; "_id" : 2, "host" : "172.16.105.130:27017" &#125; ]&#125;&gt; rs.initiate(config)&#123; "info" : "Config now saved locally. Should come online in about a minute.", "ok" : 1&#125; 此时，可以看到一旦初始化完成的 node128 节点上，可以看到一些输出类似如下 ...2014-11-07T11:52:03.848+0800 [conn1] replSet replSetInitiate admin command received from client2014-11-07T11:52:03.855+0800 [conn1] replSet replSetInitiate config object parses ok, 3 members specified2014-11-07T11:52:03.900+0800 [conn1] replSet replSetInitiate all members seem up2014-11-07T11:52:03.900+0800 [conn1] ******2014-11-07T11:52:03.900+0800 [conn1] creating replication oplog of size: 990MB...2014-11-07T11:52:03.900+0800 [FileAllocator] allocating new datafile /data/mongodbtest/rep/data/local.1, filling with zeroes...2014-11-07T11:52:03.905+0800 [FileAllocator] done allocating datafile /data/mongodbtest/rep/data/local.1, size: 1024MB, took 0.004 secs2014-11-07T11:52:03.908+0800 [conn1] ******2014-11-07T11:52:03.908+0800 [conn1] replSet info saving a newer config version to local.system.replset: &#123; _id: "repset", version: 1, members: [ &#123; _id: 0, host: "172.16.105.128:27017" &#125;, &#123; _id: 1, host: "172.16.105.129:27017" &#125;, &#123; _id: 2, host: "172.16.105.130:27017" &#125; ] &#125;2014-11-07T11:52:03.914+0800 [conn1] build index on: local.system.replset properties: &#123; v: 1, key: &#123; _id: 1 &#125;, name: "_id_", ns: "local.system.replset" &#125;2014-11-07T11:52:03.915+0800 [conn1] replSet replSetInitiate config now saved locally. Should come online in about a minute.2014-11-07T11:52:04.829+0800 [rsStart] replSet I am 172.16.105.128:270172014-11-07T11:52:04.837+0800 [rsStart] replSet STARTUP22014-11-07T11:52:04.840+0800 [rsSync] replSet SECONDARY2014-11-07T11:52:04.845+0800 [rsMgr] replSet can't see a majority, will not try to elect self2014-11-07T11:52:06.832+0800 [rsHealthPoll] replSet member 172.16.105.129:27017 is up2014-11-07T11:52:06.833+0800 [rsHealthPoll] replSet member 172.16.105.130:27017 is up2014-11-07T11:52:06.834+0800 [rsMgr] replSet info electSelf 02014-11-07T11:52:06.835+0800 [rsMgr] replSet couldn't elect self, only received 1 votes2014-11-07T11:52:06.836+0800 [rsMgr] replSet info electSelf 02014-11-07T11:52:06.837+0800 [rsMgr] replSet couldn't elect self, only received 1 votes2014-11-07T11:52:07.612+0800 [initandlisten] connection accepted from 172.16.105.130:51773 #2 (2 connections now open)2014-11-07T11:52:07.613+0800 [conn2] end connection 172.16.105.130:51773 (1 connection now open)2014-11-07T11:52:07.613+0800 [initandlisten] connection accepted from 172.16.105.130:51774 #3 (3 connections now open)2014-11-07T11:52:07.673+0800 [initandlisten] connection accepted from 172.16.105.129:56952 #4 (3 connections now open)2014-11-07T11:52:08.834+0800 [rsHealthPoll] replSet member 172.16.105.129:27017 is now in state STARTUP22014-11-07T11:52:08.835+0800 [rsHealthPoll] replset info 172.16.105.130:27017 thinks that we are down2014-11-07T11:52:08.835+0800 [rsHealthPoll] replSet member 172.16.105.130:27017 is now in state STARTUP22014-11-07T11:52:08.837+0800 [rsMgr] not electing self, 172.16.105.130:27017 would veto with 'I don't think 172.16.105.128:27017 is electable'2014-11-07T11:52:08.841+0800 [rsMgr] not electing self, 172.16.105.130:27017 would veto with 'I don't think 172.16.105.128:27017 is electable'2014-11-07T11:52:14.839+0800 [rsMgr] replSet info electSelf 02014-11-07T11:52:14.856+0800 [rsMgr] replSet PRIMARY2014-11-07T11:52:21.703+0800 [conn5] end connection 172.16.105.129:56953 (2 connections now open)2014-11-07T11:52:21.704+0800 [initandlisten] connection accepted from 172.16.105.129:56956 #6 (3 connections now open)...2014-11-07T11:52:23.719+0800 [initandlisten] connection accepted from 172.16.105.129:56958 #11 (5 connections now open)...2014-11-07T11:52:24.847+0800 [rsHealthPoll] replSet member 172.16.105.129:27017 is now in state SECONDARY2014-11-07T11:52:24.848+0800 [rsHealthPoll] replSet member 172.16.105.130:27017 is now in state SECONDARY...2014-11-07T11:52:25.677+0800 [slaveTracking] build index on: local.slaves properties: &#123; v: 1, key: &#123; _id: 1 &#125;, name: "_id_", ns: "local.slaves" &#125;2014-11-07T11:52:25.677+0800 [slaveTracking] added index to empty collection2014-11-07T11:52:47.616+0800 [clientcursormon] mem (MB) res:37 virt:29342014-11-07T11:52:47.616+0800 [clientcursormon] mapped (incl journal view):22082014-11-07T11:52:47.616+0800 [clientcursormon] connections:72014-11-07T11:52:47.616+0800 [clientcursormon] replication threads:322014-11-07T11:52:51.740+0800 [conn6] end connection 172.16.105.129:56956 (6 connections now open)2014-11-07T11:52:51.741+0800 [initandlisten] connection accepted from 172.16.105.129:56962 #16 (7 connections now open)... 此时查看集群状态,已经可以看到终端提示符已经变成了 PRIMARY，身份已经成为主 &gt; rs.status()&#123; "set" : "repset", "date" : ISODate("2014-11-07T04:08:15Z"), "myState" : 1, "members" : [ &#123; "_id" : 0, "name" : "172.16.105.128:27017", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", "uptime" : 2488, "optime" : Timestamp(1415332323, 1), "optimeDate" : ISODate("2014-11-07T03:52:03Z"), "electionTime" : Timestamp(1415332334, 1), "electionDate" : ISODate("2014-11-07T03:52:14Z"), "self" : true &#125;, &#123; "_id" : 1, "name" : "172.16.105.129:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 969, "optime" : Timestamp(1415332323, 1), "optimeDate" : ISODate("2014-11-07T03:52:03Z"), "lastHeartbeat" : ISODate("2014-11-07T04:08:15Z"), "lastHeartbeatRecv" : ISODate("2014-11-07T04:08:14Z"), "pingMs" : 0, "syncingTo" : "172.16.105.128:27017" &#125;, &#123; "_id" : 2, "name" : "172.16.105.130:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 969, "optime" : Timestamp(1415332323, 1), "optimeDate" : ISODate("2014-11-07T03:52:03Z"), "lastHeartbeat" : ISODate("2014-11-07T04:08:15Z"), "lastHeartbeatRecv" : ISODate("2014-11-07T04:08:14Z"), "pingMs" : 0, "syncingTo" : "172.16.105.128:27017" &#125; ], "ok" : 1&#125;repset:PRIMARY&gt; 复制集的配置 配置保存在local 中 repset:PRIMARY&gt; use localswitched to db localrepset:PRIMARY&gt; show collectionsmeoplog.rsreplset.minvalidstartup_logsystem.indexessystem.replsetrepset:PRIMARY&gt; db.system.replset.find()&#123; "_id" : "repset", "version" : 2, "members" : [ &#123; "_id" : 0, "host" : "172.16.105.128:27017", "priority" : 2 &#125;, &#123; "_id" : 1, "host" : "172.16.105.129:27017", "priority" : 3 &#125; ] &#125; 测试1.主节点插入数据 repset:PRIMARY&gt; use testswitched to db testrepset:PRIMARY&gt; show dbsadmin (empty)local 1.078GBrepset:PRIMARY&gt; db.testdb.insert(&#123;"test1":"testval1"&#125;)WriteResult(&#123; "nInserted" : 1 &#125;)repset:PRIMARY&gt; show dbsadmin (empty)local 1.078GBtest 0.078GB 2.从节点进行查询数据 repset:SECONDARY&gt; show dbsadmin (empty)local 1.078GBtest 0.078GBrepset:SECONDARY&gt; use testswitched to db testrepset:SECONDARY&gt; show tables2014-11-07T12:15:20.724+0800 error: &#123; "$err" : "not master and slaveOk=false", "code" : 13435 &#125; at src/mongo/shell/query.js:131//默认的只有主节点进行读写数据，从节点只能同步数据，但是不能读repset:SECONDARY&gt; db.getMongo().setSlaveOk()//赋读的权限epset:SECONDARY&gt; use testswitched to db testrepset:SECONDARY&gt; show tablessystem.indexestestdbrepset:SECONDARY&gt; db.testdb.find()&#123; "_id" : ObjectId("545c473769632a6132b03cf7"), "test1" : "testval1" &#125; 故障转移2014-11-07T12:32:30.107+0800 [rsHealthPoll] warning: Failed to connect to 172.16.105.128:27017, reason: errno:111 Connection refused2014-11-07T12:32:30.108+0800 [rsHealthPoll] warning: Failed to connect to 172.16.105.128:27017, reason: errno:111 Connection refused2014-11-07T12:32:30.108+0800 [rsHealthPoll] couldn't connect to 172.16.105.128:27017: couldn't connect to server 172.16.105.128:27017 (172.16.105.128) failed, connection attempt failed2014-11-07T12:32:49.205+0800 [rsHealthPoll] replset info 172.16.105.128:27017 heartbeat failed, retrying 此时查看副本集状态 repset:SECONDARY&gt; rs.status()&#123; "set" : "repset", "date" : ISODate("2014-11-07T04:35:13Z"), "myState" : 2, "syncingTo" : "172.16.105.130:27017", "members" : [ &#123; "_id" : 0, "name" : "172.16.105.128:27017", "health" : 0, "state" : 8, "stateStr" : "(not reachable/healthy)", //已经为不可达 "uptime" : 0, "optime" : Timestamp(1415333687, 1), "optimeDate" : ISODate("2014-11-07T04:14:47Z"), "lastHeartbeat" : ISODate("2014-11-07T04:35:12Z"), "lastHeartbeatRecv" : ISODate("2014-11-07T04:31:36Z"), "pingMs" : 0 &#125;, &#123; "_id" : 1, "name" : "172.16.105.129:27017", "health" : 1, "state" : 2, "stateStr" : "SECONDARY", "uptime" : 3267, "optime" : Timestamp(1415333687, 1), "optimeDate" : ISODate("2014-11-07T04:14:47Z"), "self" : true &#125;, &#123; "_id" : 2, "name" : "172.16.105.130:27017", "health" : 1, "state" : 1, "stateStr" : "PRIMARY", //切换为主 "uptime" : 2586, "optime" : Timestamp(1415333687, 1), "optimeDate" : ISODate("2014-11-07T04:14:47Z"), "lastHeartbeat" : ISODate("2014-11-07T04:35:12Z"), "lastHeartbeatRecv" : ISODate("2014-11-07T04:35:12Z"), "pingMs" : 0, "electionTime" : Timestamp(1415334702, 1), "electionDate" : ISODate("2014-11-07T04:31:42Z") &#125; ], "ok" : 1&#125; 恢复的时候出现了一个错误，停止mongodb前台进程的时候，再次启动出现报错 2014-11-07T12:38:05.458+0800 [initandlisten] recover : no journal files present, no recovery needed2014-11-07T12:38:05.458+0800 [initandlisten] ERROR: Insufficient free space for journal files2014-11-07T12:38:05.459+0800 [initandlisten] Please make at least 3379MB available in /data/mongodbtest/rep/data/journal or use --smallfiles//出现这个故障提示，磁盘空间不足了，所以导致，可手动关闭该功能，默认功能开启 读写分离常规写操作来说并没有读操作多，所以一台主节点负责写，多台副本节点负责读 1.设置读写分离需要先在副本节点SECONDARY 设置 setSlaveOk。 2.在程序中设置读操作连接为副本节点SECONDARY即可 状态机官方解释，自己简单的翻译过来，翻译水平有限，错误之处还望指正 Number Name State Description 0 STARTUP Cannot vote. All members start up in this state. The mongod parses the replica set configuration document while in STARTUP. 1 PRIMARY Can vote. The primary is the only member to accept write operations. 2 SECONDARY Can vote. The secondary replicates the data store. 3 RECOVERING Can vote. Members either perform startup self-checks, or transition from completing a rollback or resync. 4 FATAL Cannot vote. Has encountered an unrecoverable error. 5 STARTUP2 Cannot vote. Forks replication and election threads before becoming a secondary. 6 UNKNOWN Cannot vote. Has never connected to the replica set. 7 ARBITER Can vote. Arbiters do not replicate data and exist solely to participate in elections. 8 DOWN Cannot vote. Is not accessible to the set. 9 ROLLBACK Can vote. Performs a rollback. 10 REMOVED Cannot vote. Was once in the replica set but has now been removed. 核心状态 PRIMARY处于该状态接受写操作，同一时间内副本集中有且只有一个 PRIMARY， PRIMARY 状态可以由 SECONDARY 经过投票选举而来，并且 PRIMARY 具有选举权 SECONDARY处于此状态的成员会从 PRIMARY 同步数据且可以接受读操作，当 PRIMARY 不可达的时候 SECONDARY 将会投票选举一个新 PRIMARY ARBITER仲裁节点，处在此状态下的成员既不能从 PRIMARY 复制数据，也不能进行写操作，只能进行投票；复制集中应该有一个成员处于仲裁状态从而避免了副本集中具有偶数成员的情况，副本集中最多只能有一个仲裁者的存在 关于成员的设置信息，详情Replica Set Members 初始化状态 STARTUP每个成员一套副本启动的启动状态。mongod然后加载该成员的复制设置配置,和转换 STARTUP2 成员的状态。此时不能参与投票 STARTUP2主程序读取完配置信息之后很快进入此状态，此期间，成员创建线程来处理内部成员复制操作，而后过渡到 :replstate:RECOVERING 状态； 初始化同步期间，成员们传输数据和建立索引，此期间一直保持 :replstate:STARTUP2 状态，这个期间，成员也是不能投票的 RECOVERING成员没有准备进行读操作的时候保持这个状态，这个状态期间会进行常规操作，并不一定会反映出异常状态，并且这个时候有资格进行投票，但是没有资格成为 PRIMARY。在启动期间,通过 RECOVERING 过渡到 STARTUP2 之后,才可以成为 SECONDARY；在正常操作期间,如果 SECONDARY 落后的其他成员复制集,它可能需要重新同步与其他集。而重新同步,成员进入 RECOVERING 状态。；每当副本集代替 PRIMARY 的选举中,旧的 PRIMARY 数据和包含的文档没有及时同步到 SECONDARY 。在这种情况下，这些成员需要回滚重新写入同步。回滚时成员将会 RECOVERING 状态。 错误状态 FATAL成员,遇到一个不可恢复的错误进入死亡状态。成员在这种状态需要管理员干预。 UNKNOWN成员从来没有连接状态信息到副本集都处于未知状态。 DOWN成员和主的连接中断，进入此状态 REMOVED成员从集合移除的时候的状态，会在 log 里记录一条 replSet REMOVED 的信息 ROLLBACK当 SECONDARY 从 PAIMARY 进行回滚进行写操作的时候，就进入了此状态]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>mongodb复制集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发环境（二）]]></title>
    <url>%2Fnote%2Fdjango%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%EF%BC%88%E4%BA%8C%EF%BC%89.html</url>
    <content type="text"><![CDATA[17 岁时你不漂亮，可以怪罪于母亲没有遗传好的容貌；但是 30 岁了依然不漂亮，就只能责怪自己，因为在那么漫长的日子里，你没有往生命里注入新的东西 之前的那篇是说明了django环境的site package完全独立出来了，但是使用的python解释器还是系统的，为了继续独立出来，甚至是达到ruby的rvm的自由切换解释器版本，那样不更好，日后线上升级python版本的时候直接再本地切换版本来运行当前代码测试岂不快哉，其实本篇已经不能算django开发环境了，是python开发环境部署在上篇的基础上，继续进行解释器的版本管理器的安装，这里我使用的时pyenv，另外一个管理器是 pythonbrew，还有一个 pythonz，至于为什么选择 pyenv，pythonbrew 的 GitHub 主页上给出了解释如下 英文翻译水平太烂，只能搬原文DeprecatedThis project is no longer under active development.You are encouraged to try out pyenv instead. 一、为什么选用pyenv Depend on Python itself. pyenv was made from pure shell scripts. There is no bootstrap problem of Python. Need to be loaded into your shell. Instead, pyenv’s shim approach works by adding a directory to your $PATH. Manage virtualenv. Of course, you can create virtualenv yourself, or pyenv-virtualenv to automate the process. 这个项目目前已经在慢慢取代了pythonbrew，GitHub主页https://github.com/yyuu/pyenv 1.1 简介 pyenv lets you easily switch between multiple versions of Python. It’s simple, unobtrusive, and follows the UNIX tradition of single-purpose tools that do one thing well.This project was forked from rbenv and ruby-build, and modified for Python. 1.2 功能 Let you change the global Python version on a per-user basis. Provide support for per-project Python versions. Allow you to override the Python version with an environment variable. Search commands from multiple versions of Python at a time. This may be helpful to test across Python versions with tox. 二、安装2.1 基于 GitHub 的安装This will get you going with the latest version of pyenv and make it easy to fork and contribute any changes back upstream. 1、克隆仓库$ cd$ git clone git://github.com/yyuu/pyenv.git .pyenv 2、指明环境变量$ echo 'export PYENV_ROOT="$HOME/.pyenv"' &gt;&gt; ~/.bash_profile$ echo 'export PATH="$PYENV_ROOT/bin:$PATH"' &gt;&gt; ~/.bash_profile 3、开启shims and autocompletion$ echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bash_profile 4、重新启动shell让其生效 $ exec $SHELL 5、这时候就可以安装另外版本的python了#这里会在$PYENV_ROOT/versions下生成一个目录$ pyenv install 2.7.6 6、重构shim，利用pyenv安装完新version的py还是利用安装完新site package都需要执行这个操作$ pyenv rehash 7、升级pyenv#升级到最新版$ cd ~/.pyenv$ git pull#升级到指定版本$ cd ~/.pyenv$ git fetch$ git tagv0.1.0$ git checkout v0.1.08、卸载指定py版本通用方法~/.pyenv/versionspyenv uninstall暴力做法rm -rf $pyversion 如果是mac平台$ brew update$ brew install pyenv //安装$ brew upgrade pyenv //升级#安装完成之后$ echo 'eval "$(pyenv init -)"' &gt;&gt; ~/.bash_profile //只需要执行一次即可 2.2 使用官方usage页 $ pyenv commands //列出可以使用的命令$ pyenv install 3.4.0$ pyenv version //查看当前的python version $ pyenv versions //列出pyenv安装的所有组件，包括site package$ pyenv which python3.4 //列出给定的python version可执行文件位置$ pyenv whence 2to3 //列出pyenv安装的python version$ pyenv install --list //列出所有可以安装的包括python version，pypy等$ pyenv rehash //Run this command after you install a new version of Python, or install a package that provides binaries.$ pyenv uninstall //卸载#下面关于pyenv local和pyenv global是两个重要命令稍后做出单独使用的解释 2.3 补充 2015-07-03 好久不弄了，因为最近准备开始写一个项目的关系，所以重新关注了，但是发觉安装方式也多了，出现了更友好的安装方式，具体地址见参考阅读 pyenv-installer 1、推荐做法安装$ curl -L https://raw.githubusercontent.com/yyuu/pyenv-installer/master/bin/pyenv-installer | bash升级pyenv update卸载$ rm -fr ~/.pyenv 2、PyPi 方式$ pip install --egg pyenv 2.4 整合virtualenv 这个pyenv设计了插件来整合了virtualenv甚至还人性化的推出了virtualenvwrapper 1、安装 $ git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv$ exec "$SHELL"#上面会把最近版本安装到~/.pyenv/plugins/pyenv-virtualenv目录#mac下的安装$ brew install pyenv-virtualenv 2、使用 $ pyenv virtualenv 2.7.6 venv-2.7.6 //创建一个使用2.7.6版本的解释器的名称为my-virtual-env-2.7.6虚拟环境，存放在~/.pyenv/versions$ pyenv virtualenv 3.4.0 venv-django1.6-3.4.0 //同理创建一个3.4解释器的虚拟环境，就是前面我需要的完全独立的测试环境#这里有个注意的地方这里的解释器必须是通过pyenv安装的解释器，如果不加参数，如下$ pyenv virtualenv django1.6 //那么这里会使用系统的python version创建虚拟环境，如果需要加参数，就必须是pyenv安装的版本#激活虚拟环境venv33，这个虚拟环境必须是pyenv创建存在的$ pyenv activate venv33#退出虚拟环境$ pyenv deactivate 参考阅读 pyenv pyenv installer]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>pyenv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下mysql密码丢失]]></title>
    <url>%2Fnote%2Fdb_Mac%E4%B8%8Bmysql%E5%AF%86%E7%A0%81%E4%B8%A2%E5%A4%B1.html</url>
    <content type="text"><![CDATA[本身的osx平台上安装了mysql搭建测试环境，偶尔一次mysql密码丢失，找回的思路和linux平台都是一样的，只是这里osx平台下一些操作不同，记录下 1.关闭MySQL进程sudo killall -TERM mysqld 2.重新启动MySQLcd /usr/lcoal/mysql/bin/sudo ./mysqld_safe 3.修改用户口令即可方法1： 用SET PASSWORD命令 mysql -u root mysql&gt; SET PASSWORD FOR 'root'@'localhost' = PASSWORD('newpass');方法2：用mysqladmin mysqladmin -u root password "newpass"如果root已经设置过密码，采用如下方法 mysqladmin -u root password oldpass "newpass" 方法3： 用UPDATE直接编辑user表 mysql -u root mysql&gt; use mysql; mysql&gt; UPDATE user SET Password = PASSWORD('newpass') WHERE user = 'root'; mysql&gt; FLUSH PRIVILEGES;非Mac平台的mysql在丢失root密码的时候，可以这样 mysqld_safe --skip-grant-tables&amp; mysql -u root mysql mysql&gt; UPDATE user SET password=PASSWORD("new password") WHERE user='root'; mysql&gt; FLUSH PRIVILEGES;]]></content>
      <categories>
        <category>DB</category>
      </categories>
      <tags>
        <tag>osx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[expect中send的特殊字符问题]]></title>
    <url>%2Fnote%2Fexpect%E4%B8%ADsend%E7%9A%84%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E9%97%AE%E9%A2%98.html</url>
    <content type="text"><![CDATA[最近碰到了一个问题，早起使用的一个 expect 脚本登录一个新机器的时候密码提示报错了，但是手动登录确实是可以的，所以还是脚本中传递密码的时候出了问题，找了半天最后发觉是 expect 产生于 tcl 语言自身的问题，用正确的密码登录失败了，但是密码的确是没有问题的，一直提示报错，不停的查看网友们的情况，后来得知大致原因是由于 tcl 这门语言本身对 send 中的特殊字符产生了转义导致了密码错误,继续查看，大致有两种情况 1. send 中的特殊字符如果是在 send 语句中的特殊字符，例如 中括号”[ ]”，花括号” { }” 都会被当做 tcl 本身的语法进行转义，但是对于“@”这样的特殊字符，仍旧被当做特殊字符处理，所以碰到了这样的 tcl 本身的特殊字符处理之外的特殊字符串的话必须进行转义，如果在 send 语句中出现了，那么转义只需要加上一个“\”，例如 原先的密码为 &quot;@[!}&quot; 那么需要 set passwd "@ \[ ! \&#125;"，这里我刻意用了空格来区分开来并且下面使用 send "$passwd\r" 2. expect 中的特殊字符如果出现在了 expect 语法中，那么需要加两个“\”，上面的例子就变成了 那么需要 set passwd "@ \\[ ! \\&#125;"，这里我刻意用了空格来区分开来并且下面使用 send "$passwd\r" 从目前出现的情况来看，应该可能实在 tcl 语言内在的字符会被处理，不知道是否还有其他字符会被处理，先这样吧]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>expect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2014年年终总结]]></title>
    <url>%2Fnote%2F%E5%B7%A5%E4%BD%9C_2014-%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93.html</url>
    <content type="text"><![CDATA[2013年11月底加入上家公司，在任职的期间内的付出与回报，总结一些自身的缺点和不足，以便自身改进。 加入这里和计划和期望最终没能和自己当初的规划一样，也发现了自身的诸多不足，同时也看到了公司的一些缺陷，最终综合在一直，选择离开。对于每一个员工，离开都有特定的理由。用这篇文章指出我这种既非新人，亦非资深人士在技术岗位上的一些感悟 一、付出这段时间，让我感觉付出最多的还是时间，每周一天的休假，经常不确定的加班。可能是之前一直保持的状态，也慢慢习惯了，就像多数人印象里互联网公司里多数人都是那个点下班一样，我也步入了即使下班没有事情以及会选择晚一点下班，“坐一会”的习惯，虽然可以看看一些其他资料，研究一个新技术，但是留给生活上的时间是少之又少，不停的陷入一种在公司工作，回家只能睡觉的一种状态。开始的我单纯的以为年轻的时候就应该这样积攒，沉淀来让自己羽翼更加丰满，而后慢慢意识到，如果是真心这样的状态，是坚持不了多久的，熬了几年之后身体累垮，有气无力？这肯定不是我想要的结果。 开始适当的调整自己，少一些“坐一会”，多分配一点生活时间，明显改善到了一切的变化。生活方面的改善，显著的给工作带来了更好的驱动力，相辅相成，如此简单的道理，可到了如今才开始落实 对于这里的岗位上，渐渐感觉到了自身逐渐暴露出来的不足，总结几点如下： 1.1、细心在少数时候，犯下了这样的毛病，主要体会就是个别文档中的错别字，操作步骤，虽不致命，但是却可以让他人感觉到我的不专业，这份工作中不少工作都是从开始到结束都是自己单一完成，最后的审核也是自己，久而久之养成了一遍带过的习惯，为此付出了不小的代价，为此觉得从还得从自身入手，宁可牺牲点时间，加强校验，业报保质的完成任务，而不是追求时间的最小化 1.2、英文如同多数其他IT岗位一般，运维岗对英文的能力是有相当的依赖的，作为新人开始加入工作的时候对英文文档还不太敏感，多数也是依赖中文，自头用英文布置一些任务的时候开始的确有点手足无措到慢慢适应并且到开始享受，深感英文对于技术的辅助作用，所以无论是我还是其他互联网岗位的各位，英文功力的提升势必是必修课 1.3、done better than perfect有一种感觉，有时候工作的时候总想做的更好，从开始设计到后期实现，总希望每一步中间都是用自己认知里最好的方式来实现，这样的结果才能让自己满意，可恰恰是这种想法让自己吃了无数苦头，纠结于每个步骤甚至于每个细节，让自己痛苦不堪，甚至连交付的任务都没有能按时完成，当然挨批等都是情理之中的事情 经历了几次苦头之后，愈加明白，能力范围之内，完成为第一优先级；其次有能力的情况下在考虑优化；仅仅一个人的岗位上完成许多事情，仅仅能全部完成已纯属不易，荣不得过多的时间耗在某一件事情上。当然这是和之前的岗位有所关系，所以也造就了我对后面的工作选择上开始更多了有了自己的看法和选择，这种大而广之的工作对精力的消耗也是显而易见，也不利于后期的工作，也和自己的职业规划有点背道而驰，这可能也是离开的原因之一 1.4、情绪这部分其实是不应该有的，毕竟已经不是新人了，之所以写出来，也是坦诚的对待自己的过去的工作，这里的情绪说的通俗点就是工作的不爽，本以为自己的个性是个相当能耐磨的人，硬生生的从刚来的有点热血沸腾的人变得寡言，中间的变化已不再多赘述；公司的气氛，也是相当之压抑，甚至诡异。 当情绪产生的时候，就开始慢慢的影响到工作，影响到了在公司的各方面表现，这方面主要体现于，慢慢变得寡言，自给自足，疲于应付。当固守己见成为习惯的时候，当任何底层意见和建议都不足以生效，不足以改变任何现状的时候，只能选择离开，这也许是最好的选择 1.5、宽 vs 深？这方面可能在运维岗这里体现的比较明显，宽度和深度的问题，可能是技术岗上都需要越过的坎。这方面也是在工作之后的权衡，从刚进入公司一人岗，到半年后补充了一个新人，始终在不停的处理各种各样问题，能牵扯到的关系的事宜都直接会被叫去处理，就有了最繁忙的时候看一个问题都不会超过半天的尴尬境地，总结这份工作岗位性质，囊括运维，网管，前台，人力，客服，最后到劳动力都扮演过。 宽 已经是这个岗位直观给我的感受，也的确从中得到了一些收获，但是一直扮演这么多角色，终归无法从这里得到自己最想要的东西。另外诸多并不擅长且疲于应付的事宜中，处理的不完善也得到了不少批评，不过这直观了增强了日后对这方面事宜的处理技巧，不得不说是一种收获。 深 虽然上面给自己带来了多方位处理问题的技巧，但是对于自己的技术深度提升却不太多，毕竟自己仍旧处于新人往资深上转换的过程中，技术实力是筹码，没有深度对日后都相对不利。但是岗位的要求依旧和自己期望的大相径庭，加上一些管理层面的因素，就逐渐产生了上面的情绪，结果不言而喻。 对于有句“技术对管理的容忍度很低”，个人对这句话有点理解，混乱的管理模式会让员工变得难以适应，离职率的上升也是不无道理的 二、收获问我在这份工作中收获到了什么，当真学习到很多，处理的问题的广度和眼界，不断学习陌生领域的问题，因而获益；从上面的阐述中，英文，处理问题的技巧，技术的进步乃至眼界层面都上了一个台阶；相信每经过一个这种阶段，都会对自己的各方面提升颇多，只有不断的审视自己，弥补自己的缺陷和不足，转换成行之有效的方法和技巧，在日后的工作各方面就会无往不利，写下这些作为反思自己，也借此不断调整自己更好的来适应日后的发展，也希望各位不吝赐教，指点不足和改进的地方，将不胜感激]]></content>
      <categories>
        <category>工作</category>
      </categories>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django开发环境部署（一）]]></title>
    <url>%2Fnote%2Fdjango%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%EF%BC%88%E4%B8%80%EF%BC%89.html</url>
    <content type="text"><![CDATA[山有山的高度，水有水的深度，没必要攀比；风有风的自由，云有云的温柔，没必要模仿。你认为快乐的，就去寻找；你认为值得的，就去守候；你认为是幸福的，就去珍惜。没有不被评说的事，没有不被猜测的人。别太在乎别人的看法，做最真实的最朴实的自己，依心而行。才能无憾今生 之所以写这篇文章的原因在于 django 环境的确轻松搭建，之前 Ubuntu 上安装了，的确很轻松，但是后期我才知道随便做个环境出来很容易到了后面很麻烦，污染了系统里的 python 版本，导致系统 python 环境异常崩溃，系统重装的 Ubuntu 的亲们你们是有感触吧，所以好多人采用 virtualenv 吧，但是期初用 virtualenv 的时候的确不需要系统的依赖包了，但是后来折腾来折腾去还是很麻烦，最后我不得已我又各种删，所以最后看到了一个哥们的文章，我才觉得找到了自己自己想要的东西了所以重头再 mac 下已默认 python 2.7.5 为系统 python 系统版本，完全独立出来的虚拟环境，方便删除，挪动，更改环境中的各组件版本，也许我有轻微强迫症的人。不污染系统环境，不依赖于系统的 package，完全独立的 python 版本，独立的django 版本，独立的 django 依赖包，所以马上从头开始 一、安装 pip在python中可以使用easy_install和pip安装python拓展但推荐使用pip，在stackoverflow看到个帖子，阐明了理由 Don't use easy_install, unless you like stabbing yourself in the face. Use pip.Two reasons, there may be more:- pip provides an uninstall command- if an installation fails in the middle, pip will leave you in a clean state. 1.1 pip 简介Pip 是安装 python 包的工具，提供了安装包，列出已经安装的包，升级包以及卸载包的功能。Pip 是对 easy_install 的取代，提供了和 easy_install 相同的查找包的功能，因此可以使用 easy_install 安装的包也同样可以使用pip进行安装。 Pip 的安装可以通过源代码包，easy_install 或者脚本。 因为easy_install:$ easy_install pip也可以通过这样的方式安装# sudo apt-get install python-pip python-dev build-essential 1.2 pip 使用安装 package$ pip install Markdown列出安装的packages$ pip freeze安装特定版本的package 通过使用==, &gt;=, &lt;=, &gt;, &lt;来指定一个版本号。 $ pip install Markdown&lt;2.0$ pip install -v Markdown==2.3$ pip install Markdown&gt;2.0,&lt;2.0.3升级包升级包到当前最新的版本，可以使用-U 或者 --upgrade$ pip install -U Markdown卸载包 $ pip uninstall Markdown查询包pip search Markdown更多详情pip help 国内碰到最多的问题，就是源连接超时之类的，所以下面这些方法都是针对这些情况下的 走代理pip install --proxy="http://domain\username:pwd@xxx.xxx.xxx.xxx:80" Markdown如果没有代理，直接换个源下载吧，具体的源信息可以在参考链接里的 pypi mirror 里找到，找到 CN 的就可以了pip install bpython --trusted-host e.pypi.python.orgpip install bpython -i e.pypi.python.org/sample 二、安装virtualenv$ sudo pip install virtualenv使用方法：1、创建虚拟环境$ virtualenv env1 //创建虚拟环境env1 默认情况下，虚拟环境会依赖系统环境中的 site packages，就是说系统中已经安装好的第三方 package 也会安装在虚拟环境中，如果不想依赖这些 package ，那么可以加上参数 --no-site-packages 建立虚拟环境，可以用下面命令查看 package 安装位置 # python -c "from distutils.sysconfig import get_python_lib;print(get_python_lib())"/usr/lib/python2.7/dist-packages //Ubuntu下的路径/Library/Python/2.7/site-packages //mac下的路径$ virtualenv env2 --no-site-package 这条命令安装完了之后site package就会安装到创建好的虚拟环境中，这样就实现了独立于系统之外，不污染系统了 2、启用虚拟环境 cd env1source ./bin/activate 注意此时命令行会多一个(env1)，ENV为虚拟环境名称，接下来所有模块都只会安装到该目录中去。 3、退出虚拟环境 deactivate 4、在虚拟环境中安装python module pip install [套件名称] Virtualenv 附带有pip安装工具，因此需要安装的套件可以直接运行： 如果没有启动虚拟环境，系统也安装了pip工具，那么套件将被安装在系统环境中，为了避免发生此事，可以在 ~/.bashrc 文件中加上： export PIP_REQUIRE_VIRTUALENV=true 或者让在执行pip的时候让系统自动开启虚拟环境： export PIP_RESPECT_VIRTUALENV=true 三、安装 virtualenvwrapperVirtaulenvwrapper 是 virtualenv 的扩展包，用于更方便管理虚拟环境，它可以做： 将所有虚拟环境整合在一个目录下 管理（新增，删除，复制）虚拟环境 快速切换虚拟环境 tab 补全虚拟环境名字 每個操作都提供允许使用者自己定制的 hooks 可以编写比较容易分享的 extension plugin 安装 $ sudo pip install virtualenvwrapper 此时还不能使用 virtualenvwrapper，默认 virtualenvwrapper 安装在 /usr/local/bin 下面，实际上你需要运行 virtualenvwrapper.sh 文件才行 配置.bashrc alias python="python2.7" 如果你的系统 python 安装的位置不是默认位置，请加上环境变量申明 PATH=$&#123;PATH&#125;:/usr/local/share/python #virtualenvwrapperexport WORKON_HOME=$HOME/virtualenvs //虚拟环境存放位置自己指定source /usr/local/bin/virtualenvwrapper.sh //指定virtualenvwrapper的执行文件路径export VIRTUALENVWRAPPER_PYTHON=/usr/bin/python2.7 //系统python2.7执行文件位置，根据自己环境而定export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages' //启动时候指定参数，就是我们用的独立于系统的安装包export PIP_VIRTUALENV_BASE=$WORKON_HOME //告知pip virtualenv的位置export PIP_RESPECT_VIRTUALENV=true //执行pip的时候让系统自动开启虚拟环境 如果是 mac 用户，由于 Terminal 在启动时加载的用户配置并非 .bashrc，而是 ~/.bash_profile，所在还需要在 ~/.bash_profile 加入[ -r ~/.bashrc ] &amp;&amp; source ~/.bashrc 使用方法1、列出虚拟环境列表 workon或lsvirtualenv 2、新建虚拟环境 mkvirtualenv [虚拟环境名称] 3、启动\切换虚拟环境 workon [虚拟环境名称] 4、复制虚拟环境$ cpvirtualenv ENVNAME TARGETENVNAME 5、删除虚拟环境 rmvirtualenv [虚拟环境名称] 6、离开虚拟环境 deactivate 四、安装 pythonbrew对于日后想用不同的版本 python 进行代码测试的话自然少不了这个，接下来的内容中加上这部分 五、安装辅助组件 yolk是一个列出python安装包的工具 $ pip install yolk` $ yolk -l 六、安装django#安装ms@mss:~$ workon test(test)ms@mss:~$ pip install django #django安装的位置python -c "import sys; sys.path = sys.path[1:]; import django; print(django.__path__)"['/home/ms/.virtualenvs/test/local/lib/python2.7/site-packages/django'] \\这里就是我虚拟环境中 到此本地的开发 django 环境也就安装完了，这样独立的开发环境，pythonbrew 安装的 python 版本，不依赖于系统，完全独立，直接删除没有任何影响，或者直接拷贝虚机环境修改里面的 python 版本和 django 版本就可以进行另外的测试了，和系统环境无关联，达到了我想要的结果，就不至于乱折腾系统了，我直接乱折腾虚拟环境 参考阅读 pyenv pypi mirrors]]></content>
      <categories>
        <category>django</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>virtualenv</tag>
      </tags>
  </entry>
</search>
